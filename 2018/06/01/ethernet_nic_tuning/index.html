<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Ethernet nic tuning | 无常无形无功;不动不破不空</title><meta name="keywords" content="network,benchmark,nic,irq"><meta name="author" content="Homer"><meta name="copyright" content="Homer"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="benchmark NIC ppspkggen kernel mode,No more diff between 1GbE with 10GbE (BCM57800)The problem, Jesper said, is that the kernel developers have focused on scaling out to large numbers of cores. In the">
<meta property="og:type" content="article">
<meta property="og:title" content="Ethernet nic tuning">
<meta property="og:url" content="http://yoursite.com/2018/06/01/ethernet_nic_tuning/index.html">
<meta property="og:site_name" content="无常无形无功;不动不破不空">
<meta property="og:description" content="benchmark NIC ppspkggen kernel mode,No more diff between 1GbE with 10GbE (BCM57800)The problem, Jesper said, is that the kernel developers have focused on scaling out to large numbers of cores. In the">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png">
<meta property="article:published_time" content="2018-06-01T02:49:42.000Z">
<meta property="article:modified_time" content="2021-04-28T03:41:08.000Z">
<meta property="article:author" content="Homer">
<meta property="article:tag" content="network">
<meta property="article:tag" content="benchmark">
<meta property="article:tag" content="nic">
<meta property="article:tag" content="irq">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png"><link rel="shortcut icon" href="/img/stout-shield.png"><link rel="canonical" href="http://yoursite.com/2018/06/01/ethernet_nic_tuning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-04-28 11:41:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="无常无形无功;不动不破不空" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/fighting-spiri-logot.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">56</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">54</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#benchmark-NIC-pps"><span class="toc-number">1.</span> <span class="toc-text">benchmark NIC pps</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slot-status"><span class="toc-number">2.</span> <span class="toc-text">slot status</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#THEORETICAL-MAXIMUM-RATE"><span class="toc-number">3.</span> <span class="toc-text">THEORETICAL MAXIMUM RATE</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#About-FEC"><span class="toc-number">4.</span> <span class="toc-text">About FEC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CPU-setting"><span class="toc-number">5.</span> <span class="toc-text">CPU setting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#nic-offload"><span class="toc-number">6.</span> <span class="toc-text">nic offload</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Resize-the-hardware-buffer-queue-to-max"><span class="toc-number">6.1.</span> <span class="toc-text">Resize the hardware buffer queue to max</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#setting-driver"><span class="toc-number">6.2.</span> <span class="toc-text">setting driver</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Interrupt-Queues"><span class="toc-number">7.</span> <span class="toc-text">Interrupt Queues</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Busy-Polling"><span class="toc-number">7.1.</span> <span class="toc-text">Busy Polling</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Socket-receive-queues"><span class="toc-number">8.</span> <span class="toc-text">Socket receive queues</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Change-the-speed-of-the-incoming-queue"><span class="toc-number">8.1.</span> <span class="toc-text">Change the speed of the incoming queue</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Increase-the-depth-of-the-application%E2%80%99s-socket-queue"><span class="toc-number">8.1.1.</span> <span class="toc-text">Increase the depth of the application’s socket queue</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Use-setsockopt-to-configure-a-larger-SO-RCVBUF-value-userspace"><span class="toc-number">8.2.</span> <span class="toc-text">Use setsockopt to configure a larger SO_RCVBUF value (userspace)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RSS-IRQ-Affinity"><span class="toc-number">8.3.</span> <span class="toc-text">RSS IRQ Affinity</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Support-for-UDP-RSS"><span class="toc-number">8.3.1.</span> <span class="toc-text">Support for UDP RSS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Receive-Flow-Streering-RFS"><span class="toc-number">9.</span> <span class="toc-text">Receive Flow Streering (RFS)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Accelerated-RFS"><span class="toc-number">9.0.1.</span> <span class="toc-text">Accelerated RFS</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Interrupt-Moderation-interrupt-coalescence-or-Interrupt-Blanking"><span class="toc-number">10.</span> <span class="toc-text">Interrupt Moderation (interrupt coalescence or Interrupt Blanking)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#disable-PCIE-power-save"><span class="toc-number">11.</span> <span class="toc-text">disable PCIE power save</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#disable-numa"><span class="toc-number">11.1.</span> <span class="toc-text">disable numa</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RFC2544-stipulates-that-the-latency-test"><span class="toc-number">12.</span> <span class="toc-text">RFC2544 stipulates that the latency test</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-network-latency"><span class="toc-number">13.</span> <span class="toc-text">The network latency</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tools"><span class="toc-number">14.</span> <span class="toc-text">Tools</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#nc-test"><span class="toc-number">14.1.</span> <span class="toc-text">nc test</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#iperf3"><span class="toc-number">14.2.</span> <span class="toc-text">iperf3</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#qperf"><span class="toc-number">14.3.</span> <span class="toc-text">qperf</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#netperf"><span class="toc-number">14.4.</span> <span class="toc-text">netperf</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#sockperf"><span class="toc-number">14.5.</span> <span class="toc-text">sockperf</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#redis"><span class="toc-number">14.6.</span> <span class="toc-text">redis</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RFC6349-TCP-benchmark"><span class="toc-number">15.</span> <span class="toc-text">RFC6349 TCP benchmark</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#irqbalance"><span class="toc-number">15.1.</span> <span class="toc-text">irqbalance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#turbostat"><span class="toc-number">15.2.</span> <span class="toc-text">turbostat</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#numastat"><span class="toc-number">15.3.</span> <span class="toc-text">numastat</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#numad"><span class="toc-number">15.4.</span> <span class="toc-text">numad</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#OProfile"><span class="toc-number">15.5.</span> <span class="toc-text">OProfile</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#valgrind"><span class="toc-number">15.6.</span> <span class="toc-text">valgrind</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#intel-cmt-cat"><span class="toc-number">15.7.</span> <span class="toc-text">intel-cmt-cat</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#mellanox-nic-exapmle"><span class="toc-number">16.</span> <span class="toc-text">mellanox nic exapmle</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ixgbe-example"><span class="toc-number">17.</span> <span class="toc-text">ixgbe example</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#txqueueleng"><span class="toc-number">18.</span> <span class="toc-text">txqueueleng</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Enable-jumbo-frames"><span class="toc-number">18.1.</span> <span class="toc-text">Enable jumbo frames</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIC-receive-packages"><span class="toc-number">19.</span> <span class="toc-text">NIC receive packages</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Bottle-neck"><span class="toc-number">19.1.</span> <span class="toc-text">Bottle neck</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux-network-parameters"><span class="toc-number">20.</span> <span class="toc-text">Linux network parameters</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#TCP-control-algorithms"><span class="toc-number">20.1.</span> <span class="toc-text">TCP control algorithms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#The-others-parameters"><span class="toc-number">20.2.</span> <span class="toc-text">The others parameters</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-frto"><span class="toc-number">20.2.1.</span> <span class="toc-text">tcp_frto</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-window-scaling"><span class="toc-number">20.2.2.</span> <span class="toc-text">tcp_window_scaling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-win-scale"><span class="toc-number">20.2.3.</span> <span class="toc-text">tcp_win_scale</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-timestamps"><span class="toc-number">20.2.4.</span> <span class="toc-text">tcp_timestamps</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#keepalive"><span class="toc-number">20.2.5.</span> <span class="toc-text">keepalive</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-tw-reuse"><span class="toc-number">20.2.6.</span> <span class="toc-text">tcp_tw_reuse</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-sack"><span class="toc-number">20.2.7.</span> <span class="toc-text">tcp_sack</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#netfilter"><span class="toc-number">20.2.8.</span> <span class="toc-text">netfilter</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sysctl-conf"><span class="toc-number">21.</span> <span class="toc-text">sysctl.conf</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-syn-retries"><span class="toc-number">21.0.1.</span> <span class="toc-text">tcp_syn_retries</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><span class="toc-number">21.0.2.</span> <span class="toc-text">Enabling flow limits and tuning flow limit hash table size</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NFS-hangs-because-zero-window-problem"><span class="toc-number">22.</span> <span class="toc-text">NFS hangs because zero window problem</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#All-NFS-connection-are-hang-all-TCP-state-are-in-TIMEWAIT-status"><span class="toc-number">22.1.</span> <span class="toc-text">All NFS connection are hang, all TCP state are in TIMEWAIT status</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Monitor"><span class="toc-number">23.</span> <span class="toc-text">Monitor</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#kernel"><span class="toc-number">23.1.</span> <span class="toc-text">kernel</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ListenOverflows"><span class="toc-number"></span> <span class="toc-text">ListenOverflows</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#ListenDrops"><span class="toc-number"></span> <span class="toc-text">ListenDrops</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#nstat-got-value-from-proc-net-netstat"><span class="toc-number"></span> <span class="toc-text">nstat got value from &#x2F;proc&#x2F;net&#x2F;netstat</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-cores"><span class="toc-number"></span> <span class="toc-text">4 cores</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#in-some-overflow-status"><span class="toc-number"></span> <span class="toc-text">in some overflow status</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Full-throughput-duplex"><span class="toc-number"></span> <span class="toc-text">Full throughput duplex</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#when-I-was-watch-it-the-time-squeeze-not-increased-only-slowly-increasing-at-rx-steer-missed-packets-1623"><span class="toc-number">1.</span> <span class="toc-text">when I was watch it, the time_squeeze not increased. only slowly increasing at rx_steer_missed_packets: 1623</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#here-is-2-v-1-test-case-node-1-and-node-2-send-and-receive-to-node-3-there-is-no-tcp-retrans-in-node-little-0-5-s-but-it-was-full-throughput-bond-dual-port-tx-2-4GB-s-tx-2-4GB-s-only-a-lot-of-tcp-retrans-in-node-1-and-node-2-190-200-s"><span class="toc-number"></span> <span class="toc-text">here is 2 v 1 test case,  node 1 and node 2 send and receive to node 3, there is no tcp retrans in node(little , 0.5&#x2F;s), but it was full throughput (bond, dual port, tx:2.4GB&#x2F;s tx 2.4GB&#x2F;s), only a lot of tcp retrans in node 1 and node 2 (190~200&#x2F;s)</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#kernel-improved"><span class="toc-number">0.0.1.</span> <span class="toc-text">kernel improved</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Driver"><span class="toc-number">0.1.</span> <span class="toc-text">Driver</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#About-TCP-fast-retrans"><span class="toc-number">1.</span> <span class="toc-text">About TCP fast retrans</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ABout-TCP-segment-out-of-order"><span class="toc-number">1.0.1.</span> <span class="toc-text">ABout TCP segment out of order</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIC-receive-data"><span class="toc-number">2.</span> <span class="toc-text">NIC receive data</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NIC-lt-%E2%80%93-gt-driver"><span class="toc-number">2.1.</span> <span class="toc-text">NIC &lt;–&gt; driver</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#NIC-Data-Processing"><span class="toc-number">2.2.</span> <span class="toc-text">NIC Data Processing</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ring-buffer"><span class="toc-number">2.2.1.</span> <span class="toc-text">ring buffer</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#sriov-doc"><span class="toc-number">3.</span> <span class="toc-text">sriov doc</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PCI-init"><span class="toc-number">4.</span> <span class="toc-text">PCI init</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#softirq-Subsystem-Initialization"><span class="toc-number">5.</span> <span class="toc-text">softirq Subsystem Initialization</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ethtool-setting"><span class="toc-number">6.</span> <span class="toc-text">ethtool setting</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#overrun-and-dropped"><span class="toc-number">7.</span> <span class="toc-text">overrun and dropped</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#82599-limit"><span class="toc-number">8.</span> <span class="toc-text">82599 limit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CentOS-7-packet-dropped-because-virtual-memmory-performance"><span class="toc-number">9.</span> <span class="toc-text">CentOS 7 packet dropped because virtual memmory performance</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#memory-tuning"><span class="toc-number">9.1.</span> <span class="toc-text">memory tuning</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#page-allocation-failure-order-2-mode-0x4020"><span class="toc-number">9.1.1.</span> <span class="toc-text">page allocation failure. order:2, mode:0x4020</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#reduce-dirty-page-not-recommand-in-low-dirty-env"><span class="toc-number">9.1.2.</span> <span class="toc-text">reduce dirty page (not recommand in low dirty env)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#kmalloc-reserve"><span class="toc-number">9.1.3.</span> <span class="toc-text">kmalloc_reserve</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Looks-like-it-is-the-malloc-slow-cause-access-hang"><span class="toc-number">9.1.4.</span> <span class="toc-text">Looks like it is the malloc slow cause access hang</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#network-snmap-counter-nstat-z"><span class="toc-number">10.</span> <span class="toc-text">network snmap counter; nstat -z</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bonding-parameters"><span class="toc-number">11.</span> <span class="toc-text">bonding parameters</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Bandwidth-delay-product"><span class="toc-number">12.</span> <span class="toc-text">Bandwidth-delay product</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MTU"><span class="toc-number">13.</span> <span class="toc-text">MTU</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Deep-buffers-matter"><span class="toc-number">14.</span> <span class="toc-text">Deep buffers matter</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Deep-Buffers-Matter"><span class="toc-number">14.1.</span> <span class="toc-text">Deep Buffers Matter!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Buffer-utilisation-per-port"><span class="toc-number">14.2.</span> <span class="toc-text">Buffer utilisation per port</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Possible-SYN-flooding-on-port-xxx-Sending-cookies"><span class="toc-number">15.</span> <span class="toc-text">Possible SYN flooding on port xxx. Sending cookies</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Redhat-monitor-sh"><span class="toc-number">16.</span> <span class="toc-text">Redhat monitor.sh</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">无常无形无功;不动不破不空</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Ethernet nic tuning</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-06-01T02:49:42.000Z" title="Created 2018-06-01 10:49:42">2018-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-04-28T03:41:08.000Z" title="Updated 2021-04-28 11:41:08">2021-04-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Network/">Network</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h3 id="benchmark-NIC-pps"><a href="#benchmark-NIC-pps" class="headerlink" title="benchmark NIC pps"></a>benchmark NIC pps</h3><p>pkggen kernel mode,<br>No more diff between 1GbE with 10GbE (BCM57800)<br><a target="_blank" rel="noopener" href="https://lwn.net/Articles/629155/">The problem, Jesper said, is that the kernel developers have focused on scaling out to large numbers of cores. In the process, they have been able to hide regressions in per-core efficiency. The networking stack, as a result, works well for many workloads, but workloads that are especially latency-sensitive have suffered. The kernel, today, can only forward something between 1M and 2M packets per core every second, while some of the bypass alternatives approach a rate of 15M packets per core per second. Then there is the cost of performing a system call. On a system with SELinux and auditing enabled, that cost is just over 75ns — over the time budget on its own. Disabling auditing and SELinux reduces the time required to just under 42ns, which is better, but that is still a big part of the time budget. There are ways of amortizing that cost over multiple packets; they include system calls like sendmmsg(), recvmmsg(), sendfile(), and splice().</a></p>
<p>10GbE Full-duplex, about 2M</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Result: OK: 958748771(c958745900+d2871) usec, 2000000000 (42byte,0frags)</span><br><span class="line">  2086052pps 700Mb/sec (700913472bps) errors: 0</span><br><span class="line"></span><br><span class="line">Result: OK: 939714052(c939699215+d14836) usec, 2000000000 (42byte,0frags)</span><br><span class="line">  2128307pps 715Mb/sec (715111152bps) errors: 0</span><br><span class="line"></span><br><span class="line">pgset <span class="string">&quot;count 2000000000&quot;</span></span><br><span class="line">pgset <span class="string">&quot;delay 0&quot;</span></span><br><span class="line">pgset <span class="string">&quot;clone_skb 0&quot;</span></span><br><span class="line">pgset <span class="string">&quot;pkt_size 8&quot;</span></span><br></pre></td></tr></table></figure>

<p>1GbE Full-duplex, about 1.5M</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">pgset <span class="string">&quot;count 2000000000&quot;</span></span><br><span class="line">pgset <span class="string">&quot;delay 0&quot;</span></span><br><span class="line">pgset <span class="string">&quot;clone_skb 0&quot;</span></span><br><span class="line">pgset <span class="string">&quot;pkt_size 8&quot;</span></span><br><span class="line"></span><br><span class="line">Result: OK: 184502252(c184496912+d5340) usec, 274564113 (42byte,0frags)</span><br><span class="line">  1488134pps 500Mb/sec (500013024bps) errors: 0</span><br><span class="line"></span><br><span class="line">Result: OK: 183209415(c183209277+d138) usec, 272639542 (42byte,0frags)</span><br><span class="line">  1488130pps 500Mb/sec (500011680bps) errors: 0</span><br><span class="line"></span><br><span class="line"><span class="comment">## no more help modify buffer and queues.</span></span><br><span class="line">``e</span><br><span class="line"></span><br><span class="line"><span class="comment">### [Qlogic qede model](https://access.redhat.com/solutions/2898381)</span></span><br><span class="line">Got the qede NIC <span class="built_in">type</span></span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line">2f:00.0 Ethernet controller [0200]: QLogic Corp. FastLinQ QL41000 Series 10/25/40/50GbE Controller [1077:8070] (rev 02)</span><br><span class="line">2f:00.1 Ethernet controller [0200]: QLogic Corp. FastLinQ QL41000 Series 10/25/40/50GbE Controller [1077:8070] (rev 02)</span><br><span class="line"></span><br><span class="line">$ cat ~/fastlinq-8.50.25.0/qede-8.50.25.0/src/qede_main.c</span><br><span class="line"></span><br><span class="line"><span class="comment">#define CHIP_NUM_57980S_IOV             0x1664</span></span><br><span class="line"><span class="comment">#define CHIP_NUM_AH                     0x8070</span></span><br><span class="line"><span class="comment">#define CHIP_NUM_AH_IOV                 0x8090</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_57980S_IOV        CHIP_NUM_57980S_IOV</span></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_AH                CHIP_NUM_AH</span></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_AH_IOV            CHIP_NUM_AH_IOV</span></span><br></pre></td></tr></table></figure>

<h3 id="slot-status"><a href="#slot-status" class="headerlink" title="slot status"></a>slot status</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ 05:00.0 Ethernet controller: Intel Corporation Ethernet Controller XXV710 <span class="keyword">for</span> 25GbE SFP28 (rev 02)</span><br><span class="line">$ lspci -s 05:00.0 -vvv | grep -Ei <span class="string">&#x27;8G|MSI-X&#x27;</span></span><br><span class="line">      Capabilities: [70] MSI-X: Enable+ Count=129 Masked-</span><br><span class="line">              LnkCap: Port <span class="comment">#0, Speed 8GT/s, Width x8, ASPM L1, Latency L0 &lt;2us, L1 &lt;16us</span></span><br><span class="line">              LnkSta: Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br><span class="line"></span><br><span class="line"><span class="comment">## RSS support</span></span><br><span class="line">$ lspci -v -s 83:00.0 | grep <span class="string">&quot;MSI-X: Enable+&quot;</span></span><br><span class="line">83:00.0 Ethernet controller: Intel Corporation 82599ES 10-Gigabit SFI/SFP+ Network Connection (rev 01)</span><br><span class="line">        Flags: bus master, fast devsel, latency 0, IRQ 247, NUMA node 1</span><br><span class="line">        I/O ports at d020 [size=32]</span><br><span class="line">        Capabilities: [50] MSI: Enable- Count=1/1 Maskable+ 64bit+</span><br><span class="line">        Capabilities: [70] MSI-X: Enable+ Count=64 Masked-</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h3 id="THEORETICAL-MAXIMUM-RATE"><a href="#THEORETICAL-MAXIMUM-RATE" class="headerlink" title="THEORETICAL MAXIMUM RATE"></a><a target="_blank" rel="noopener" href="https://support-kb.spirent.com/resources/sites/SPIRENT/content/live/FAQS/10000/FAQ10597/en_US/How_to_Test_10G_Ethernet_WhitePaper_RevB.PDF">THEORETICAL MAXIMUM RATE</a></h3><p>There are two important concepts related to 10GbE performance: frame rate and throughput. The MAC bit rate of 10GbE, defined in the IEEE standard 802.3ae, is 10 billion bits per second. Frame rate is a simple arithmetic calculation based on the bit rate and frame format definitions. Throughput, defined in IETF RFC 1242, is the highest rate at which the system under test can forward the offered load, without loss. Manufacturers can claim line-rate throughput only if their switch forwards all the traffic offered at the 10Gb/s line rate for the entire duration of the test. The bit rate at which 10GbE Media Access Layer (MAC) operates, 10 billion bits per second, is only one of the parameters in defining the transmission rate for this important new technology. The usual description of true network performance is frame rate, which indicates how many Ethernet frames are moving across the network. The maximum frame rate for 10GbE is determined by a formula that divides the 10 billion bits per second by the preamble, frame length, and inter-frame gap fields, expressed in bits. The maximum frame rate is calculated using the minimum values of the following parameters, as described in the IEEE 802.3ae standard:</p>
<ul>
<li>Preamble - 8 bytes * 8 = 64 bits</li>
<li>Frame length - 64 bytes (minimum) * 8 = 512 bits</li>
<li>Inter-frame gap - 12 bytes (minimum) * 8 = 96 bits<br>Therefore,<br>Maximum Frame Rate =<br>MAC Transmit Bit Rate/<br>(Preamble + Frame Length + Inter-frame Gap)<br>= 10,000,000,000 / (64 + 512 + 96)<br>= 10,000,000,000 / 672<br>= 14,880,952.38 frame per second (fps)</li>
</ul>
<h3 id="About-FEC"><a href="#About-FEC" class="headerlink" title="About FEC"></a><a target="_blank" rel="noopener" href="https://solarflare.hammer-europe.com/assets/uploads/resources/QLogic%20-%20White%20Paper%20-%2025Gb%20Ethernet.pdf">About FEC</a></h3><p>IEEE 802.3 Standard Interfaces that Specify 25GbE</p>
<table>
<thead>
<tr>
<th align="center">Phy layer</th>
<th align="center">Name</th>
<th align="center">error Correction</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MMF Optics</td>
<td align="center">25GBASE-SR</td>
<td align="center">RS-FEC</td>
</tr>
<tr>
<td align="center">Direct Attach Copper</td>
<td align="center">25GBASE-CR</td>
<td align="center">BASE-R FEC or RS-FEC</td>
</tr>
<tr>
<td align="center">Direct Attach Copper</td>
<td align="center">25GBASE-CR-S</td>
<td align="center">BASE-R FEC or disabled</td>
</tr>
<tr>
<td align="center">Electrical Backplane</td>
<td align="center">25GBASE-KR</td>
<td align="center">BASE-R FEC or RS-FEC</td>
</tr>
<tr>
<td align="center">Electrical Backplane</td>
<td align="center">25GBASE-KR-S</td>
<td align="center">BASE-R FEC or disabled</td>
</tr>
<tr>
<td align="center">Twisted Pair</td>
<td align="center">25GBASE-T</td>
<td align="center">N/A</td>
</tr>
</tbody></table>
<p>The IEEE standard specifies two backplane and copper interfaces. These have different goals, hence the different interface. The –S short reach interfaces aim to support high-quality cables without Forward Error Correction (FEC) to minimize latency. Full reach interfaces aimto support the lowest possible cable or backplane cost and the longest possible reach, which do require the use of FEC. FEC options include BASE-R FEC (also referred to as Fire Code) and RS-FEC (also referred to as Reed-Solomon). RS-FEC has been used for a range of applications including data storage satellite transmissions. BASE-R FEC is a newer technology that is particularly well suited for correction of the burst errors<br>typical in a backplane channel resulting from error propagation in the receive equalizer.</p>
<p>IEEE 标准指定了两个底板和铜接口。这些接口的目标不同，因此接口存在不同。–S 短距离接口旨在支持无需转发纠错（FEC）的高质<br>量电缆，以最大限度地降低延迟。全距离接口旨在实现尽可能低的电缆或背板成本以及尽可能长的距离，这需要使用FEC。FEC 选项包<br>括 BASE-R FEC（也称为 Fire Code）和 RS-FEC（也称为 Reed-Solomon）。RS-FEC 已用于一系列应用，包括数据存储卫星传播。BASE-R FEC 是一种新型技术，特别适合纠正背板通道中由于接收均衡器的错误传播而导致的突发错误。</p>
<h3 id="CPU-setting"><a href="#CPU-setting" class="headerlink" title="CPU setting"></a>CPU setting</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cpupower  frequency-set -g performance</span><br><span class="line">cpupower idle-set -d 3</span><br><span class="line">cpupower idle-set -d 2</span><br><span class="line">cpupower idle-set -d 1</span><br><span class="line">cpupower idle-set -d 0</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line"></span><br><span class="line">$ cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_max_freq</span><br><span class="line">$ cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get local cpus</span></span><br><span class="line">$ cat /sys/class/net/eth7/device/local_cpus</span><br><span class="line">0000,000fffc0,00000000,0fffc000</span><br></pre></td></tr></table></figure>

<h3 id="nic-offload"><a href="#nic-offload" class="headerlink" title="nic offload"></a>nic offload</h3><table>
<thead>
<tr>
<th>Features</th>
<th>status</th>
</tr>
</thead>
<tbody><tr>
<td>TSO TCP Segmentation Offload</td>
<td>hardware on</td>
</tr>
<tr>
<td>GSO Generic Segmentation Offload,soft TSO</td>
<td>software off</td>
</tr>
<tr>
<td>GRO Generic Receive Offload/LRO</td>
<td>hardware on, options ixgbe LRO=1</td>
</tr>
<tr>
<td>UFO UDP Fragmentation Offload</td>
<td>hardware off fixed</td>
</tr>
<tr>
<td>rx-checksumming</td>
<td>hardware on</td>
</tr>
<tr>
<td>tx-checksumming</td>
<td>hardware on</td>
</tr>
<tr>
<td>scatter-gather</td>
<td>hardware on</td>
</tr>
<tr>
<td>RSS Receive side scaling</td>
<td>hardware on</td>
</tr>
<tr>
<td>RPS software RSS</td>
<td>software off</td>
</tr>
<tr>
<td>RFS Receive Flow Streering,UDP support ?</td>
<td>software on</td>
</tr>
<tr>
<td>XPS Transmit Packet Steering</td>
<td>software on</td>
</tr>
<tr>
<td>busy-poll: on fixed</td>
<td>hw and sw, work with sysctl.net.core.busy_poll &gt; 0</td>
</tr>
</tbody></table>
<p>TSO = LSO (also called large segmentation offload)<br>RFS and XPS has the same function from receive or transmit, avoid cache miss, numa overhead<br>Receive Packet Steering (RPS) is logically a software implementation of RSS<br>Generic segmentation offload (GSO) is logically a software implementation of TSO</p>
<p>if TSO was on, disable GSO, same with RSS and RPS</p>
<p>Enabling the RFS requires enabling the ‘ntuple’ flag via the ethtool,RFS requires the kernel to be compiled with the CONFIG_RFS_ACCEL option. This options is available in kernels 2.6.39 and above. Furthermore, RFS requires Device Managed Flow Steering support.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;-----softirq&lt;--RPS-| CPU_core</span><br><span class="line">&lt;-----softirq&lt;--RPS---CPU_core &lt;---interrupt--- rx queue &lt;---RSS---NIC &lt;---packages</span><br><span class="line">&lt;-----softirq&lt;--RPS---CPU_core &lt;---interrupt--- rx queue &lt;---RSS---NIC &lt;---packages</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool --offload enp5s0 rx on tx on</span><br><span class="line">Actual changes:</span><br><span class="line">rx-checksumming: on</span><br><span class="line">tx-checksumming: on</span><br><span class="line">	tx-checksum-ipv4: on</span><br><span class="line">	tx-checksum-ipv6: on</span><br><span class="line">tcp-segmentation-offload: on</span><br><span class="line">	tx-tcp-segmentation: on</span><br><span class="line">	tx-tcp6-segmentation: on</span><br><span class="line"></span><br><span class="line"><span class="comment"># enable TSO</span></span><br><span class="line"><span class="comment"># If your NIC not support TSO, you could enable GSO</span></span><br><span class="line">$ ethtool -K enp4s0 tso on</span><br><span class="line">$ ethtool -K enp4s0 gso off</span><br><span class="line">$ ethtool -K ethX rx on  <span class="comment">## rx-checksuming tcp offload</span></span><br><span class="line">$ ethtool -K ethX sg on  <span class="comment">## tcp-sgmentation offloading</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#In case “tx-nocache-copy” is enabled, (this is the case for some kernels, e.g. kernel 3.10, which is the default for RH7.0) “tx-nocache-copy” should be disabled.</span></span><br><span class="line">$ ethtool -K ethX tx-nocache-copy off</span><br></pre></td></tr></table></figure>
<p><a href="(https://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters_Archive.pdf">100GbE setting</a></p>
<h4 id="Resize-the-hardware-buffer-queue-to-max"><a href="#Resize-the-hardware-buffer-queue-to-max" class="headerlink" title="Resize the hardware buffer queue to max"></a>Resize the hardware buffer queue to max</h4><p>Reduce the number of packets being dropped by increasing the size of the queue so that the it does not overflow as easily</p>
<p>big buffer will cause high latency with the throughput setting</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -G enp1s0f0 RX 4096 TX 4096</span><br><span class="line">$ ethtool -g enp1s0f0</span><br><span class="line">Ring parameters <span class="keyword">for</span> enp1s0f0:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:		4096</span><br><span class="line">RX Mini:	0</span><br><span class="line">RX Jumbo:	0</span><br><span class="line">TX:		4096</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:		4096</span><br><span class="line">RX Mini:	0</span><br><span class="line">RX Jumbo:	0</span><br><span class="line">TX:		4096</span><br></pre></td></tr></table></figure>

<h4 id="setting-driver"><a href="#setting-driver" class="headerlink" title="setting driver"></a>setting driver</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/modprobe.d/ixgbe.conf</span><br><span class="line">options ixgbe allow_unsupported_sfp=1,1</span><br><span class="line">options ixgbe MQ=1,1 RSS=8,8 <span class="comment"># I don &#x27;t think too many CPU is a good setting</span></span><br><span class="line">options ixgbe LRO=1</span><br><span class="line">options ixgbe InterruptThrottleRate=20000,20000</span><br><span class="line"></span><br><span class="line"><span class="comment"># unsupport optical module</span></span><br><span class="line">$ modprobe ixgbe allow_unsupported_sfp=1,1</span><br></pre></td></tr></table></figure>
<p>MQ:Disable or enable Multiple Queues, default 1 (array of int)<br>RSS:Number of Receive-Side Scaling Descriptor Queues, default 0=number of cpus (array of int)<br>InterruptThrottleRate:Maximum interrupts per second, per vector, (0,1,956-488281), default 1 (array of int)<br>LRO:Large Receive Offload (0,1), default 0 = off (array of int)</p>
<h3 id="Interrupt-Queues"><a href="#Interrupt-Queues" class="headerlink" title="Interrupt Queues"></a>Interrupt Queues</h3><h4 id="Busy-Polling"><a href="#Busy-Polling" class="headerlink" title="Busy Polling"></a>Busy Polling</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">                        high-latency</span><br><span class="line">interrupt-based -----------------------------&gt; poll-based</span><br></pre></td></tr></table></figure>

<p>Busy polling helps reduce latency in the network receive path by allowing socket layer code to poll the receive queue of a network device, and disabling network interrupts. </p>
<p><code>This removes delays caused by the interrupt and the resultant context switch.</code><br>However, <code>it also increases CPU utilization</code>. Busy polling also prevents the CPU from sleeping, which can incur additional power consumption.</p>
<p>single queue map single cpu core, avoid lock or race cpu resource </p>
<p>kernel 3.11 support SO_BUSY_POLL<br>Busy polling is disabled by default (sysctl.net.core.busy_poll = 0)<br>This parameter controls the number of microseconds to wait for packets on the device queue for socket poll and selects. Red Hat recommends a value of 50</p>
<p>To enable busy polling globally<br>you must also set sysctl.net.core.busy_read to a value other than 0.<br>This parameter controls the number of microseconds to wait for packets on the device queue for socket reads.<br>It also sets the default value of the SO_BUSY_POLL option. </p>
<p>Red Hat recommends a value of 50 for a small number of sockets, and a value of 100 for large numbers of sockets. For extremely large numbers of sockets (more than several hundred), use epoll(kernel 4.12) instead.</p>
<p><a target="_blank" rel="noopener" href="https://oxnz.github.io/2016/05/03/performance-tuning-networking/">Busy polling helps reduce latency in the network receive path by</a></p>
<ul>
<li>allowing socket layer code to poll the receive queue of a network device </li>
<li>and disable network interrupts</li>
</ul>
<p>delays caused by the interrupts and the resultant context switches<br>increses CPU utilization.Also prevent the CPU from sleeping, which can incur additional power comsumption.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sw</span></span><br><span class="line">net.core.busy_poll = 50 <span class="comment"># default 0</span></span><br><span class="line">net.core.busy_read = 100 <span class="comment"># default 0, redhat recommand only 50</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#hw</span></span><br><span class="line">$ ethtool -k device | grep <span class="string">&quot;busy-poll&quot;</span></span><br><span class="line">busy-poll: on [fixed]</span><br></pre></td></tr></table></figure>

<p>Busy polling behavior is supported by the following drivers. These drivers are also supported on Red Hat Enterprise Linux 7.1<br>driver support: bnx2x,be2net,ixgbe,mlx4,myri10ge</p>
<p>mlx4 driver with busy polling</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rx-usecs: 16</span><br><span class="line">rx-frames: 44</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://www.cnhalo.net/2017/07/24/linux-busy-poll/">netperf TCP_RR 1 byte payload each way, 3.11 kernel,default 17500tps, busy poll could reach 6300tps</a></p>
<h3 id="Socket-receive-queues"><a href="#Socket-receive-queues" class="headerlink" title="Socket receive queues"></a>Socket receive queues</h3><h4 id="Change-the-speed-of-the-incoming-queue"><a href="#Change-the-speed-of-the-incoming-queue" class="headerlink" title="Change the speed of the incoming queue"></a>Change the speed of the incoming queue</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/net/core/dev_weight</span><br><span class="line">64</span><br><span class="line"><span class="comment">#64 was default value</span></span><br></pre></td></tr></table></figure>

<p>The maximum number of packets that kernel can handle on a NAPI interrupt, it’s a Per-CPU variable. For drivers that support LRO HW or GRO_HW, a hardware aggregated packet is counted as one packet in this context</p>
<p>Altering the drain rate of a queue is usually the simplest way to mitigate poor network performance. However, increasing the number of packets that a device can receive at one time uses additional processor time, during which no other processes can be scheduled, so this can cause other performance problems</p>
<p>Device weight refers to the number of packets a device can receive at one time (in a single scheduled processor access). You can increase the rate at which a queue is drained by increasing its device weight, which is controlled by the dev_weight parameter.</p>
<p>it will increase CPU overhead</p>
<p>Altering the drain rate of a queue is usually the simplest way to mitigate poor network performance. However, increasing the number of packets that a device can receive at one time uses additional processor time, during which no other processes can be scheduled, so this can cause other performance problems.</p>
<h5 id="Increase-the-depth-of-the-application’s-socket-queue"><a href="#Increase-the-depth-of-the-application’s-socket-queue" class="headerlink" title="Increase the depth of the application’s socket queue"></a>Increase the depth of the application’s socket queue</h5><p>Increase the value of /proc/sys/net/core/rmem_default</p>
<ul>
<li>Decrease the speed of incoming traffic<ul>
<li>filter</li>
<li>dropping</li>
<li>lower devcei weight</li>
</ul>
</li>
<li>Increse the depth of the application’s socket queue (not a long-term solution)</li>
</ul>
<p>This parameter controls the default size of the receive buffer used by sockets. This value must be smaller than or equal to the value of /proc/sys/net/core/rmem_max.</p>
<p>This parameter controls the maximum size in bytes of a socket’s receive buffer. Use getsockopt to get current value</p>
<h4 id="Use-setsockopt-to-configure-a-larger-SO-RCVBUF-value-userspace"><a href="#Use-setsockopt-to-configure-a-larger-SO-RCVBUF-value-userspace" class="headerlink" title="Use setsockopt to configure a larger SO_RCVBUF value (userspace)"></a>Use setsockopt to configure a larger SO_RCVBUF value (userspace)</h4><p>This parameter controls the maximum size in bytes of a socket’s receive buffer. Use the getsockopt system call to determine the current value of the buffer.</p>
<h4 id="RSS-IRQ-Affinity"><a href="#RSS-IRQ-Affinity" class="headerlink" title="RSS IRQ Affinity"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/2144921">RSS IRQ Affinity</a></h4><p>Get the PCIE device numa node</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/class/net/[interface]/device/numa_node</span><br><span class="line">$ cat /sys/devices/[PCI root]/[PCIe <span class="keyword">function</span>]/numa_node</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>CPU</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody><tr>
<td>bin</td>
<td>0001</td>
<td>0010</td>
<td>0100</td>
<td>1000</td>
<td>10000</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Deci</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>8</td>
<td>16</td>
<td>32</td>
<td>64</td>
<td>128</td>
<td>256</td>
<td>512</td>
<td>1024</td>
<td>2048</td>
<td>4096</td>
</tr>
<tr>
<td>Hex</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>8</td>
<td>10</td>
<td>20</td>
<td>40</td>
<td>80</td>
<td>100</td>
<td>200</td>
<td>400</td>
<td>800</td>
<td>1000</td>
</tr>
</tbody></table>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">printf</span> <span class="string">&#x27;%x\n&#x27;</span> <span class="string">&quot;<span class="subst">$((2#10101010101)</span>)&quot;</span></span><br><span class="line">555 <span class="comment">#numa_node0</span></span><br><span class="line"></span><br><span class="line">$ awk -F: <span class="string">&#x27;$0~/enp5/ || $0~/mlx4/ &#123;print $1&#125;&#x27;</span> /proc/interrupts | <span class="keyword">while</span> <span class="built_in">read</span> line</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> 555 &gt; /proc/irq/<span class="variable">$line</span>/smp_affinity</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#For example, to handle interrupts with CPUs 0, 1, 2, and 3, set the value of rps_cpus to f, which is the hexadecimal value for 15. In binary representation, 15 is 00001111 (1+2+4+8).</span></span><br><span class="line"></span><br><span class="line">or you could</span><br><span class="line">/sys/class/net</span><br><span class="line">eno1 -&gt; ../../devices/pci0000:17/0000:17:02.0/0000:18:00.0/net/eno1</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0</span><br><span class="line">$ ls /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0/msi_irqs</span><br><span class="line">56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85</span><br><span class="line">$ ls -l /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0/msi_irqs</span><br><span class="line"></span><br><span class="line"><span class="comment">#intel</span></span><br><span class="line">$ set_irq_affinity -x all ethX</span><br><span class="line">$ set_irq_affinity -x <span class="built_in">local</span> ethX</span><br><span class="line">$ set_irq_affinity 1-2 ethX</span><br><span class="line"></span><br><span class="line"><span class="comment">#mellanox</span></span><br><span class="line">set_irq_affinity_bynode.sh 0 p7p1</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">printf</span> %0.2x<span class="string">&#x27;\n&#x27;</span> 1024</span><br><span class="line">400</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">printf</span> %0.2x<span class="string">&#x27;\n&#x27;</span> 4096</span><br><span class="line">1000</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> 400 &gt; /proc/irq/66/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 400 &gt; /proc/irq/67/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 1000 &gt; /proc/irq/69/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 1000 &gt; /proc/irq/70/smp_affinity</span><br></pre></td></tr></table></figure>
<p>When configuring RSS, Red Hat recommends <code>limiting the number of queues to one per physical CPU core</code><br>Hyper-threads are often represented as separate cores in analysis tools, but configuring queues for all cores including logical cores such as <code>hyper-threads has not proven beneficial to network performance</code></p>
<p>When enabled, RSS distributes network processing equally between available CPUs based on the amount of processing each CPU has queued. However, you can use the ethtool –show-rxfh-indir and –set-rxfh-indir parameters to modify how network activity is distributed, and weight certain types of network activity as more important than others.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool --set-rxfh-indir enp1s0f0 equal 4</span><br><span class="line">$ watch -d  -n 1 <span class="string">&quot;cat /proc/interrupts | grep enp1s0f0&quot;</span></span><br><span class="line"><span class="comment"># You could see only 4 interrupt number increase a lot</span></span><br><span class="line"></span><br><span class="line">$ ethtool --show-rxfh-indir enp1s0f0</span><br><span class="line">$ ethtool -x enp1s0f0</span><br><span class="line"><span class="comment">## You can set priority for each queue.</span></span><br><span class="line">RX flow <span class="built_in">hash</span> indirection table <span class="keyword">for</span> p4p1 with 48 RX ring(s):</span><br><span class="line">    0:      0     1     2     3     4     5     6     7</span><br><span class="line">    8:      8     9    10    11    12    13    14    15</span><br><span class="line">   16:     16    17    18    19    20    21    22    23</span><br><span class="line">   24:     24    25    26    27    28    29    30    31</span><br><span class="line">   32:     32    33    34    35    36    37    38    39</span><br><span class="line">   40:     40    41    42    43    44    45    46    47</span><br><span class="line">   48:      0     1     2     3     4     5     6     7</span><br><span class="line">   56:      8     9    10    11    12    13    14    15</span><br><span class="line">   64:     16    17    18    19    20    21    22    23</span><br><span class="line">   72:     24    25    26    27    28    29    30    31</span><br><span class="line">   80:     32    33    34    35    36    37    38    39</span><br><span class="line">   88:     40    41    42    43    44    45    46    47</span><br><span class="line">   96:      0     1     2     3     4     5     6     7</span><br><span class="line">  104:      8     9    10    11    12    13    14    15</span><br><span class="line">  112:     16    17    18    19    20    21    22    23</span><br><span class="line">  120:     24    25    26    27    28    29    30    31</span><br><span class="line"><span class="comment">### 16 (line) x 8 (column) = 128, total 128 value, that means indirection table = 128, total 48 RX rings</span></span><br><span class="line"><span class="comment">### eg: line &quot;96:&quot; second field(1), means 98th hash data equal 2, the data will go to second queue</span></span><br><span class="line"><span class="comment">### ethtool -X eth0 weight 6 5 4 3 2 1 .... , you can set 48 x weights, 48 data sum will not large than 128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set weight for the queue</span></span><br><span class="line">$ ethtool --set-rxfh-indir eth3 weight 6 2</span><br><span class="line">$ ethtool --set-rxfh-indir eth3 weight 1 2</span><br></pre></td></tr></table></figure>

<p><code>The irqbalance daemon can be used in conjunction with RSS to reduce the likelihood of cross-node memory transfers and cache line bouncing. This lowers the latency of processing network packets.</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl <span class="built_in">enable</span> irqbalance</span><br><span class="line">$ systemctl start irqbalance</span><br><span class="line"><span class="comment"># debug irqblaance</span></span><br><span class="line">$ irqbalance -d -f</span><br></pre></td></tr></table></figure>

<h5 id="Support-for-UDP-RSS"><a href="#Support-for-UDP-RSS" class="headerlink" title="Support for UDP RSS"></a><a target="_blank" rel="noopener" href="https://downloadmirror.intel.com/22919/eng/README.txt">Support for UDP RSS</a></h5><p>   rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6<br>     Retrieves the hash options for the specified network traffic type.</p>
<p>  -N –config-nfc<br>     Configures the receive network flow classification.</p>
<p>   rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6<br>   m|v|t|s|d|f|n|r…<br>     Configures the hash options for the specified network traffic type.</p>
<pre><code> udp4    UDP over IPv4
 udp6    UDP over IPv6

 f   Hash on bytes 0 and 1 of the Layer 4 header of the rx packet.
 n   Hash on bytes 2 and 3 of the Layer 4 header of the rx packet.</code></pre>
<p>The following is an example using udp4 (UDP over IPv4):</p>
<p>  To include UDP port numbers in RSS hashing run:</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ethtool</span> -N ethX rx-flow-hash udp<span class="number">4</span> sdfn</span><br></pre></td></tr></table></figure>

<p>  To exclude UDP port numbers from RSS hashing run:</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ethtool</span> -N ethX rx-flow-hash udp<span class="number">4</span> sd</span><br></pre></td></tr></table></figure>

<p>  To display UDP hashing current configuration run:</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">ethtool</span> -n ethX rx-flow-hash udp<span class="number">4</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/performance_tuning_guide/index">redhat performance tuning guide</a><br><a target="_blank" rel="noopener" href="https://fasterdata.es.net/host-tuning/100g-tuning/">100GbE tuning</a><br><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/www/public/us/en/documents/reference-guides/xl710-x710-performance-tuning-linux-guide.pdf">xl710-x710-performance-tuning-linux-guide</a></p>
<p>Receive Packet Steering (RPS) is similar to RSS in that it is used to direct packets to specific CPUs for processing. However, RPS is implemented at the software level, and helps to prevent the hardware queue of a single network interface card from becoming a bottleneck in network traffic.<br>Does the all cpu cores share a  hardware-based receive queues ?</p>
<h3 id="Receive-Flow-Streering-RFS"><a href="#Receive-Flow-Streering-RFS" class="headerlink" title="Receive Flow Streering (RFS)"></a>Receive Flow Streering (RFS)</h3><p>Receive Flow Steering (RFS) extends RPS/RSS behavior to increase the CPU cache hit rate and thereby reduce network latency. Where RPS forwards packets based solely on queue length, RFS uses the RPS backend to calculate the most appropriate CPU, then forwards packets based on the location of the application consuming the packet. This increases CPU cache efficiency.</p>
<p>RFS is disabled by default. To enable RFS, you must edit two files:<br>/proc/sys/net/core/rps_sock_flow_entries</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">echo</span> 32768 &gt; /proc/sys/net/core/rps_sock_flow_entries</span><br><span class="line">$ <span class="keyword">for</span> f <span class="keyword">in</span> /sys/class/net/ens6/queues/rx-*/rps_flow_cnt; <span class="keyword">do</span> <span class="built_in">echo</span> 4096 &gt; <span class="variable">$f</span>; <span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>Set the value of this file to the maximum expected number of concurrently active connections. We recommend a value of 32768 for moderate server loads. All values entered are rounded up to the nearest power of 2 in practice.</p>
<p>Set the value of this file to the value of rps_sock_flow_entries divided by N, where N is the number of receive queues on a device. For example, if rps_flow_entries is set to 32768 and there are 16 configured receive queues, rps_flow_cnt should be set to 2048(I improve it to 4096). For single-queue devices, the value of rps_flow_cnt is the same as the value of rps_sock_flow_entries.</p>
<p>Data received from a single sender is not sent to more than one CPU. If the amount of data received from a single sender is greater than a single CPU can handle, configure a larger frame size to reduce the number of interrupts and therefore the amount of processing work for the CPU.</p>
<p>About large frame </p>
<ul>
<li>large mtu</li>
<li>TCP Segmentation Offload, merge to large than mtu size</li>
</ul>
<p>Consider using numactl or taskset in conjunction with RFS to pin applications to specific cores, sockets, or NUMA nodes. This can help prevent packets from being processed out of order.</p>
<h5 id="Accelerated-RFS"><a href="#Accelerated-RFS" class="headerlink" title="Accelerated RFS"></a>Accelerated RFS</h5><p>RFS and accelerated RFS (aRFS) are kernel features currently available in most distributions. The aRFS feature requires explicit configuration in order to enable it.<br>it need the driver support</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_RFS_ACCEL=y</span><br><span class="line">CONFIG_MLX5_EN_ARFS=y</span><br></pre></td></tr></table></figure>

<p>Accelerated RFS boosts the speed of RFS by adding hardware assistance. Like RFS, packets are forwarded based on the location of the application consuming the packet. Unlike traditional RFS, however, packets are sent directly to a CPU that is local to the thread consuming the data: either the CPU that is executing the application, or a CPU local to that CPU in the cache hierarchy.<br>Accelerated RFS is only available if the following conditions are met:<br>Accelerated RFS must be supported by the network interface card. Accelerated RFS is supported by cards that export the ndo_rx_flow_steer() netdevice function.<br>ntuple filtering must be enabled.</p>
<p>CPU to queue mapping is deduced based on the IRQ affinities configured by the driver for each receive queue.</p>
<ol>
<li>RFS enabled</li>
<li>CONFIG_RFS_ACCEL enabled</li>
<li>Enable ntuple</li>
<li>Configure your IRQ settings to ensure each RX queue is handled by one of your desired network processing CPUs.</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># default ATR （automated Application Targeting Routing）</span></span><br><span class="line">$ ethtool -K ens6 ntuple on</span><br><span class="line">$ ethtool -k ens6</span><br><span class="line">ntuple-filters: on</span><br><span class="line">$ systemctl stop irqbalance</span><br><span class="line"><span class="comment">#Configure your IRQ settings to ensure each RX queue is handled by one of your desired network processing CPUs.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## Custom policy</span></span><br><span class="line">$ ethtool -u eth0</span><br><span class="line">40 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"><span class="comment">### dest port 80 go to rx queue 2</span></span><br><span class="line">$ ethtool -U eth0 flow-type tcp4 dst-port 80 action 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># if you are mellanox NIC</span></span><br><span class="line">$ show_irq_affinity.sh ens6</span><br><span class="line"></span><br><span class="line"><span class="comment">### Custom policy, EP(Externally Programed) mode</span></span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type ip4 src-ip 192.168.100.1  action -1</span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type tcp4 src-port 80  action 2</span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type udp4 src-port 80  action 2</span><br><span class="line"></span><br><span class="line"><span class="comment">#To specify that all traffic from 10.23.4.6 to 10.23.4.18 be placed in queue 4, issue this command:</span></span><br><span class="line">$ ethtool --config-ntuple flow-type tcp4 src-ip 10.23.4.6 dst-ip 10.23.4.18 action 4</span><br><span class="line"></span><br><span class="line"><span class="comment">#Forwards to queue 2 all IPv4 TCP traffic from 192.168.10.1:2000 that is going to 192.168.10.2:2001, placing the filter at position 33 of the Perfect-Match filter table (and overwriting any rule currently in that position):</span></span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 src-port 2000 dst-port 2001 action 2 loc 33</span><br><span class="line"></span><br><span class="line"><span class="comment">#Drops all UDP packets from 10.4.83.2:</span></span><br><span class="line">$ ethtool --config-ntuple flow-type udp4 src-ip 10.4.82.2 action -1</span><br><span class="line"><span class="comment">#Note: The VLAN field is not a supported filter with the i40e driver (Intel Ethernet Controller XL710 and Intel Ethernet Controller X710 NICs).</span></span><br><span class="line"><span class="comment">#For more information and options, see the ethtool man page documentation on the -U, -N, or --config-ntuple option.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List</span></span><br><span class="line">$ ethtool --show-ntuple p2p1</span><br><span class="line">10 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove</span></span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; delete N</span><br><span class="line"></span><br><span class="line"><span class="comment"># There&#x27;s generic flow steering rule configuration interface on ethtool, called RX NFC.</span></span><br><span class="line">$ ethtool --config-nfc ix00 flow-type tcp4 src-ip 10.0.0.1 dst-ip 10.0.0.2 src-port 10000 dst-port 10001 action 6</span><br><span class="line">Added rule with ID 2045</span><br><span class="line">$ ethtool --show-nfc ix00</span><br><span class="line">12 RX rings available</span><br><span class="line">Total 1 rules</span><br><span class="line">Filter: 2045</span><br><span class="line">     Rule Type: TCP over IPv4</span><br><span class="line">     Src IP addr: 10.0.0.1 mask: 0.0.0.0</span><br><span class="line">     Dest IP addr: 10.0.0.2 mask: 0.0.0.0</span><br><span class="line">     TOS: 0x0 mask: 0xff</span><br><span class="line">     Src port: 10000 mask: 0x0</span><br><span class="line">     Dest port: 10001 mask: 0x0</span><br><span class="line">     VLAN EtherType: 0x0 mask: 0xffff</span><br><span class="line">     VLAN: 0x0 mask: 0xffff</span><br><span class="line">     User-defined: 0x0 mask: 0xffffffffffffffff</span><br><span class="line">     Action: Direct to queue 6</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/howto-configure-arfs-on-connectx-4">monitor</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -S eno1 | egrep rx.*pack</span><br><span class="line"><span class="comment"># disable</span></span><br><span class="line">$ ethtool -K ens6 ntuple off</span><br><span class="line"></span><br><span class="line">$ taskset -c 5 netserver &amp;</span><br><span class="line">$ netperf -H <span class="variable">$ipaddr</span> -l 200 -t TCP_STREAM &amp;</span><br><span class="line"></span><br><span class="line">$ ethtool -S ens6 | egrep rx.*pack</span><br><span class="line"><span class="comment"># only rx8 improved</span></span><br><span class="line">rx7_packets: 0</span><br><span class="line">rx7_lro_packets: 0</span><br><span class="line">rx8_packets: 6296748</span><br><span class="line">rx8_lro_packets: 0</span><br><span class="line">rx9_packets: 0</span><br><span class="line"></span><br><span class="line">$ ethtool -K ens6 ntuple on</span><br><span class="line">$ taskset -c 5 netserver &amp;</span><br><span class="line">$ netperf -H 11.134.201.5 -l 200 -t TCP_STREAM &amp;</span><br><span class="line">$ ethtool -S ens6 | egrep rx.*pack</span><br><span class="line">rx5_packets: 234532 <span class="comment"># only rx5 increase, it ‘s worked</span></span><br><span class="line">rx5_lro_packets: 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># mellanox enable the driver arfs</span></span><br><span class="line">$ enable_arfs.sh ens6</span><br></pre></td></tr></table></figure>

<h3 id="Interrupt-Moderation-interrupt-coalescence-or-Interrupt-Blanking"><a href="#Interrupt-Moderation-interrupt-coalescence-or-Interrupt-Blanking" class="headerlink" title="Interrupt Moderation (interrupt coalescence or Interrupt Blanking)"></a>Interrupt Moderation (interrupt coalescence or Interrupt Blanking)</h3><p>parm:           InterruptThrottleRate:Maximum interrupts per second, per vector, (0,1,956-488281), default 1 (array of int) </p>
<p>0 = Setting InterruptThrottleRate to 0 turns off any interrupt moderation and may improve small packet latency, but is generally not suitable for bulk throughput traffic due to the increased cpu utilization of the higher interrupt rate. Please note that on 82599-based adapters, disabling InterruptThrottleRate will also result in the driver disabling HW RSC(receive side coalescing).</p>
<p>HW RSC looks like TCP Segmentation offload or GSO, merge 1500~9000 mtu to a large frame(65536 or more), you could get it by tcpdump</p>
<p>On 82598-based adapters, disabling InterruptThrottleRate will also result in disabling LRO (Large Receive Offloads).</p>
<p>1 = Dynamic mode attempts to moderate interrupts per vector while maintaining very low latency. <code>This can sometimes cause extra CPU utilization.</code><br>If planning on deploying ixgbe in a latency sensitive environment please consider this parameter.</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ modprobe ixgbe InterruptThrottleRate=<span class="number">8000</span>,<span class="number">4000</span></span><br></pre></td></tr></table></figure>
<p>956-488281, Interrupt Throttle Rate (interrupts/sec). The ITR parameter controls how many interrupts each interrupt vector can generate per second. On MQ/RSS enabled kernels with MSI-X interrupts this means that each RX vector can generate 8000 interrupts per second and each TX vector can generate 4000 interrupts per second. Increasing ITR lowers latency at the cost of increased CPU utilization, though it may help throughput in some circumstances.</p>
<p><code>Note: Adaptive moderation must be disabled in order to ensure that static values are in use.</code><br>It is possible to change the values for ethtool as well:</p>
<p>Mellanox example</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -C eth4 rx-usecs <span class="number">0</span> rx-frames <span class="number">10</span> tx-usecs <span class="number">16</span> tx-frames <span class="number">100</span></span><br><span class="line">$ ethtool -c eth4</span><br></pre></td></tr></table></figure>
<p>if you need to improve value of rx-usecs, improve latency and througput, and suggestion improve </p>
<figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#must tso could be enabled</span></span><br><span class="line">$ ethtool -K eth2 tso <span class="keyword">on</span> </span><br><span class="line">$ net.ipv4.tcp_tso_win_divisor = <span class="number">30</span> <span class="comment">#default 3</span></span><br></pre></td></tr></table></figure>
<p>This allows control over what percentage of the congestion window can be consumed by a single TSO frame. The setting of this parameter is a choice between burstiness and building larger TSO frames.</p>
<p>rx-frames[-irq] rx-usecs[-irq] tx-frames[-irq] tx-usecs[-irq]<br>The range of 0-235 microseconds provides an effective range of 4,310 to 250,000 interrupts per second. The value of rx-µsecs-high can be set independent of rx-µsecs and tx-µsecs in the same ethtool command, and is also independent of the adaptive interrupt moderation algorithm. The underlying hardware supports granularity in 2-microsecond intervals, so adjacent values might result in the same interrupt rate.</p>
<p>DIM is enabled by default. In case you wish to disable it. in some spcical case, you will modify these interrupt options<br><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/dynamically-tuned-interrupt-moderation--dim-x">not recommended disable Dynamically Interrupt Moderation</a></p>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/usingethtoolrates.html">adaptive-rx Dynamic control to decrease RX latency at low packet rates and increase throughput at high packet rates</a></li>
<li>rx-usecs This is the number of microseconds to wait before raising an RX interrupt after a packet has been received. When rx-usecs is set to 0 rx-frames is used</li>
<li>rx-frames     This is the number of frames to queue up before raising an RX interrupt.</li>
<li>adaptive-tx Dynamic control to decrease TX latency at low packet rates and increase throughput at high packet rates</li>
<li>tx-usecs This is the number of microseconds to wait before raising an TX interrupt after a packet has been sent. When tx-usecs is set to 0 tx-frames is used</li>
<li>tx-frames This is the number of frames to queue up before raising an TX interrupt</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#To turn on adaptive interrupt moderation, recommand</span></span><br><span class="line">$ ethtool -C ethX adaptive-rx on adaptive-tx on</span><br><span class="line"></span><br><span class="line"><span class="comment">#To turn off adaptive interrupt moderation</span></span><br><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off</span><br></pre></td></tr></table></figure>

<p>A good place to start for general tuning is 84 µs, or ~12000 interrupts/s. If you see rx_dropped counters are running during traffic (using ethtool -S ethX) then you probably have too slow of a CPU, not enough buffers from the adapter’s ring size (ethtool -G) to hold packets for 84 µs or to low of an interrupt rate.<br>That mean CPU too slower or kernel handler too slower.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off rx-usecs 84 tx-usecs 84</span><br></pre></td></tr></table></figure>

<p>The next value to try, if you are not maxed out on CPU utilization, is 62 µs. This uses more CPU, but it services buffers faster, and requires fewer descriptors (ring size, ethtool -G). </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off rx-usecs 62 tx-usecs 62</span><br></pre></td></tr></table></figure>
<p>If your CPU is at 100%, then increasing the interrupt rate is not advised. In certain circumstances such as a CPU bound workload, you might want to increase the µs value to enable more CPU time for other applications.</p>
<p>If you require low latency performance and/or have plenty of CPU to devote to network processing, you can disable interrupt moderation entirely, which enables the interrupts to fire as fast as possible.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off rx-usecs 0 tx-usecs 0</span><br></pre></td></tr></table></figure>
<p>Totaly, tx,rx-usecs value the lower means the smaller frame to interrupt moderation. the more cpu overhead and the lower latency<br>increase tx,tx-usecs that means high latency and get the biger frame to interrupt moderation, the lower cpu overhead and high latency and high througput, it will impact tcp performance, so increase tcp_tso_win_divisor to 30</p>
<p>If cache pressure is suspected (many queues active) reducing buffers from default can help Intel® Data Direct I/O (Intel® DDIO) operate with better efficiently. Intel recommends trying 128 or 256 per queue, being aware that an increase in interrupt rate via ethtool -C might be necessary to avoid an increase in rx_dropped.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -G eth12 rx 256 tx 256</span><br></pre></td></tr></table></figure>

<p>Change the Tx and Rx ring sizes as needed, a larger value takes more resources but can provide better forwarding rates:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -G ethX rx 4096 tx 4096</span><br></pre></td></tr></table></figure>

<p>Layer 2 flow control can impact TCP performance considerably and is recommended to be disabled for most workloads</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -A ethX rx off tx off</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -c enp4s0d1</span><br><span class="line">Coalesce parameters <span class="keyword">for</span> enp4s0d1:</span><br><span class="line">Adaptive RX: off  TX: off</span><br><span class="line">stats-block-usecs: 0</span><br><span class="line">sample-interval: 0</span><br><span class="line">pkt-rate-low: 400000</span><br><span class="line">pkt-rate-high: 450000</span><br><span class="line"></span><br><span class="line">rx-usecs: 0</span><br><span class="line">rx-frames: 0</span><br><span class="line">rx-usecs-irq: 0</span><br><span class="line">rx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">tx-usecs: 8</span><br><span class="line">tx-frames: 16</span><br><span class="line">tx-usecs-irq: 0</span><br><span class="line">tx-frames-irq: 256</span><br><span class="line"></span><br><span class="line">rx-usecs-low: 0</span><br><span class="line">rx-frame-low: 0</span><br><span class="line">tx-usecs-low: 0</span><br><span class="line">tx-frame-low: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-high: 128</span><br><span class="line">rx-frame-high: 0</span><br><span class="line">tx-usecs-high: 0</span><br><span class="line">tx-frame-high: 0</span><br><span class="line"></span><br><span class="line">$ ethtool -i p5p2</span><br><span class="line">driver: i40e</span><br><span class="line">version: 2.4.6</span><br><span class="line">firmware-version: 6.01 0x80003554 1.1747.0</span><br><span class="line">bus-info: 0000:05:00.1</span><br><span class="line">supports-statistics: yes</span><br><span class="line">supports-test: yes</span><br><span class="line">supports-eeprom-access: yes</span><br><span class="line">supports-register-dump: yes</span><br><span class="line">supports-priv-flags: yes</span><br><span class="line"></span><br><span class="line">$ ethtool -l p5p2</span><br><span class="line">Channel parameters <span class="keyword">for</span> p5p2:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:             0</span><br><span class="line">TX:             0</span><br><span class="line">Other:          1</span><br><span class="line">Combined:       64</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:             0</span><br><span class="line">TX:             0</span><br><span class="line">Other:          1</span><br><span class="line">Combined:       8</span><br><span class="line"></span><br><span class="line">$ ethtool -L enp1s0f1 combined 8  <span class="comment">#combined means tx and rx</span></span><br><span class="line">$ ethtool -L enp1s0f1 rx 8 </span><br><span class="line"></span><br><span class="line">$ ethtool -x eth0</span><br><span class="line"><span class="comment"># check rx flow hash indirection table for eth0</span></span><br><span class="line"></span><br><span class="line">$ ethtool -g p5p2</span><br><span class="line">Ring parameters <span class="keyword">for</span> p5p2:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:             4096</span><br><span class="line">RX Mini:        0</span><br><span class="line">RX Jumbo:       0</span><br><span class="line">TX:             4096</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:             512</span><br><span class="line">RX Mini:        0</span><br><span class="line">RX Jumbo:       0</span><br><span class="line">TX:             512</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://download.01.org/packet-processing/ONPS2.1/Intel_ONP_Release_2.1_Performance_Test_Report_Rev1.0.pdf">Intel_ONP_Release_2.1_performance_test_report</a></p>
<h3 id="disable-PCIE-power-save"><a href="#disable-PCIE-power-save" class="headerlink" title="disable PCIE power save"></a>disable PCIE power save</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;pcie_aspm=off&#x27;</span> --args=<span class="string">&#x27;intel_idle.max_cstate=0&#x27;</span> --args=<span class="string">&#x27;processor.max_cstate=1&#x27;</span></span><br></pre></td></tr></table></figure>

<h4 id="disable-numa"><a href="#disable-numa" class="headerlink" title="disable numa"></a>disable numa</h4><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">$ </span>echo kernel.numa_balancing=0 &gt;&gt; <span class="regexp">/etc/sysctl</span>.conf</span><br><span class="line"><span class="variable">$ </span>sysctl -p</span><br></pre></td></tr></table></figure>

<h3 id="RFC2544-stipulates-that-the-latency-test"><a href="#RFC2544-stipulates-that-the-latency-test" class="headerlink" title="RFC2544 stipulates that the latency test"></a>RFC2544 stipulates that the latency test</h3><ul>
<li>Should be at least 120 seconds in duration</li>
<li>Frame sizes to be used on Ethernet 64, 128, 256, 512, 1024, 1280, and 1518</li>
<li>Should include an identifying tag in one frame after 60 seconds with the type of tag being implementation dependent</li>
<li>Records the time at which the frame is fully transmitted (timestamp A)</li>
<li>The receiver logic in the test equipment must recognize the tag information in the frame stream and record the time at which the tagged frame was received (timestamp B)</li>
<li>This test should be performed with the test frame addressed to the same destination as the rest of the data stream, and also with each of the test frames addressed to a new destination network</li>
<li>The test must be repeated at least 20 times with the reported value being the average of the recorded values</li>
<li>The latency is timestamp B minus timestamp A, as per the relevant definition from RFC</li>
</ul>
<h3 id="The-network-latency"><a href="#The-network-latency" class="headerlink" title="The network latency"></a><a target="_blank" rel="noopener" href="https://www.marvell.com/documents/rjx203ukari4r93gntem/">The network latency</a></h3><p>There are new technologies that are pushing latencies into the singledigit microsecond range when measured back-to-back in benchmark<br>repeat 20 times and get the average result</p>
<p>50 – 125μs   1Gb Ethernet (TCP/IP)</p>
<ul>
<li>Multi-tasking: multiple highbandwidth applications running<br>simultaneously</li>
<li>Bulk data transfer</li>
<li>Transactional database backup and<br>applications</li>
<li>Web (front-end for data centers)</li>
</ul>
<p>5 – 50μs 10Gb Ethernet<br>(TCP/IP)</p>
<ul>
<li>Bulk data transfer</li>
<li>Real-time video streaming</li>
<li>Database backup and applications</li>
</ul>
<p>3 – 5μs RDMA, RoCEE, and<br>iWARP</p>
<ul>
<li>High Performance Computing</li>
<li>High-Frequency Trading (HFT)</li>
<li>Inter-process communication (IPC)<br>cluster</li>
<li>Low-latency applications</li>
</ul>
<p>Sub-3μs(less than 3μs) InfiniBand (QDR)<br>and proprietary</p>
<ul>
<li>High Performance Computing</li>
<li>High Frequency Trading (HFT)</li>
<li>Ultra-low latency applications</li>
</ul>
<h3 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h3><h4 id="nc-test"><a href="#nc-test" class="headerlink" title="nc test"></a>nc test</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Server $ nc -l 22222 &lt; /dev/zero</span><br><span class="line">Client $ nc <span class="variable">$serverip</span> 22222 &gt; /dev/null</span><br><span class="line">Client $ nc <span class="variable">$serverip</span> 22222 | pv  <span class="comment"># show the speed</span></span><br></pre></td></tr></table></figure>

<h4 id="iperf3"><a href="#iperf3" class="headerlink" title="iperf3"></a>iperf3</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Server $ iperf3 -s -D -p 520<span class="variable">$i</span></span><br><span class="line">Client $ iperf3 -c <span class="variable">$client_ip</span> -P 1 -t 360000 -p 520<span class="variable">$i</span></span><br></pre></td></tr></table></figure>

<h4 id="qperf"><a href="#qperf" class="headerlink" title="qperf"></a>qperf</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Server $ qperf -lp <span class="variable">$port</span> &amp;</span><br><span class="line">Client $ qperf -lp <span class="variable">$port</span> -t 36000 -oo msg_size:1K:4K:*2 <span class="variable">$server_ip</span> tcp_bw </span><br><span class="line"><span class="comment">#or</span></span><br><span class="line">Client $ qperf -lp <span class="variable">$port</span> -t 60 -oo msg_size:64:1024K:*4 <span class="variable">$server_ip</span> tcp_lat</span><br></pre></td></tr></table></figure>

<h4 id="netperf"><a href="#netperf" class="headerlink" title="netperf"></a>netperf</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Server $ taskset -c 5 netserver &amp;</span><br><span class="line">Client $ netperf -H <span class="variable">$ipaddr</span> -l 200 -t TCP_STREAM </span><br><span class="line"></span><br><span class="line">Server $ numactl -C 2 netserver -D  -4 -v 2 -p 5000 -f -L 192.168.12.201</span><br><span class="line">Client $ numactl -N 0 ./netperf -n 6 -p 5000 -H 192.168.12.201 -c -C -t TCP_STREAM -l 15 -T 2,2 -- -m $((<span class="number">2</span>**<span class="variable">$i</span>))</span><br><span class="line">Client $ numactl -N 0 ./netperf -n 6 -p 5000 -H 192.168.12.201 -c -C -t TCP_RR -l 20 -T 2,2 -- -m $((<span class="number">2</span>**<span class="variable">$i</span>))</span><br><span class="line">Client $ numactl -N 0 ./netperf -n 6 -p 5000 -H 192.168.12.201 -c -C -t UDP_RR -l 20 -T 2,2 -- -m $((<span class="number">2</span>**<span class="variable">$i</span>))</span><br></pre></td></tr></table></figure>

<h4 id="sockperf"><a href="#sockperf" class="headerlink" title="sockperf"></a>sockperf</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">./sockperf<span class="built_in"> server </span>--tcp -p 11111</span><br><span class="line">./sockperf<span class="built_in"> server </span>-p 11111 #udp</span><br><span class="line">numactl -C 2 /opt/sockperf/bin/sockperf tp -m 256  -i 192.168.12.201 -p 11111 -t 20</span><br><span class="line">numactl -C 2 /opt/sockperf/bin/sockperf pp -m 256  -i 192.168.12.201 -p 11111 -t 20</span><br></pre></td></tr></table></figure>

<h4 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Server $ LD_PRELOAD=libvma.so VMA_STATS_FD_NUM=500 redis-server --port 7777  --protected-mode no --maxmemory 12000mb --maxmemory-samples 10 --maxmemory-policy allkeys-lru</span><br><span class="line">Client $ numactl -C 2 redis-benchmark -r 10000000 -n 20000000 -t get,<span class="built_in">set</span>,lpush,lpop -P 16 -q -h 192.168.12.201 -p 7777 -d 16</span><br></pre></td></tr></table></figure>

<h3 id="RFC6349-TCP-benchmark"><a href="#RFC6349-TCP-benchmark" class="headerlink" title="RFC6349 TCP benchmark"></a><a target="_blank" rel="noopener" href="https://www.viavisolutions.com/zh-cn/literature/rfc-6349-testing-truespeed-viavi-solutions-experience-your-network-your-custom-application-notes-zh.pdf">RFC6349 TCP benchmark</a></h3><ul>
<li><p>RFC 4821 through PLPMTUD make sure network path mtu</p>
</li>
<li><p>benchmark RRT(Round-Trip Time) and BB(bottle neck bandwidth)</p>
<ul>
<li><p>example:RRT=25ms, bandwidth=45Mbps, window=64KB, receiver take 12.5ms to sender<br>BDP(bandwidth-delay product) = BB * RRT /8 = 140.625 KB, double sender ‘s window size</p>
</li>
<li><p>TCP global synchronization</p>
</li>
<li><p>RWND(Receive Window)</p>
</li>
<li><p>CWND(Congestion Window)</p>
</li>
<li><p>LFN(Long fat network)</p>
</li>
<li><p>RTD(round-trip delay time)</p>
</li>
<li><p>TDP(Tail drop polocy)</p>
</li>
<li><p>tcp transfer time</p>
<ul>
<li>In the 500Mbps netowrk, start 5x transmit services, each transmit means 100Mbps, actually, the 5 x tansmit bandwith are not balancing. 5 x sender transfer 100MB file.<ul>
<li>500MB/(500Mbps/8)=8 sec, in fact, the test use 12sec, that means 12sec/8sec=1.5, 1.5x late than the theoretically</li>
</ul>
</li>
</ul>
</li>
<li><p>tcp efficiency</p>
<ul>
<li>(total bytes - retrans bytes)/total bytes * 100 = 98%, in our data center , there are 2 percent tcp retrans. that too bad in some times.</li>
</ul>
</li>
<li><p>tcp cache latency percent, (test average rrt - base rrt)/base rrt * 100, if base rrt= 25ms, in the test, the average rrt=32ms, (32-25)/25*100=28%, tcp RTD increase 28%(congestion)</p>
</li>
</ul>
</li>
<li><p>if the tcp performance not reach your expect</p>
<ul>
<li>re-gen tcp connection, and modify tcp rwnd size, mtu size</li>
<li>speed limit cause tail drop polocy and cause too many tcp retrans</li>
<li>the maximum tcp cache size, it limit by OS memory size, and to check tcp queue</li>
<li>socket buffer size, a lot of OS could modify the each connection receive and transmit buffer limit. the socket buffer must be large enough.</li>
</ul>
</li>
</ul>
<h4 id="irqbalance"><a href="#irqbalance" class="headerlink" title="irqbalance"></a>irqbalance</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">--powerthresh </span></span><br><span class="line"><span class="comment">--hintpolicy </span></span><br><span class="line"><span class="comment">--policyscript </span></span><br><span class="line"><span class="comment">--banirq</span></span><br><span class="line"><span class="comment">--ban </span></span><br><span class="line"><span class="comment">--balance_level </span></span><br><span class="line"><span class="comment">--numa_node</span></span><br></pre></td></tr></table></figure>

<h4 id="turbostat"><a href="#turbostat" class="headerlink" title="turbostat"></a>turbostat</h4><h4 id="numastat"><a href="#numastat" class="headerlink" title="numastat"></a>numastat</h4><h4 id="numad"><a href="#numad" class="headerlink" title="numad"></a>numad</h4><h4 id="OProfile"><a href="#OProfile" class="headerlink" title="OProfile"></a>OProfile</h4><h4 id="valgrind"><a href="#valgrind" class="headerlink" title="valgrind"></a>valgrind</h4><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">valgrind <span class="attribute">--tool</span>=memcheck <span class="attribute">--leak-check</span>=<span class="literal">yes</span> <span class="attribute">--show-reachable</span>=<span class="literal">yes</span> <span class="attribute">--num-callers</span>=20 <span class="attribute">--track-fds</span>=<span class="literal">yes</span> ./lustre_exporter</span><br></pre></td></tr></table></figure>

<h4 id="intel-cmt-cat"><a href="#intel-cmt-cat" class="headerlink" title="intel-cmt-cat"></a>intel-cmt-cat</h4><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ yum install <span class="built_in">int</span>el-cmt-cat.x86_64</span><br><span class="line"></span><br><span class="line">TIME <span class="number">2020</span><span class="number">-01</span><span class="number">-07</span> <span class="number">17</span>:<span class="number">54</span>:<span class="number">05</span></span><br><span class="line">           LLC(Last Level Cache): CMT(Cache Monitoring Technology) Cache Occupancy </span><br><span class="line">           MBL:MBM local bandwidth</span><br><span class="line">           MBR:MBM Remote bandwidth                             </span><br><span class="line">$ pqos</span><br><span class="line">    CORE   IPC   MISSES     LLC[KB]   MBL[MB/s]   MBR[MB/s]</span><br><span class="line">                                            </span><br><span class="line">       <span class="number">0</span>  <span class="number">0.26</span>       <span class="number">6</span>k      <span class="number">1080.0</span>         <span class="number">0.2</span>         <span class="number">0.0</span></span><br><span class="line">       <span class="number">1</span>  <span class="number">0.26</span>       <span class="number">0</span>k         <span class="number">0.0</span>         <span class="number">0.0</span>         <span class="number">0.0</span></span><br><span class="line">       <span class="number">2</span>  <span class="number">0.27</span>       <span class="number">4</span>k      <span class="number">4600.0</span>         <span class="number">0.5</span>         <span class="number">0.0</span></span><br><span class="line">       <span class="number">3</span>  <span class="number">0.26</span>       <span class="number">5</span>k       <span class="number">520.0</span>         <span class="number">0.0</span>         <span class="number">0.2</span></span><br><span class="line">       <span class="number">4</span>  <span class="number">0.27</span>       <span class="number">8</span>k      <span class="number">1120.0</span>         <span class="number">0.7</span>         <span class="number">0.1</span></span><br><span class="line">       <span class="number">5</span>  <span class="number">0.25</span>      <span class="number">12</span>k      <span class="number">1080.0</span>         <span class="number">0.7</span>         <span class="number">0.2</span></span><br><span class="line">       <span class="number">6</span>  <span class="number">0.28</span>      <span class="number">18</span>k      <span class="number">1040.0</span>         <span class="number">0.9</span>         <span class="number">0.1</span></span><br><span class="line">       <span class="number">7</span>  <span class="number">0.25</span>       <span class="number">0</span>k         <span class="number">0.0</span>         <span class="number">0.0</span>         <span class="number">0.0</span></span><br><span class="line">       <span class="number">8</span>  <span class="number">0.27</span>       <span class="number">4</span>k      <span class="number">3400.0</span>         <span class="number">0.2</span>         <span class="number">0.1</span></span><br><span class="line">       <span class="number">9</span>  <span class="number">0.25</span>       <span class="number">0</span>k      <span class="number">1360.0</span>         <span class="number">0.1</span>         <span class="number">0.1</span></span><br><span class="line">      <span class="number">10</span>  <span class="number">0.26</span>      <span class="number">14</span>k      <span class="number">7000.0</span>         <span class="number">1.3</span>         <span class="number">0.0</span></span><br><span class="line">      <span class="number">11</span>  <span class="number">0.39</span>       <span class="number">1</span>k       <span class="number">120.0</span>         <span class="number">0.0</span>         <span class="number">0.0</span></span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://github.com/intel/intel-cmt-cat/wiki/Usage-Examples">Usage-example</a></p>
<p>Cache Monitoring Technology (CMT)<br>Cache Allocation Technology (CAT)<br>Memory Bandwidth Monitoring (MBM)<br>Memory Bandwidth Allocation (MBA)<br>Code and Data Prioritization (CDP)</p>
<h3 id="mellanox-nic-exapmle"><a href="#mellanox-nic-exapmle" class="headerlink" title="mellanox nic exapmle"></a>mellanox nic exapmle</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">ethtool</span> <span class="string">-k</span>  <span class="string">enp131s0f1</span></span><br><span class="line"><span class="attr">Features for enp131s0f1:</span></span><br><span class="line"><span class="attr">rx-checksumming:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-checksumming:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-checksum-ipv4:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-checksum-ip-generic:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line">	<span class="attr">tx-checksum-ipv6:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-checksum-fcoe-crc:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line">	<span class="attr">tx-checksum-sctp:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">scatter-gather:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-scatter-gather:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-scatter-gather-fraglist:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tcp-segmentation-offload:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-tcp-segmentation:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-tcp-ecn-segmentation:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line">	<span class="attr">tx-tcp6-segmentation:</span> <span class="string">on</span></span><br><span class="line">	<span class="attr">tx-tcp-mangleid-segmentation:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">udp-fragmentation-offload:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">generic-segmentation-offload:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">generic-receive-offload:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">large-receive-offload:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">rx-vlan-offload:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-vlan-offload:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">ntuple-filters:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">receive-hashing:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">highdma:</span> <span class="string">on</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">rx-vlan-filter:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">vlan-challenged:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-lockless:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">netns-local:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-gso-robust:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-fcoe-segmentation:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-gre-segmentation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-ipip-segmentation:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-sit-segmentation:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-udp_tnl-segmentation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">fcoe-mtu:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-nocache-copy:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">loopback:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">rx-fcs:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">rx-all:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">tx-vlan-stag-hw-insert:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">rx-vlan-stag-hw-parse:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">rx-vlan-stag-filter:</span> <span class="string">on</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">busy-poll:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">tx-gre-csum-segmentation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-udp_tnl-csum-segmentation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-gso-partial:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">tx-sctp-segmentation:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">rx-gro-hw:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">l2-fwd-offload:</span> <span class="string">off</span> [<span class="string">fixed</span>]</span><br><span class="line"><span class="attr">hw-tc-offload:</span> <span class="string">off</span></span><br><span class="line"><span class="attr">rx-udp_tunnel-port-offload:</span> <span class="string">on</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">ethtool</span> <span class="string">-i</span> <span class="string">enp131s0f1</span></span><br><span class="line"><span class="attr">driver:</span> <span class="string">mlx5_core</span></span><br><span class="line"><span class="attr">version:</span> <span class="number">5.0</span><span class="number">-0</span></span><br><span class="line"><span class="attr">firmware-version:</span> <span class="number">14.20</span><span class="number">.1010</span> <span class="string">(MT_2420110034)</span></span><br><span class="line"><span class="attr">expansion-rom-version:</span></span><br><span class="line"><span class="attr">bus-info:</span> <span class="number">0000</span><span class="string">:83:00.1</span></span><br><span class="line"><span class="attr">supports-statistics:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">supports-test:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">supports-eeprom-access:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">supports-register-dump:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">supports-priv-flags:</span> <span class="literal">yes</span></span><br><span class="line"></span><br><span class="line"><span class="string">ethtool</span> <span class="string">-g</span> <span class="string">enp131s0f1</span></span><br><span class="line"><span class="attr">Ring parameters for enp131s0f1:</span></span><br><span class="line"><span class="attr">Pre-set maximums:</span></span><br><span class="line"><span class="attr">RX:</span>		<span class="number">8192</span></span><br><span class="line"><span class="attr">RX Mini:</span>	<span class="number">0</span></span><br><span class="line"><span class="attr">RX Jumbo:</span>	<span class="number">0</span></span><br><span class="line"><span class="attr">TX:</span>		<span class="number">8192</span></span><br><span class="line"><span class="attr">Current hardware settings:</span></span><br><span class="line"><span class="attr">RX:</span>		<span class="number">8192</span></span><br><span class="line"><span class="attr">RX Mini:</span>	<span class="number">0</span></span><br><span class="line"><span class="attr">RX Jumbo:</span>	<span class="number">0</span></span><br><span class="line"><span class="attr">TX:</span>		<span class="number">8192</span></span><br><span class="line"></span><br><span class="line"><span class="string">ethtool</span> <span class="string">-i</span> <span class="string">enp131s0f1</span></span><br><span class="line"><span class="attr">driver:</span> <span class="string">mlx5_core</span></span><br><span class="line"><span class="attr">version:</span> <span class="number">5.0</span><span class="number">-0</span></span><br><span class="line"><span class="attr">firmware-version:</span> <span class="number">14.20</span><span class="number">.1010</span> <span class="string">(MT_2420110034)</span></span><br><span class="line"><span class="attr">expansion-rom-version:</span></span><br><span class="line"><span class="attr">bus-info:</span> <span class="number">0000</span><span class="string">:83:00.1</span></span><br><span class="line"><span class="attr">supports-statistics:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">supports-test:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">supports-eeprom-access:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">supports-register-dump:</span> <span class="literal">no</span></span><br><span class="line"><span class="attr">supports-priv-flags:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure>

<h3 id="ixgbe-example"><a href="#ixgbe-example" class="headerlink" title="ixgbe example"></a>ixgbe example</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -g enp1s0f0</span><br><span class="line">Ring parameters <span class="keyword">for</span> enp1s0f0:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:		4096</span><br><span class="line">RX Mini:	0</span><br><span class="line">RX Jumbo:	0</span><br><span class="line">TX:		4096</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:		4096</span><br><span class="line">RX Mini:	0</span><br><span class="line">RX Jumbo:	0</span><br><span class="line">TX:		4096</span><br><span class="line"></span><br><span class="line">$ ethtool -i enp1s0f0</span><br><span class="line">driver: ixgbe</span><br><span class="line">version: 5.5.2</span><br><span class="line">firmware-version: 0x800006da, 255.65535.255</span><br><span class="line">expansion-rom-version:</span><br><span class="line">bus-info: 0000:01:00.0</span><br><span class="line">supports-statistics: yes</span><br><span class="line">supports-test: yes</span><br><span class="line">supports-eeprom-access: yes</span><br><span class="line">supports-register-dump: yes</span><br><span class="line">supports-priv-flags: yes</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Features <span class="keyword">for</span> enp1s0f0:</span><br><span class="line">rx-checksumming: on</span><br><span class="line">tx-checksumming: on</span><br><span class="line">	tx-checksum-ipv4: off [fixed]</span><br><span class="line">	tx-checksum-ip-generic: on</span><br><span class="line">	tx-checksum-ipv6: off [fixed]</span><br><span class="line">	tx-checksum-fcoe-crc: on [fixed]</span><br><span class="line">	tx-checksum-sctp: on</span><br><span class="line">scatter-gather: on</span><br><span class="line">	tx-scatter-gather: on</span><br><span class="line">	tx-scatter-gather-fraglist: off [fixed]</span><br><span class="line">tcp-segmentation-offload: on</span><br><span class="line">	tx-tcp-segmentation: on</span><br><span class="line">	tx-tcp-ecn-segmentation: off [fixed]</span><br><span class="line">	tx-tcp6-segmentation: on</span><br><span class="line">	tx-tcp-mangleid-segmentation: off</span><br><span class="line">udp-fragmentation-offload: off [fixed]</span><br><span class="line">generic-segmentation-offload: on</span><br><span class="line">generic-receive-offload: on</span><br><span class="line">large-receive-offload: off    </span><br><span class="line">rx-vlan-offload: on</span><br><span class="line">tx-vlan-offload: on</span><br><span class="line">ntuple-filters: off</span><br><span class="line">receive-hashing: on</span><br><span class="line">highdma: on [fixed]</span><br><span class="line">rx-vlan-filter: on</span><br><span class="line">vlan-challenged: off [fixed]</span><br><span class="line">tx-lockless: off [fixed]</span><br><span class="line">netns-local: off [fixed]</span><br><span class="line">tx-gso-robust: off [fixed]</span><br><span class="line">tx-fcoe-segmentation: on [fixed]</span><br><span class="line">tx-gre-segmentation: on</span><br><span class="line">tx-ipip-segmentation: off [fixed]</span><br><span class="line">tx-sit-segmentation: off [fixed]</span><br><span class="line">tx-udp_tnl-segmentation: on</span><br><span class="line">fcoe-mtu: off [fixed]</span><br><span class="line">tx-nocache-copy: off</span><br><span class="line">loopback: off [fixed]</span><br><span class="line">rx-fcs: off [fixed]</span><br><span class="line">rx-all: off</span><br><span class="line">tx-vlan-stag-hw-insert: off [fixed]</span><br><span class="line">rx-vlan-stag-hw-parse: off [fixed]</span><br><span class="line">rx-vlan-stag-filter: off [fixed]</span><br><span class="line">busy-poll: on [fixed]</span><br><span class="line">tx-gre-csum-segmentation: on</span><br><span class="line">tx-udp_tnl-csum-segmentation: on</span><br><span class="line">tx-gso-partial: on</span><br><span class="line">tx-sctp-segmentation: off [fixed]</span><br><span class="line">rx-gro-hw: off [fixed]</span><br><span class="line">l2-fwd-offload: off [fixed]</span><br><span class="line">hw-tc-offload: off</span><br><span class="line">rx-udp_tunnel-port-offload: on</span><br></pre></td></tr></table></figure>

<h3 id="txqueueleng"><a href="#txqueueleng" class="headerlink" title="txqueueleng"></a>txqueueleng</h3><p><a target="_blank" rel="noopener" href="https://www.nas.nasa.gov/assets/pdf/papers/NAS_Technical_Report_NAS-2014-01.pdf">This queue parameter is mostly applicable for high-speed WAN transfers. For low-latency networks, the default setting of 1000 is sufficient. The receiving end is configured with the sysctl setting net.core.netdev_max_backlog. The default for this setting is also 1000 and does not need to be modified unless there is significant latency.</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip link <span class="built_in">set</span> dev enp5s0 txqueuelen 1000</span><br><span class="line">ip link <span class="built_in">set</span> dev enp5s0d1 txqueuelen 1000</span><br><span class="line">ip link <span class="built_in">set</span> dev bond0 txqueuelen 2000</span><br></pre></td></tr></table></figure>

<h4 id="Enable-jumbo-frames"><a href="#Enable-jumbo-frames" class="headerlink" title="Enable jumbo frames"></a><a target="_blank" rel="noopener" href="http://ehealth-aussie.blogspot.com/2011/11/in-depth-look-into-path-mtu-discovery.html">Enable jumbo frames</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_mtu_probing = 1</span><br><span class="line">net.ipv4.tcp_base_mss = 512</span><br><span class="line">net.ipv4.ip_no_pmtu_disc = 0</span><br></pre></td></tr></table></figure>

<h3 id="NIC-receive-packages"><a href="#NIC-receive-packages" class="headerlink" title="NIC receive packages"></a><a target="_blank" rel="noopener" href="https://oxnz.github.io/2016/05/03/performance-tuning-networking/">NIC receive packages</a></h3><p>packet -&gt; NIC -&gt; internal hardware buffer or ring buffer -&gt; hardware interrupt request -&gt; software interrupt operation -&gt;<br>from buffer to network stack -&gt; forwarded/discarded/rejected/passed to a socket receive queue for an application -&gt;<br>remove from network stack until no packets left in NIC buffer or a certain number of packets are transferred (/proc/sys/net/core/dev_weight)</p>
<h4 id="Bottle-neck"><a href="#Bottle-neck" class="headerlink" title="Bottle neck"></a>Bottle neck</h4><ul>
<li><p>The NIC hardware buffer or ring buffer</p>
</li>
<li><p>The hardware or software interrupt queues</p>
</li>
<li><p>The socket receive queue for the application</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">eno1</span>: flags=<span class="number">6211</span>&lt;UP,BROADCAST,RUNNING,SLAVE,MULTICAST&gt;  mtu <span class="number">9000</span></span><br><span class="line">        <span class="attribute">ether</span> e<span class="number">4</span>:<span class="number">43</span>:<span class="number">4</span>b:<span class="number">08</span>:<span class="number">41</span>:e<span class="number">2</span>  txqueuelen <span class="number">1000</span>  (Ethernet)</span><br><span class="line">        <span class="attribute">RX</span> packets <span class="number">104934573253</span>  bytes <span class="number">236357913149742</span> (<span class="number">214</span>.<span class="number">9</span> TiB)</span><br><span class="line">        <span class="attribute">RX</span> errors <span class="number">0</span>  dropped <span class="number">228</span>  overruns <span class="number">0</span>  frame <span class="number">0</span></span><br><span class="line">        <span class="attribute">TX</span> packets <span class="number">311616323933</span>  bytes <span class="number">1529707025808932</span> (<span class="number">1</span>.<span class="number">3</span> PiB)</span><br><span class="line">        <span class="attribute">TX</span> errors <span class="number">0</span>  dropped <span class="number">0</span> overruns <span class="number">0</span>  carrier <span class="number">0</span>  collisions <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>RX</p>
<pre><code>  * frame/length counts only misaligned frames, it means frames with a length not divisible by 8. Because of that length is not a valid frame and it is simply discarded (too-short frames and too-long frames)

  * overruns/fifo counts that times when there is fifo overruns
          * caused by the rate at which the buffer gets full and the kernel isn&#39;t able to reclaim the buffer
          * No cpu resource, interrupt not balance and not affinity, eg: all nic interrupt in core0

  * [dropped(normal) counts](https://serverfault.com/questions/528290/ifconfig-eth0-rx-dropped-packets/601186)
          * Softnet backlog full
          * Bad / Unintended VLAN tags
          * Unknown / Unregistered protocols
          * IPv6 frames when the server is not configured for IPv6

  * dropped (in my opinion)
          * Overloading
          * Hardware issue
                  * NIC ring buffer too slower
                  * NIC/optical module issue
                  * PCIE issue
                  * Bad cable</code></pre>
</li>
<li><p><a target="_blank" rel="noopener" href="http://blog.hyfather.com/blog/2013/03/04/ifconfig/">TX</a></p>
<pre><code>  *  aborted transmission
  *  errors due to carrirer
  *  fifo err
  *  heartbeat erros
  *  window err
  *  collisions is the number of transmissions terminated due to CSMA/CD (Carrier Sense Multiple Access with Collision Detection).</code></pre>
</li>
</ul>
<p>The number of collisions tells us how many packets (ethernet frames) ended up colliding (being put on the network medium at the same time as) other packets, the result being that each of them would have to be recalled and resent by their respective network interfaces shortly afterwards. A high collision rate would indicate that the network is very busy, possibly overloaded. The more collisions you have, the more packets have to be resent, the more traffic you have and so on.</p>
<h3 id="Linux-network-parameters"><a href="#Linux-network-parameters" class="headerlink" title="Linux network parameters"></a>Linux network parameters</h3><h4 id="TCP-control-algorithms"><a href="#TCP-control-algorithms" class="headerlink" title="TCP control algorithms"></a>TCP control algorithms</h4><ul>
<li>cubic</li>
<li>reno</li>
<li>htcp<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_congestion_control=htcp</span><br><span class="line">net.ipv4.tcp_low_latency=0</span><br></pre></td></tr></table></figure></li>
<li>bbr for the bad network env<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_low_latency=1</span><br><span class="line">net.ipv4.tcp_congestion_control=bbr</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="The-others-parameters"><a href="#The-others-parameters" class="headerlink" title="The others parameters"></a>The others parameters</h4><h5 id="tcp-frto"><a href="#tcp-frto" class="headerlink" title="tcp_frto"></a>tcp_frto</h5><p>tcp_frto (integer; default: 0; since Linux 2.4.21/2.6)<br>Enable  F-RTO,  an enhanced recovery algorithm for TCP retrans‐mission timeouts (RTOs).   It  is  particularly  beneficial  in wireless  environments  where  packet  loss is typically due to random radio interference rather than intermediate router  con‐gestion.  See RFC 4138 for more details.<br>              This file can have one of the following values:<br>              0  Disabled.<br>              1  The basic version F-RTO algorithm is enabled.<br>              2  Enable  SACK-enhanced  F-RTO  if  flow uses SACK.  The basic version can be used also when SACK is in use though in  that case scenario(s) exists where F-RTO interacts badly with the packet counting of the SACK-enabled TCP flow.</p>
<p>In some of a lot of tcp-retrans in our LAN, but I have not permission to what happend in network switch, I ‘m just do my best to avoid it in linux kernel</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_frto=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_sack=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_frto=<span class="number">2</span></span><br></pre></td></tr></table></figure>

<h5 id="tcp-window-scaling"><a href="#tcp-window-scaling" class="headerlink" title="tcp_window_scaling"></a>tcp_window_scaling</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#default</span></span><br><span class="line">net.ipv4.tcp_window_scaling = 1</span><br></pre></td></tr></table></figure>
<p>tcp_window_scaling - support for large TCP Windows (RFC 1323).<br>The options info in SYN or SYN/ACK packages<br>Needs to be set to 1 if the Max TCP Window is over 65535</p>
<h5 id="tcp-win-scale"><a href="#tcp-win-scale" class="headerlink" title="tcp_win_scale"></a>tcp_win_scale</h5><p>The following variable is used to tell the kernel how much of the socket buffer space should be used for TCP window size, and how much to save for an application buffer<br>A value of 1 means the socket buffer will be divided evenly between TCP windows size and application</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_adv_win_scale=1</span><br></pre></td></tr></table></figure>

<h5 id="tcp-timestamps"><a href="#tcp-timestamps" class="headerlink" title="tcp_timestamps"></a>tcp_timestamps</h5><p>add additional 10 bytes to each packet but more accurate timestamp make TCP congestion control algorithms work better and are recommonded for fast networks</p>
<p>The following changes are recommended for improving IPv4 traffic performance, Disable the TCP timestamps option for better CPU utilization</p>
<p>I will enable it</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_timestamps=1</span><br></pre></td></tr></table></figure>

<h5 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h5><p>This determines the wait time between isAlive interval probes</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Decrease the time default value for connections to keep alive</span></span><br><span class="line"><span class="comment">#default net.ipv4.tcp_keepalive_intvl = 75</span></span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line"><span class="comment">#default net.ipv4.tcp_keepalive_probes = 9</span></span><br><span class="line">net.ipv4.tcp_keepalive_probes = 5</span><br><span class="line"><span class="comment">#default net.ipv4.tcp_keepalive_time = 7200</span></span><br><span class="line">net.ipv4.tcp_keepalive_time = 1800</span><br></pre></td></tr></table></figure>

<h5 id="tcp-tw-reuse"><a href="#tcp-tw-reuse" class="headerlink" title="tcp_tw_reuse"></a>tcp_tw_reuse</h5><p>This allows reusing sockets in TIME_WAIT state for new connections when it is safe from protocol viewpoint.<br>Allow to reuse TIME_WAIT sockets for new connections when it is safe from protocol viewpoint. It should not be changed without advice/request of technical experts.</p>
<p>Note: The tcp_tw_reuse setting is particularly useful in environments where numerous short connections are open and left in TIME_WAIT state, such as web servers. Reusing the sockets can be very effective in reducing server load.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse=1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br></pre></td></tr></table></figure>

<h5 id="tcp-sack"><a href="#tcp-sack" class="headerlink" title="tcp_sack"></a>tcp_sack</h5><p>Enable the TCP selective acks option for better throughput:<br>With selective acknowledgments, the data receiver can inform the sender about all segments that have arrived successfully, so the sender need retransmit only the segments that have actually been lost.</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">sysctl</span> -w net.ipv<span class="number">4</span>.tcp_sack=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-c00916755">There are warnings saying that net.ipv4.tcp_tw_reuse and</a></p>
<pre><code>net.ipv4.tcp_tw_recycle tunables should not be changed without consulting experts first.  What does this mean and what can go
wrong if they are enabled.
Answer:  Potential problems are not specific to Linux.  Enabling these tunables will not make the host crash or unstable, but it may break TCP/IP functionality if the host is connected to devices such as load-balancers or firewalls.  Some of these devices can reject SYN if it reuses the same connection (i.e. src/dst IP and src/dst ports are the same) too quickly.  RFC 1122 describes when it is acceptable to recycle the connection when SYN arrives for a connection in TIME_WAIT state.</code></pre>
<h5 id="netfilter"><a href="#netfilter" class="headerlink" title="netfilter"></a>netfilter</h5><p>To reduce the number of connections in TIME_WAIT state, we can decrease the number of seconds connections are kept in this state before being dropped:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reduce TIME_WAIT from the 120s default to 30-60s</span></span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_time_wait=30</span><br><span class="line"><span class="comment"># reduce FIN_WAIT from teh 120s default to 30-60s</span></span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_fin_wait=30</span><br><span class="line">````</span><br><span class="line"></span><br><span class="line"><span class="comment">#### [Neighbour Table Overflow](https://www.cyberciti.biz/faq/centos-redhat-debian-linux-neighbor-table-overflow/)</span></span><br><span class="line"><span class="string">&quot;kernel: Neighbour table overflow&quot;</span> <span class="keyword">in</span> the system messages  </span><br><span class="line"></span><br><span class="line">```bash</span><br><span class="line"><span class="comment">## Determines how often to check for stale neighbor entries, default 60 secs</span></span><br><span class="line">cat /proc/sys/net/ipv4/neigh/e*/gc_stale_time</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line"></span><br><span class="line"><span class="comment">## works best with &lt;= 500 client computers ##</span></span><br><span class="line"><span class="comment"># Force gc to clean-up quickly</span></span><br><span class="line">net.ipv4.neigh.default.gc_interval = 1800</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set ARP cache entry timeout</span></span><br><span class="line">net.ipv4.neigh.default.gc_stale_time = 1800</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup DNS threshold for arp</span></span><br><span class="line"><span class="comment"># gc_thresh3 represents the hard maximum number of entries in the ARP cache</span></span><br><span class="line">net.ipv4.neigh.default.gc_thresh3 = 8192</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2 = 4096</span><br><span class="line">net.ipv4.neigh.default.gc_thresh1 = 1024</span><br><span class="line"></span><br><span class="line">Configure interfaces to always use the best <span class="built_in">local</span> address <span class="keyword">for</span> this target. Ignore the <span class="built_in">source</span> address <span class="keyword">in</span> the IP packet and try to select <span class="built_in">local</span> address that we prefer <span class="keyword">for</span> talks with the target host.</span><br><span class="line">Raw</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line"></span><br><span class="line">Configure all interfaces to allow you to have multiple network interfaces on the same subnet, and have the ARPs <span class="keyword">for</span> each interface be answered based on whether or not the kernel would route a packet from the ARP<span class="string">&#x27;d IP out that interface (this change also requires source-based routing to be deployed and functional):</span></span><br><span class="line"><span class="string">Raw</span></span><br><span class="line"><span class="string">net.ipv4.conf.all.arp_filter = 1</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.arp_filter = 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br></pre></td></tr></table></figure>
<p>gc_thresh1 (since Linux 2.2)<br>       The minimum number of entries to keep in  the  ARP  cache. The garbage collector will not run if there are fewer than this number of entries in the cache.  Defaults to 128.</p>
<p>gc_thresh2 (since Linux 2.2)<br>       The soft maximum number of entries to keep  in  the  ARP  cache.The garbage collector will allow the number of entries to exceed this  for  5  seconds  before  collection  will  be   performed. Defaults to 512.</p>
<p>gc_thresh3 (since Linux 2.2)<br>       The  hard  maximum  number  of entries to keep in the ARP cache.The garbage collector will always run if  there  are  more  than this number of entries in the cache.  Defaults to 1024.</p>
<h3 id="sysctl-conf"><a href="#sysctl-conf" class="headerlink" title="sysctl.conf"></a>sysctl.conf</h3><p><a target="_blank" rel="noopener" href="https://levelup.gitconnected.com/linux-kernel-tuning-for-high-performance-networking-receive-backlog-5b3f54fb82a7">network_receive</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### Interrupt Coalescing (soft IRQ) and Ingress QDisc</span></span><br><span class="line">net.core.netdev_max_backlog = 65536 </span><br><span class="line">net.core.netdev_max_backlog = 2000</span><br><span class="line"><span class="comment">#  the maximum number of packets, queued on the INPUT side (the ingress qdisc), when the interface receives packets faster than kernel can process them.</span></span><br><span class="line"><span class="comment"># Sets the maximum number of packets allowed to queue when a particular interface receives packets faster than the kernel can process them.</span></span><br><span class="line"><span class="comment"># Each CPU core can hold a number of packets in a ring buffer before the network stack is able to process them. If the buffer is filled faster than TCP stack can process them, a dropped packet counter is incremented and they will be dropped. The net.core.netdev_max_backlog setting should be increased to maximize the number of packets queued for processing on servers with high burst traffic.</span></span><br><span class="line"></span><br><span class="line">net.core.netdev_budget=600</span><br><span class="line"><span class="comment">#netdev_budget is the maximum number of packets taken from all interfaces in one polling cycle (NAPI poll). In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.</span></span><br><span class="line"><span class="comment">#Maximum number of packets received in one NAPI polling cycle, total for all interfaces/CPUs. Cannot exceed</span></span><br><span class="line"></span><br><span class="line">                                             softirq                              s o f t --------- i r q</span><br><span class="line">             |normal workload   | syscall  | handle 0|               | syscall |handle 1|handle 2|handle 3|</span><br><span class="line">---CPU core--------------------------------------------------------------------------------------------------</span><br><span class="line">             |                             |                                   |</span><br><span class="line">             |                             |                                   |</span><br><span class="line">       <span class="built_in">disable</span> irqs                      poll                                 poll</span><br><span class="line">             |                             |                                   |</span><br><span class="line">             |                             |                                   |</span><br><span class="line">---NIC------------------------------------------------------------------------------------------------------</span><br><span class="line">                                  pkg1         pkg1 pkg2                pkg3</span><br><span class="line"></span><br><span class="line">This is much faster, but brings up another problem. What happens <span class="keyword">if</span> we have so many packets to process that we spend all our time processing packets from the NIC, but we never have time to <span class="built_in">let</span> the userspace processes actually drain those queues (<span class="built_in">read</span> from TCP connections, etc.)? Eventually the queues would fill up, and we’d start dropping packets. To try and make this fair, the kernel limits the amount of packets processed <span class="keyword">in</span> a given softirq context to a certain budget. Once this budget is exceeded, it wakes up a separate thread called ksoftirqd (you’ll see one of these <span class="keyword">in</span> ps <span class="keyword">for</span> each core) <span class="built_in">which</span> processes these softirqs outside of the normal syscall/interrupt path. This thread is scheduled using the standard process scheduler, <span class="built_in">which</span> already tries to be fair.</span><br><span class="line"></span><br><span class="line"><span class="comment">#Be careful of increasing this value unless there is a very good reason. A value exceeding 1000 is unlikely to be very helpful. In fact increasing this value too much can have detrimental effect and in the worse case scenario lead to softirq hangs or performance problems, as the softirqs can run for too long and starve other processes of CPU. the maximum number of packets taken from all interfaces in one polling cycle (NAPI poll). In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.</span></span><br><span class="line"></span><br><span class="line">net.core.netdev_budget_usecs=2000 <span class="comment">#default 2000</span></span><br><span class="line"><span class="comment">#is the maximum number of packets, queued on the INPUT side (the ingress qdisc), when the interface receives packets faster than kernel can process them.</span></span><br><span class="line"><span class="comment">#netdev_budget_usecs maximum number of microseconds in one NAPI polling cycle. Polling will exit when either netdev_budget_usecs have elapsed during the poll cycle or the number of packets processed reaches netdev_budget</span></span><br><span class="line"></span><br><span class="line">net.core.dev_weight=128 <span class="comment">#default 64</span></span><br><span class="line"><span class="comment">#he maximum number of packets that kernel can handle on a NAPI interrupt, it&#x27;s a Per-CPU variable. For drivers that support LRO or GRO_HW, a hardware aggregated packet is counted as one packet in this.</span></span><br><span class="line"><span class="comment"># Maximum number of packets the driver can receive during a NAPI interrupt, per CPU.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## need hardware support</span></span><br><span class="line">net.core.busy_poll = 50 </span><br><span class="line"><span class="comment"># This parameter controls the number of microseconds to wait for packets on the device queue for socket poll and selects </span></span><br><span class="line"><span class="comment"># default 0</span></span><br><span class="line"><span class="comment"># This parameter controls the number of microseconds to wait for packets on the device queue for socket reads</span></span><br><span class="line">net.core.busy_read = 100 </span><br><span class="line"><span class="comment"># default 0</span></span><br><span class="line"><span class="comment">#bnx2x</span></span><br><span class="line"><span class="comment">#be2net</span></span><br><span class="line"><span class="comment">#ixgbe</span></span><br><span class="line"><span class="comment">#mlx4</span></span><br><span class="line"><span class="comment">#myri10ge</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### Egress qdisc</span></span><br><span class="line">default_qdisc is the default queuing discipline to use <span class="keyword">for</span> network devices</span><br></pre></td></tr></table></figure>
<p>$ /proc/sys/net/core/default_qdisc<br>pfifo_fast<br>sysctl net.core.default_qdisc<br>net.core.default_qdisc<br>#net.core.default_qdisc = pfifo_fast<br>#net.core.default_qdisc=fq_codel<br>#net.core.default_qdisc=fq<br>net.core.default_qdisc = pfifo_fast</p>
<p>$ ifconfig ethX txqueuelen 2000<br>txqueuelen is the maximum number of packets, queued on the OUTPUT side.</p>
<p>$ tc -s qdisc ls dev enp1s0f0<br>qdisc mq 0: root<br> Sent 8704680006739 bytes 1081832598 pkt (dropped 0, overlimits 0 requeues 38187748)<br> backlog 0b 0p requeues 38187748<br>qdisc pfifo_fast 0: parent :c bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 34858645 bytes 521805 pkt (dropped 0, overlimits 0 requeues 17)<br> backlog 0b 0p requeues 17<br>qdisc pfifo_fast 0: parent :b bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 676539 bytes 3021 pkt (dropped 0, overlimits 0 requeues 0)<br> backlog 0b 0p requeues 0<br>qdisc pfifo_fast 0: parent :a bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 37492499 bytes 9420 pkt (dropped 0, overlimits 0 requeues 390)<br> backlog 0b 0p requeues 390<br>qdisc pfifo_fast 0: parent :9 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 422056 bytes 1476 pkt (dropped 0, overlimits 0 requeues 0)<br> backlog 0b 0p requeues 0<br>qdisc pfifo_fast 0: parent :8 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 98686230031 bytes 12114256 pkt (dropped 0, overlimits 0 requeues 756171)<br> backlog 0b 0p requeues 756171<br>qdisc pfifo_fast 0: parent :7 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 108277741139 bytes 12015011 pkt (dropped 0, overlimits 0 requeues 636061)<br> backlog 0b 0p requeues 636061<br>qdisc pfifo_fast 0: parent :6 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 991256915583 bytes 110945978 pkt (dropped 0, overlimits 0 requeues 12727685)<br> backlog 0b 0p requeues 12727685<br>qdisc pfifo_fast 0: parent :5 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 4394205535 bytes 754058 pkt (dropped 0, overlimits 0 requeues 246)<br> backlog 0b 0p requeues 246<br>qdisc pfifo_fast 0: parent :4 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 2788904555347 bytes 315235199 pkt (dropped 0, overlimits 0 requeues 15808716)<br> backlog 0b 0p requeues 15808716<br>qdisc pfifo_fast 0: parent :3 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 56526646 bytes 85576 pkt (dropped 0, overlimits 0 requeues 2)<br> backlog 0b 0p requeues 2<br>qdisc pfifo_fast 0: parent :2 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 2752219594535 bytes 315360937 pkt (dropped 0, overlimits 0 requeues 8257982)<br> backlog 0b 0p requeues 8257982<br>qdisc pfifo_fast 0: parent :1 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1<br> Sent 1960810788184 bytes 314785861 pkt (dropped 0, overlimits 0 requeues 478)<br> backlog 0b 0p requeues 478</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">### TCP FSM and congestion algorithm</span></span><br><span class="line"><span class="attribute">net</span>.core.somaxconn = <span class="number">65536</span></span><br><span class="line"><span class="comment">#Limit of socket listen() backlog, known in userspace as SOMAXCONN. Defaults to 128.</span></span><br><span class="line"><span class="comment">#provides an upper limit on the value of the backlog parameter passed to the listen() function</span></span><br><span class="line"><span class="comment">#Decrease the time default value for tcp_fin_timeout connection, FIN-WAIT-2</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_fin_timeout = <span class="number">15</span></span><br><span class="line"><span class="comment">#tcp_available_congestion_control - shows the available congestion control choices that are registered.</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_max_syn_backlog = <span class="number">2048</span> # default <span class="number">256</span></span><br><span class="line"><span class="comment">#Maximum number of packets taken from all interfaces in one polling cycle (NAPI poll).</span></span><br><span class="line"><span class="comment">#In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Maximum number of remembered connection requests, which are still did not receive an acknowledgment from connecting client. The default value is 1024 for systems with more than 128Mb of memory, and 128 for low memory machines.</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_available_congestion_control #default reno cubic</span><br><span class="line"><span class="comment">#shows the available congestion control choices that are registered.</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_congestion_control </span><br><span class="line"><span class="comment">#default cubic</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_slow_start_after_idle=<span class="number">1</span> </span><br><span class="line"><span class="comment">#enable tcp slow start</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### TCP buffer</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_moderate_rcvbuf = <span class="number">1</span></span><br><span class="line"><span class="comment">#If set, TCP performs receive buffer auto-tuning, attempting to automatically size the buffer</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># min (size used under memory pressure), default (initial size), max (maximum size) - size of receive buffer used by TCP sockets.</span></span><br><span class="line"><span class="comment"># default (initial size), max (maximum size) - size of send buffer used by TCP sockets.</span></span><br><span class="line"><span class="comment"># the number of pages(default 4K) allocated falls below the low, pressure, high mark.</span></span><br><span class="line"><span class="comment">#                     (64M) (512M)  (16G)</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_mem =  <span class="number">16384</span> <span class="number">131072</span>   <span class="number">4194304</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_wmem = <span class="number">16384</span> <span class="number">131072</span>   <span class="number">4194304</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#                    (128M) (512M)  (24G) here is page</span></span><br><span class="line"><span class="comment"># measured in units of the system page size</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_rmem = <span class="number">32768</span> <span class="number">131072</span>  <span class="number">6291456</span></span><br><span class="line"><span class="comment"># default: net.ipv4.tcp_wmem = 4096	16384	4194304 (4194304*4/1024/1024=16M)</span></span><br><span class="line"><span class="comment"># default: net.ipv4.tcp_wmem = 4096	16384	4194304 (16M)</span></span><br><span class="line"><span class="comment"># default: net.ipv4.tcp_rmem = 4096	131072	6291456 (24M)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># allow auto-tuning up to 256MB buffers</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_rmem = <span class="number">65536</span> <span class="number">134217728</span> <span class="number">268435456</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_wmem = <span class="number">65536</span> <span class="number">134217728</span> <span class="number">268435456</span></span><br><span class="line"><span class="attribute">net</span>.core.somaxconn=<span class="number">16384</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#256M 64M, here is bytes</span></span><br><span class="line"><span class="attribute">net</span>.core.rmem_max = <span class="number">268435456</span></span><br><span class="line"><span class="attribute">net</span>.core.rmem_default = <span class="number">67108864</span> </span><br><span class="line"><span class="comment">#Socket Receive Queues, avoid package loss</span></span><br><span class="line"><span class="attribute">net</span>.core.wmem_max = <span class="number">268435456</span></span><br><span class="line"><span class="attribute">net</span>.core.wmem_default = <span class="number">67108864</span></span><br><span class="line"><span class="comment"># Each network socket is allocated a send buffer for outbound packets and a receive socket for inbound packets. These buffers are assigned a default size that depends on parameters of the operating system</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### The others</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_sack = <span class="number">1</span></span><br><span class="line"><span class="comment">#Enable the TCP selective acks option for better throughput</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_timestamps=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_mtu_probing=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_tw_reuse=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_adv_win_scale=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_window_scaling = <span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_mtu_probing=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.core.rmem_max=<span class="number">16777216</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_congestion_control=cubic</span><br><span class="line"></span><br><span class="line"><span class="comment"># fast retrans</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_frto=<span class="number">1</span></span><br><span class="line"><span class="comment">#Enable  F-RTO,  an enhanced recovery algorithm for TCP retrans‐mission timeouts (RTOs).   It  is  particularly  beneficial  in wireless  environments  where  packet  loss is typically due to random radio interference rather than intermediate router  con‐gestion.  See RFC 4138 for more details.</span></span><br><span class="line"><span class="comment">#              This file can have one of the following values:</span></span><br><span class="line"><span class="comment">#              0  Disabled.</span></span><br><span class="line"><span class="comment">#              1  The basic version F-RTO algorithm is enabled.</span></span><br><span class="line"><span class="comment">#              2  Enable  SACK-enhanced  F-RTO  if  flow uses SACK.  The basic version can be used also when SACK is in use though in  that case scenario(s) exists where F-RTO interacts badly with the packet counting of the SACK-enabled TCP flow.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># works best with &lt;= 1000 client computers ##</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.neigh.default.gc_interval = <span class="number">30</span> </span><br><span class="line"><span class="comment">#default, How frequently the garbage collector for neighbour entries should attempt to run.Defaults to 30 seconds.  </span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.neigh.default.gc_stale_time = <span class="number">60</span> </span><br><span class="line"><span class="comment">#default,  Determines how often to check for stale neighbour entries. When a neighbour entry is considered stale it is resolved again before sending data to it. Defaults to 60 seconds</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># gc_thresh3 represents the hard maximum number of entries in the ARP cache</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.neigh.default.gc_thresh<span class="number">3</span> = <span class="number">8192</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.neigh.default.gc_thresh<span class="number">2</span> = <span class="number">4096</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.neigh.default.gc_thresh<span class="number">1</span> = <span class="number">2048</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># don&#x27;t cache ssthresh from previous connection</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_no_metrics_save = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#use cookies to process SYN queue overflow</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_syncookies = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RHEL 7 default: 32768 61000</span></span><br><span class="line"><span class="comment"># outgoing port range</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.ip_local_port_range = <span class="number">2000</span> <span class="number">65535</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Decrease the time default value for tcp_fin_timeout connection, FIN-WAIT-2</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_fin_timeout = <span class="number">15</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.netfilter.ip_conntrack_max=<span class="number">204800</span></span><br><span class="line"><span class="comment"># default net.ipv4.route.gc_timeout = 300</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.icmp_ignore_bogus_error_responses = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># In WAN network connection</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_bic=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_keepalive_intvl = <span class="number">30</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_keepalive_probes = <span class="number">5</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_keepalive_time = <span class="number">1800</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_tw_reuse=<span class="number">1</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_max_tw_buckets = <span class="number">1440000</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_adv_win_scale=<span class="number">1</span></span><br><span class="line"><span class="comment">#The options info in SYN or SYN/ACK packages </span></span><br><span class="line"><span class="comment">#Needs to be set to 1 if the Max TCP Window is over 65535</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The following variable is used to tell the kernel how much of the socket buffer space should be used for TCP window size, and how much to save for an application buffer</span></span><br><span class="line"><span class="comment">#A value of 1 means the socket buffer will be divided evenly between TCP windows size and application</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_window_scaling = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_low_latency=<span class="number">0</span></span><br><span class="line"><span class="comment">### htcp</span></span><br><span class="line"><span class="attribute">net</span>.ipv<span class="number">4</span>.tcp_congestion_control=htcp</span><br><span class="line"></span><br><span class="line"><span class="comment">### default</span></span><br><span class="line"><span class="attribute">tcp_congestion_control</span>=cubic </span><br><span class="line"><span class="attribute">net</span>.core.default_qdisc=fq_codel</span><br><span class="line"><span class="comment">#net.core.default_qdisc = pfifo_fast</span></span><br></pre></td></tr></table></figure>


<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">### throughput performance</span><br><span class="line">net.core.dev_weight = <span class="number">128</span></span><br><span class="line">net.core.netdev_max_backlog = <span class="number">65536</span> </span><br><span class="line">net.core.netdev_budget=<span class="number">600</span></span><br><span class="line">net.core.busy_poll = <span class="number">50</span> </span><br><span class="line">net.core.busy_read = <span class="number">100</span> </span><br><span class="line">net.core.somaxconn = <span class="number">65536</span></span><br><span class="line">net.ipv4.tcp_fin_timeout = <span class="number">15</span></span><br><span class="line">net.ipv4.tcp_slow_start_after_idle=<span class="number">1</span> </span><br><span class="line">net.ipv4.tcp_moderate_rcvbuf = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_mem =  <span class="number">16384</span> <span class="number">131072</span>   <span class="number">4194304</span></span><br><span class="line">net.ipv4.tcp_wmem = <span class="number">16384</span> <span class="number">131072</span>   <span class="number">4194304</span></span><br><span class="line">net.ipv4.tcp_rmem = <span class="number">32768</span> <span class="number">131072</span>  <span class="number">6291456</span></span><br><span class="line">net.core.rmem_max = <span class="number">268435456</span></span><br><span class="line">net.core.rmem_default = <span class="number">67108864</span> </span><br><span class="line">net.core.wmem_max = <span class="number">268435456</span></span><br><span class="line">net.core.wmem_default = <span class="number">67108864</span></span><br><span class="line">net.ipv4.tcp_sack = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_timestamps=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_mtu_probing=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_tw_reuse=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_adv_win_scale=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_window_scaling = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_mtu_probing=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_frto=<span class="number">1</span></span><br><span class="line">net.ipv4.neigh.<span class="section">default</span>.gc_interval = <span class="number">30</span> </span><br><span class="line">net.ipv4.neigh.<span class="section">default</span>.gc_stale_time = <span class="number">60</span> </span><br><span class="line">net.ipv4.neigh.<span class="section">default</span>.gc_thresh3 = <span class="number">8192</span></span><br><span class="line">net.ipv4.neigh.<span class="section">default</span>.gc_thresh2 = <span class="number">4096</span></span><br><span class="line">net.ipv4.neigh.<span class="section">default</span>.gc_thresh1 = <span class="number">2048</span></span><br><span class="line">net.ipv4.tcp_no_metrics_save = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_syncookies = <span class="number">1</span></span><br><span class="line">net.ipv4.ip_local_port_range = <span class="number">2000</span> <span class="number">65535</span></span><br><span class="line">net.ipv4.tcp_fin_timeout = <span class="number">15</span></span><br><span class="line">net.ipv4.netfilter.ip_conntrack_max=<span class="number">204800</span></span><br><span class="line">net.ipv4.icmp_ignore_bogus_error_responses = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_keepalive_intvl = <span class="number">30</span></span><br><span class="line">net.ipv4.tcp_keepalive_probes = <span class="number">5</span></span><br><span class="line">net.ipv4.tcp_keepalive_time = <span class="number">1800</span></span><br><span class="line">net.ipv4.tcp_tw_reuse=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_max_tw_buckets = <span class="number">1440000</span></span><br><span class="line">net.ipv4.tcp_adv_win_scale=<span class="number">1</span></span><br><span class="line">net.ipv4.tcp_window_scaling = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_low_latency=<span class="number">0</span></span><br><span class="line">net.ipv4.tcp_congestion_control=cubic</span><br><span class="line">net.core.default_qdisc=fq_codel</span><br><span class="line"></span><br><span class="line"># if you custom pin cpu resources</span><br><span class="line">#kernel.numa_balancing=<span class="number">0</span></span><br><span class="line"></span><br><span class="line">#avoid the bad udp package</span><br><span class="line">#net.inet.udp.checksum=<span class="number">1</span></span><br><span class="line">#zero means not receive source route info ip package</span><br><span class="line">#net.ipv4.conf.<span class="section">default</span>.accept_source_route = <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h5 id="tcp-syn-retries"><a href="#tcp-syn-retries" class="headerlink" title="tcp_syn_retries"></a><a target="_blank" rel="noopener" href="https://testerhome.com/topics/8859">tcp_syn_retries</a></h5><p>net.ipv4.tcp_syn_retries = 6</p>
<p>tcp_syn_retries - INTEGER</p>
<p>Number of times initial SYNs for an active TCP connection attempt will be retransmitted. Should not be higher than 127. Default value<br>is 6, which corresponds to 63seconds till the last retransmission with the current initial RTO of 1second. With this the final timeout for an active TCP connection attempt will happen after 127seconds.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">time telnet <span class="variable">$ip</span> <span class="variable">$port</span></span><br><span class="line"></span><br><span class="line">Trying <span class="variable">$ip</span>...</span><br><span class="line">telnet: connect to address <span class="variable">$ip</span>: Connection timed out</span><br><span class="line">telnet <span class="variable">$ip</span> <span class="variable">$port</span>  0.00s user 0.00s system 0% cpu 2:07.29 total</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">18:04:23.765507 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13801993 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:24.768182 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13802996 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:26.772188 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13805000 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:30.780189 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13809008 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:38.796205 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13817024 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:04:54.828196 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13833056 ecr 0,nop,wscale 7], length 0</span><br><span class="line">18:05:26.860210 IP <span class="variable">$ip1</span>.<span class="variable">$port1</span> &gt; <span class="variable">$ip2</span>.<span class="variable">$port2</span>: Flags [S], seq 922947731, win 29200, options [mss 1460,sackOK,TS val 13865088 ecr 0,nop,wscale 7], length 0</span><br><span class="line"></span><br><span class="line">18:04:23.765507</span><br><span class="line">18:04:24.768182 1s</span><br><span class="line">18:04:26.772188 2s</span><br><span class="line">18:04:30.780189 4s</span><br><span class="line">18:04:38.796205 8s</span><br><span class="line">18:04:54.828196 16s</span><br><span class="line">18:05:26.860210 32s</span><br><span class="line">06:30.98        64s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"><span class="comment">#net.ipv4.tcp_syn_retries = 6</span></span><br><span class="line">``</span><br><span class="line"></span><br><span class="line"><span class="comment">##### The sysctl.conf in production final</span></span><br><span class="line">```yaml</span><br><span class="line">net.ipv4.tcp_fastopen=3</span><br><span class="line">net.core.busy_poll = 50</span><br><span class="line">net.core.busy_read = 50</span><br><span class="line">net.core.netdev_max_backlog = 100000</span><br><span class="line">net.ipv4.tcp_mtu_probing=1</span><br><span class="line">vm.min_free_kbytes=360448</span><br><span class="line">fs.pipe-max-size=104857600</span><br><span class="line">kernel.numa_balancing=0</span><br><span class="line">net.core.rmem_max = 268435456</span><br><span class="line">net.core.rmem_default = 67108864</span><br><span class="line">net.core.wmem_max = 268435456</span><br><span class="line">net.core.wmem_default = 67108864</span><br><span class="line">net.ipv4.tcp_rmem = 65536 134217728 268435456</span><br><span class="line">net.ipv4.tcp_wmem = 65536 134217728 268435456</span><br><span class="line">net.core.somaxconn=16384</span><br><span class="line">net.ipv4.tcp_tw_reuse=1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br></pre></td></tr></table></figure>

<h5 id="Enabling-flow-limits-and-tuning-flow-limit-hash-table-size"><a href="#Enabling-flow-limits-and-tuning-flow-limit-hash-table-size" class="headerlink" title="Enabling flow limits and tuning flow limit hash table size"></a>Enabling flow limits and tuning flow limit hash table size</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -w net.core.flow_limit_table_len=8192</span><br><span class="line">The value is only consulted when a new table is allocated. Modifying it does not update active tables.</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line">00000</span><br><span class="line"></span><br><span class="line"><span class="comment"># set a bitmask</span></span><br><span class="line"><span class="built_in">echo</span> f &gt; /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line"></span><br><span class="line">Per-flow rate is calculated by hashing each packet into a hashtable bucket and incrementing a per-bucket counter. The <span class="built_in">hash</span> <span class="keyword">function</span> is the same that selects a CPU <span class="keyword">in</span> RPS, but as the number of buckets can be much larger than the number of CPUs, flow <span class="built_in">limit</span> has finer-grained identification of large flows and fewer <span class="literal">false</span> positives. The default table has 4096 buckets. This value can be modified through sysctl</span><br><span class="line"></span><br><span class="line">Flow <span class="built_in">limit</span> is useful on systems with many concurrent connections, <span class="built_in">where</span> a single connection taking up 50% of a CPU indicates a problem. In such environments, <span class="built_in">enable</span> the feature on all CPUs that handle network rx interrupts (as <span class="built_in">set</span> <span class="keyword">in</span> /proc/irq/N/smp_affinity).</span><br><span class="line"></span><br><span class="line">The feature depends on the input packet queue length to exceed the flow <span class="built_in">limit</span> threshold (50%) + the flow <span class="built_in">history</span> length (256). Setting net.core.netdev_max_backlog to either 1000 or 10000 performed well <span class="keyword">in</span> experiments.</span><br></pre></td></tr></table></figure>

<h3 id="NFS-hangs-because-zero-window-problem"><a href="#NFS-hangs-because-zero-window-problem" class="headerlink" title="NFS hangs because zero window problem"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/1610363">NFS hangs because zero window problem</a></h3><p>Zero Window is something to investigate. TCP Zero Window is when the Window size in a machine remains at zero for a specified amount of time. This means that a client is not able to receive further information at the moment, and the TCP transmission is halted until it can process the information in its receive buffer.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_sack=0</span><br></pre></td></tr></table></figure>
<p>disable tcp sack and remount the nfs</p>
<p><a target="_blank" rel="noopener" href="https://wiki.wireshark.org/TCP%20ZeroWindow">Troubleshooting a Zero Window</a> For one reason or another, the machine alerting the Zero Window will not receive any more data from the host. It could be that the machine is running too many processes at that moment, and its processor is maxed. Or it could be that there is an error in the TCP receiver, like a Windows registry misconfiguration. Try to determine what the client was doing when the TCP Zero Window happened.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ tcpkill -i eth0 port 21</span><br><span class="line">$ tcpkill host 192.168.1.2</span><br><span class="line">$ tcpkill ip host 192.168.1.2 and not 192.168.1.111</span><br></pre></td></tr></table></figure>

<h4 id="All-NFS-connection-are-hang-all-TCP-state-are-in-TIMEWAIT-status"><a href="#All-NFS-connection-are-hang-all-TCP-state-are-in-TIMEWAIT-status" class="headerlink" title="All NFS connection are hang, all TCP state are in TIMEWAIT status"></a>All NFS connection are hang, all TCP state are in TIMEWAIT status</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#modify</span></span><br><span class="line">net.ipv4.tcp_low_latency=0 to net.ipv4.tcp_low_latency=1</span><br><span class="line">net.ipv4.tcp_adv_win_scale=0 to net.ipv4.tcp_adv_win_scale=1</span><br></pre></td></tr></table></figure>

<p>restart service ,it ‘s not work, restart rpcbind ,it ‘s not work, looks like tcp issue.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse=1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br><span class="line"><span class="comment"># net.ipv4.tcp_tw_recycle has been removed</span></span><br></pre></td></tr></table></figure>
<p>all TCP state to ESTABLISHED, it ‘s recovery.</p>
<h3 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h3><h4 id="kernel"><a href="#kernel" class="headerlink" title="kernel"></a>kernel</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">$</span> <span class="string">dropwatch</span> <span class="string">-l</span> <span class="string">kas</span></span><br><span class="line"><span class="string">Initalizing</span> <span class="string">kallsyms</span> <span class="string">db</span></span><br><span class="line"><span class="string">dropwatch&gt;</span> <span class="string">start</span></span><br><span class="line"><span class="string">Enabling</span> <span class="string">monitoring...</span></span><br><span class="line"><span class="string">Kernel</span> <span class="string">monitoring</span> <span class="string">activated.</span></span><br><span class="line"><span class="string">Issue</span> <span class="string">Ctrl-C</span> <span class="string">to</span> <span class="string">stop</span> <span class="string">monitoring</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_queue_purge+18</span> <span class="string">(0xffffffff91a38848)</span></span><br><span class="line"><span class="number">187</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">164</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">131</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">30</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">113</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">69</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">71</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"><span class="number">78</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_release_data+10e</span> <span class="string">(0xffffffff91a386de)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### iperf3 and qperf tcp and udp test between boardcom 57800</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">skb_queue_purge+18</span> <span class="string">(0xffffffff88038848)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">2</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">2</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">neigh_probe+5f</span> <span class="string">(0xffffffff8805d3cf)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">neigh_probe+5f</span> <span class="string">(0xffffffff8805d3cf)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">arp_error_report+39</span> <span class="string">(0xffffffff880cf779)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">neigh_probe+5f</span> <span class="string">(0xffffffff8805d3cf)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">icmp_rcv+125</span> <span class="string">(0xffffffff880d30c5)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">neigh_probe+5f</span> <span class="string">(0xffffffff8805d3cf)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">neigh_probe+5f</span> <span class="string">(0xffffffff8805d3cf)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">arp_error_report+39</span> <span class="string">(0xffffffff880cf779)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">icmp_rcv+125</span> <span class="string">(0xffffffff880d30c5)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">unix_dgram_sendmsg+4f8</span> <span class="string">(0xffffffff881108a8)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">tcp_v4_rcv+87</span> <span class="string">(0xffffffff880c1d37)</span></span><br><span class="line"><span class="number">6</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">unix_stream_connect+2da</span> <span class="string">(0xffffffff881101ea)</span></span><br><span class="line"><span class="number">4</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">unix_dgram_sendmsg+4f8</span> <span class="string">(0xffffffff881108a8)</span></span><br><span class="line"><span class="number">2</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">unix_stream_connect+2da</span> <span class="string">(0xffffffff881101ea)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">1</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"><span class="number">2</span> <span class="string">drops</span> <span class="string">at</span> <span class="string">__udp4_lib_rcv+b9</span> <span class="string">(0xffffffff880cda49)</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">ss</span> <span class="string">-eipnt</span> <span class="string">|</span> <span class="string">grep</span> <span class="string">-A</span> <span class="number">1</span> <span class="string">$ipaddr</span> <span class="string">--color</span>  <span class="string">|</span> <span class="string">grep</span> <span class="string">-B</span> <span class="number">1</span> <span class="string">-Ei</span> <span class="string">&#x27;cwnd|ssthresh&#x27;</span></span><br><span class="line">    <span class="string">*</span> <span class="string">If</span> <span class="string">cwnd</span> <span class="string">and</span> <span class="string">ssthresh</span> <span class="string">and</span> <span class="string">cwnd</span> <span class="string">&#x27;s value up and down frequently that means there is a bad network env(maybe it &#x27;</span><span class="string">s</span> <span class="string">trigger</span> <span class="string">the</span> <span class="string">tcp</span> <span class="string">slow</span> <span class="string">start</span> <span class="string">algorithm</span> <span class="string">and</span> <span class="string">TCP</span> <span class="string">Congestion</span> <span class="string">avoidance</span> <span class="string">algorithm)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Recv-Q is the count of bytes not copied by the user program connected to this socket.</span></span><br><span class="line"><span class="comment">#Send-Q is the count of bytes not acknowledged by the remote host.</span></span><br><span class="line"><span class="comment">#If there are Send-Q values/counts that are persistent:</span></span><br><span class="line">   <span class="comment">#Some of these are data the host has already sent but that have not yet arrived at the receiver, merely due to geographic distance.</span></span><br><span class="line">   <span class="comment">#Likewise, some are for sent data for which the receiver has emitted acknowledgements, which are still in transit on the return path. Some can be due to sent data which has been dropped by the network, or the responses for those.</span></span><br><span class="line">   <span class="comment">#Finally, when the receiver tells the sender to pause sending, or the sending application is faster than the network can support, an unsent-data queue can build up</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Similarly a non-zero value in Recv-Q does not really indicate a system problem but an application level issue. If the counts in Recv-Q increases it implies that application running on system is not picking up the data that the kernel is signalling to them. This may or may not be a problem. For example if the receiving application is writing to a filesystem which is slower than both the sender and the network, a receive queue would be expected to build up.</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">sar</span> <span class="string">-n</span> <span class="string">TCP,ETCP</span> <span class="number">2</span></span><br><span class="line"><span class="number">02</span><span class="string">:47:30</span> <span class="string">AM</span>  <span class="string">active/s</span> <span class="string">passive/s</span>    <span class="string">iseg/s</span>    <span class="string">oseg/s</span></span><br><span class="line"><span class="number">02</span><span class="string">:47:31</span> <span class="string">AM</span>      <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">8.51</span>      <span class="number">6.38</span></span><br><span class="line"></span><br><span class="line"><span class="number">02</span><span class="string">:47:30</span> <span class="string">AM</span>  <span class="string">atmptf/s</span>  <span class="string">estres/s</span> <span class="string">retrans/s</span> <span class="string">isegerr/s</span>   <span class="string">orsts/s</span></span><br><span class="line"><span class="number">02</span><span class="string">:47:31</span> <span class="string">AM</span>      <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span>      <span class="number">0.00</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># active/s: Number of locally-initiated TCP connections per second (e.g., via connect()).</span></span><br><span class="line"><span class="comment"># passive/s: Number of remotely-initiated TCP connections per second (e.g., via accept()).</span></span><br><span class="line"><span class="comment"># retrans/s: Number of TCP retransmits per second.</span></span><br><span class="line"><span class="comment"># The active and passive counts are often useful as a rough measure of server load: number of new accepted connections (passive), and number of downstream connections (active). It might help to think of active as outbound, and passive as inbound, but this isn’t strictly true (e.g., consider a localhost to localhost connection).</span></span><br><span class="line"><span class="comment"># Retransmits are a sign of a network or server issue; it may be an unreliable network (e.g., the public Internet), or it may be due a server being overloaded and dropping packets. The example above shows just one new TCP connection per-second.</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">/proc/sys/net/ipv4/tcp_mem</span></span><br><span class="line"><span class="number">3082008</span>	<span class="number">4109346</span>	<span class="number">6164016</span> <span class="comment"># here is 4K page, but in sysctl.conf config file was bytes</span></span><br><span class="line"></span><br><span class="line"><span class="string">$</span> <span class="string">cat</span> <span class="string">/proc/net/sockstat</span></span><br><span class="line"><span class="attr">sockets:</span> <span class="string">used</span> <span class="number">181</span>                                <span class="comment"># total sockets</span></span><br><span class="line"><span class="attr">TCP:</span> <span class="string">inuse</span> <span class="number">16</span> <span class="string">orphan</span> <span class="number">0</span> <span class="string">tw</span> <span class="number">0</span> <span class="string">alloc</span> <span class="number">27</span> <span class="string">mem</span> <span class="number">5</span>       <span class="comment"># inuse = netstat –lnt | grep ^tcp | wc –l; cat /proc/sys/net/ipv4/tcp_max_orphans</span></span><br><span class="line"><span class="attr">UDP:</span> <span class="string">inuse</span> <span class="number">3</span> <span class="string">mem</span> <span class="number">0</span>                              </span><br><span class="line"><span class="attr">UDPLITE:</span> <span class="string">inuse</span> <span class="number">0</span></span><br><span class="line"><span class="attr">RAW:</span> <span class="string">inuse</span> <span class="number">0</span></span><br><span class="line"><span class="attr">FRAG:</span> <span class="string">inuse</span> <span class="number">0</span> <span class="string">memory</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># orphan , /proc/sys/net/ipv4/tcp_max_orphans, Maximal number of TCP sockets not attached to any user file handle held by system.</span></span><br><span class="line"><span class="comment"># tw , netstat –ant | grep TIME_WAIT | wc –l</span></span><br><span class="line"><span class="comment"># alloc, netstat –ant | grep ^tcp | wc –l</span></span><br><span class="line"><span class="comment"># mem,  proc/net/sockstat, specifically the mem field, is where to look. This value is is reported in kernel pages and corresponds directly to /proc/sys/net/ipv4/tcp_mem.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#At the individual socket level, memory is allocated in kernel space only until the user space code reads it, at which time the kernel memory is freed. sk_buff-&gt;truesize is the sum of both the amount of data buffered, as well as the socket structure itself</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The device drivers allocate a region of memory for the device to perform DMA to incoming packets</span></span><br><span class="line"><span class="comment">#https://unix.stackexchange.com/questions/419518/how-to-tell-how-much-memory-tcp-buffers-are-actually-using/419525</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### tcp status</span></span><br></pre></td></tr></table></figure>
<p>$ cat /proc/net/tcp<br>  sl  local_address rem_address   st tx_queue rx_queue tr tm-&gt;when retrnsmt   uid  timeout inode</p>
<p>$ cat /proc/net/dev<br>Inter-   |   Receive                                                |  Transmit<br> face    |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed<br>enp1s0f0:  8681      58    0    0    0     0          0        18    10054      48    0    0    0     0       0          0<br>enp1s0f1:  3200      30    0    0    0     0          0        17     1110      15    0    0    0     0       0          0<br>  eno1:     180       3    0    0    0     0          0        72        0       0    0    0    0     0       0          0<br> bond0:   11881      88    0    0    0     0          0        35    11164      63    0    0    0     0       0          0<br>  eth0:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0<br>    lo:    1120      13    0    0    0     0          0         0     1120      13    0    0    0     0       0          0</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### kernel <span class="keyword">drop</span></span><br><span class="line">eg: TcpExtTCPReqQFullDrop, TcpExtTCPReqQFullDoCookies   </span><br><span class="line">[<span class="number">1.</span>](https://github.com/netdata/netdata/issues/<span class="number">3234</span>#issuecomment<span class="number">-423935842</span>) The SYN queue tracks TCP handshakes <span class="keyword">until</span> connections are fully established. It overflows <span class="keyword">when</span> too many incoming TCP <span class="keyword">connection</span> requests hang <span class="keyword">in</span> the half-<span class="keyword">open</span> state <span class="keyword">and</span> the <span class="keyword">server</span> <span class="keyword">is</span> <span class="keyword">not</span> configured <span class="keyword">to</span> fall back <span class="keyword">to</span> SYN cookies*. Overflows are usually caused <span class="keyword">by</span> SYN flood DoS attacks (i.e. someone sends lots <span class="keyword">of</span> SYN packets <span class="keyword">and</span> never completes the handshakes).  </span><br><span class="line"><span class="number">2.</span> The accept queue holds fully established TCP connections waiting <span class="keyword">to</span> be handled <span class="keyword">by</span> the listening application. It overflows <span class="keyword">when</span> the <span class="keyword">server</span> application fails <span class="keyword">to</span> accept <span class="built_in">new</span> connections at the rate they are coming <span class="keyword">in</span>.    </span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>$ awk ‘/TcpExt/ { print $21,$22 }’ /proc/net/netstat<br>ListenOverflows ListenDrops<br>0 0</p>
<h1 id="ListenOverflows"><a href="#ListenOverflows" class="headerlink" title="ListenOverflows"></a>ListenOverflows</h1><h1 id="ListenDrops"><a href="#ListenDrops" class="headerlink" title="ListenDrops"></a>ListenDrops</h1><h1 id="nstat-got-value-from-proc-net-netstat"><a href="#nstat-got-value-from-proc-net-netstat" class="headerlink" title="nstat got value from /proc/net/netstat"></a>nstat got value from /proc/net/netstat</h1><p>$ nstat -rsz | grep -Ei ‘fail|crc|dis|drop|miss|err|over|timeout|jabb|full|retrans|out.*of|restar|collis’<br>$ watch -d “nstat -rsz | grep -Ei ‘fail|crc|dis|drop|miss|err|over|timeout|jabb|full|retrans|out.*of|restar|collis’  | awk ‘$2!=0’”<br>IpInHdrErrors                   0                  0.0<br>IpInAddrErrors                  0                  0.0<br>IpInDiscards                    0                  0.0<br>IpOutDiscards                   58866              0.0<br>IpReasmTimeout                  0                  0.0<br>IpReasmFails                    0                  0.0<br>IpFragFails                     0                  0.0<br>IcmpInErrors                    5                  0.0<br>IcmpInCsumErrors                0                  0.0<br>IcmpOutErrors                   0                  0.0<br>TcpAttemptFails                 27                 0.0<br>TcpInErrs                       6                  0.0<br>TcpInCsumErrors                 0                  0.0<br>UdpInErrors                     0                  0.0<br>UdpRcvbufErrors                 0                  0.0<br>UdpSndbufErrors                 0                  0.0<br>UdpInCsumErrors                 0                  0.0<br>UdpLiteInErrors                 0                  0.0<br>UdpLiteRcvbufErrors             0                  0.0<br>UdpLiteSndbufErrors             0                  0.0<br>UdpLiteInCsumErrors             0                  0.0<br>Ip6InHdrErrors                  0                  0.0<br>Ip6InTooBigErrors               0                  0.0<br>Ip6InAddrErrors                 0                  0.0<br>Ip6InDiscards                   0                  0.0<br>Ip6OutDiscards                  0                  0.0<br>Ip6ReasmTimeout                 0                  0.0<br>Ip6ReasmFails                   0                  0.0<br>Ip6FragFails                    0                  0.0<br>Icmp6InErrors                   0                  0.0<br>Icmp6OutErrors                  0                  0.0<br>Icmp6InCsumErrors               0                  0.0<br>Udp6InErrors                    0                  0.0<br>Udp6RcvbufErrors                0                  0.0<br>Udp6SndbufErrors                0                  0.0<br>Udp6InCsumErrors                0                  0.0<br>UdpLite6InErrors                0                  0.0<br>UdpLite6RcvbufErrors            0                  0.0<br>UdpLite6SndbufErrors            0                  0.0<br>UdpLite6InCsumErrors            0                  0.0<br>TcpExtSyncookiesFailed          2493               0.0<br>TcpExtLockDroppedIcmps          0                  0.0<br>TcpExtListenOverflows           0                  0.0<br>TcpExtListenDrops               0                  0.0<br>TcpExtTCPPrequeueDropped        0                  0.0<br>TcpExtTCPRenoRecovery           0                  0.0<br>TcpExtTCPSackRecovery           53258339           0.0<br>TcpExtTCPFullUndo               26344              0.0<br>TcpExtTCPRenoFailures           0                  0.0<br>TcpExtTCPSackFailures           2014346            0.0<br>TcpExtTCPLossFailures           102464             0.0<br>TcpExtTCPTimeouts               482369             0.0<br>TcpExtTCPLossProbeRecovery      1789543            0.0<br>TcpExtTCPRenoRecoveryFail       0                  0.0<br>TcpExtTCPSackRecoveryFail       833476             0.0<br>TcpExtTCPSchedulerFailed        0                  0.0<br>TcpExtTCPAbortOnTimeout         1277               0.0<br>TcpExtTCPAbortFailed            0                  0.0<br>TcpExtTCPSACKDiscard            0                  0.0<br>TcpExtTCPBacklogDrop            0                  0.0<br>TcpExtTCPMinTTLDrop             0                  0.0<br>TcpExtTCPDeferAcceptDrop        0                  0.0<br>TcpExtTCPTimeWaitOverflow       0                  0.0<br>TcpExtTCPReqQFullDoCookies      0                  0.0<br>TcpExtTCPReqQFullDrop           0                  0.0<br>TcpExtTCPRetransFail            5889               0.0<br>TcpExtTCPOFODrop                0                  0.0<br>TcpExtTCPFastOpenActiveFail     0                  0.0<br>TcpExtTCPFastOpenPassiveFail    0                  0.0<br>TcpExtTCPFastOpenListenOverflow 0                  0.0<br>IpExtInCsumErrors               0                  0.0<br>IpExtReasmOverlaps              0                  0.0</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">#### softirq networking</span><br></pre></td></tr></table></figure>
<p>$ cat /proc/net/softnet_stat</p>
<h1 id="4-cores"><a href="#4-cores" class="headerlink" title="4 cores"></a>4 cores</h1><p>000cc282 00000000 000004e7 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>0000b828 00000000 00000053 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>0000945b 00000000 00000046 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>0003d716 00000000 000001f7 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</p>
<hr>
<p>   \      _ drop count \                                                  \        -flow limit cont<br>    _ packet count      \                                                  -- cpu collision<br>                          - time sequeeze</p>
<h2 id="in-some-overflow-status"><a href="#in-some-overflow-status" class="headerlink" title="in some overflow status"></a>in some overflow status</h2><p>024fd330 00000000 0000000d 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>01a95901 00000000 00000004 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>026bd147 00000000 00000009 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>036311fc 00000000 00000006 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>032f4c78 00000000 0000000b 00000000 00000000 00000000 00000000 00000000 00000000 00000000<br>01d79287 00000000 0000005a 00000000 00000000 00000000 00000000 00000000 00000000 00000000</p>
<p>#Each line of /proc/net/softnet_stat corresponds to a struct softnet_data structure, of which there is 1 per CPU.</p>
<p>#The values are separated by a single space and are displayed in hexadecimal<br>#The first value, sd-&gt;processed, is the number of network frames processed. This can be more than the total number of network frames received if you are using ethernet bonding. There are cases where the ethernet bonding driver will trigger network data to be re-processed, which would increment the sd-&gt;processed count more than once for the same packet.</p>
<p>The second value, sd-&gt;dropped, is the number of network frames dropped because there was no room on the processing queue. More on this later.<br>If second values are gorwing, improve sysctl -w net.core.netdev_max_backlog = 2000, A value over 10000 is unlikely to be very helpful.<br>The second colume number of frames dropped due to netdev_max_backlog being exceeded</p>
<p>The netdev_max_backlog is a queue within the Linux kernel where traffic is stored after reception from the NIC, but before processing by the protocol stacks (IP, TCP, etc). There is one backlog queue per CPU core.<br>In CentOS 7.8 the default is 100000</p>
<p>#The third value, sd-&gt;time_squeeze, is (as we saw) the number of times the net_rx_action loop terminated because the budget was consumed or the time limit was reached, but more work could have been. Increasing the budget as explained earlier can help reduce this.<br>#If 3rd column is growing,improve sysctl -w net.core.netdev_budget=600<br>Be careful of increasing this value unless there is a very good reason. A value exceeding 1000 is unlikely to be very helpful. In fact increasing this value too much can have detrimental effect and in the worse case scenario lead to softirq hangs or performance problems, as the softirqs can run for too long and starve other processes of CPU<br>3rd colume is number of times ksoftirqd ran out of netdev_budget or CPU time when there was still work to be done</p>
<p>#The next 5 values are always 0.</p>
<p>#The ninth value, sd-&gt;cpu_collision, is a count of the number of times a collision occurred when trying to obtain a device lock when transmitting packets. This article is about receive, so this statistic will not be seen below.</p>
<p>#The tenth value, sd-&gt;received_rps, is a count of the number of times this CPU has been woken up to process packets via an Inter-processor Interrupt</p>
<p>#The last value, flow_limit_count, is a count of the number of times the flow limit has been reached. Flow limiting is an optional Receive Packet Steering feature that will be examined shortly.</p>
<p>#If you decide to monitor this file and graph the results, you must be extremely careful that the ordering of these fields hasn’t changed and that the meaning of each field has been preserved. You will need to read the kernel source to verify this.</p>
<p>seq_printf(seq,<br>       “%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n”,<br>       sd-&gt;processed, sd-&gt;dropped, sd-&gt;time_squeeze, 0,<br>       0, 0, 0, 0, /* was fastroute */<br>       sd-&gt;cpu_collision, sd-&gt;received_rps, flow_limit_count);</p>
<p>#convert these data by bash</p>
<p>cat ./softnet_stat.sh<br>#!/bin/bash<br>awk ‘BEGIN {<br>     t[1]=”sd-&gt;processed”<br>     t[2]=”sd-&gt;dropped”<br>     t[3]=”sd-&gt;time_squeeze”<br>     t[9]=”sd-&gt;cpu_collision”<br>     t[10]=”sd-&gt;received_rps”<br>     printf “%s %s %s %s %s\n”,t[1],t[2],t[3],t[9],t[10];<br>}</p>
<p>{<br>   printf “%d %d %d %d %d\n”, strtonum( “0x”$1 ),strtonum( “0x”$2 ),strtonum( “0x”$3 ),strtonum( “0x”$9 ),strtonum( “0x”$10 )<br>}’  /proc/net/softnet_stat | column -t</p>
<h2 id="Full-throughput-duplex"><a href="#Full-throughput-duplex" class="headerlink" title="Full throughput duplex"></a>Full throughput duplex</h2><p>$ watch -d sh ./softnet_stat.sh<br>Every 2.0s: sh ./softnet_stat.sh                                                                                                  Mon Feb 17 00:23:15 2020</p>
<p>sd-&gt;processed  sd-&gt;dropped  sd-&gt;time_squeeze  sd-&gt;cpu_collision  sd-&gt;received_rps<br>46897674       0            15                0                  0<br>33150875       0            4                 0                  0<br>46371491       0            10                0                  0<br>64446426       0            7                 0                  0<br>57994272       0            11                0                  0<br>34935375       0            90                0                  0</p>
<h3 id="when-I-was-watch-it-the-time-squeeze-not-increased-only-slowly-increasing-at-rx-steer-missed-packets-1623"><a href="#when-I-was-watch-it-the-time-squeeze-not-increased-only-slowly-increasing-at-rx-steer-missed-packets-1623" class="headerlink" title="when I was watch it, the time_squeeze not increased. only slowly increasing at rx_steer_missed_packets: 1623"></a>when I was watch it, the time_squeeze not increased. only slowly increasing at rx_steer_missed_packets: 1623</h3><p>#Herer is mellanox doc: Number of packets that was received by the NIC, however was discarded because it did not match any flow in the NIC flow table. supported from kernel 4.16</p>
<h1 id="here-is-2-v-1-test-case-node-1-and-node-2-send-and-receive-to-node-3-there-is-no-tcp-retrans-in-node-little-0-5-s-but-it-was-full-throughput-bond-dual-port-tx-2-4GB-s-tx-2-4GB-s-only-a-lot-of-tcp-retrans-in-node-1-and-node-2-190-200-s"><a href="#here-is-2-v-1-test-case-node-1-and-node-2-send-and-receive-to-node-3-there-is-no-tcp-retrans-in-node-little-0-5-s-but-it-was-full-throughput-bond-dual-port-tx-2-4GB-s-tx-2-4GB-s-only-a-lot-of-tcp-retrans-in-node-1-and-node-2-190-200-s" class="headerlink" title="here is 2 v 1 test case,  node 1 and node 2 send and receive to node 3, there is no tcp retrans in node(little , 0.5/s), but it was full throughput (bond, dual port, tx:2.4GB/s tx 2.4GB/s), only a lot of tcp retrans in node 1 and node 2 (190~200/s)"></a>here is 2 v 1 test case,  node 1 and node 2 send and receive to node 3, there is no tcp retrans in node(little , 0.5/s), but it was full throughput (bond, dual port, tx:2.4GB/s tx 2.4GB/s), only a lot of tcp retrans in node 1 and node 2 (190~200/s)</h1><p>If you follow the softnet_break label you stumble upon something interesting. From net/core/dev.c:<br>softnet_break:<br>  sd-&gt;time_squeeze++;<br>  __raise_softirq_irqoff(NET_RX_SOFTIRQ);<br>  goto out;</p>
<p>/sys/class/net/em2/statistics/<br>/proc/net/dev</p>
<p>$ netstat -s | grep -i retr<br>    905260805 segments retransmited<br>    9599 times recovered from packet loss due to fast retransmit<br>    TCPLostRetransmit: 6059087<br>    152 timeouts after reno fast retransmit<br>    737224794 fast retransmits<br>    13068581 forward retransmits<br>    146850567 retransmits in slow start<br>    1015 classic Reno fast retransmits failed<br>    3214020 SACK retransmits failed<br>    TCPRetransFail: 16<br>    TCPSynRetrans: 61</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[tcpretrans](http:<span class="comment">//www.brendangregg.com/blog/2014-09-06/linux-ftrace-tcp-retransmit-tracing.html)</span></span><br><span class="line">```bash</span><br><span class="line"><span class="number">11</span>:<span class="number">14</span>:<span class="number">40</span> <span class="number">0</span>      <span class="number">10.0</span><span class="number">.19</span><span class="number">.53</span>:<span class="number">988</span>      R&gt; <span class="number">10.0</span><span class="number">.4</span><span class="number">.143</span>:<span class="number">1022</span>     ESTABLISHED</span><br><span class="line"><span class="number">11</span>:<span class="number">14</span>:<span class="number">40</span> <span class="number">0</span>      <span class="number">10.0</span><span class="number">.19</span><span class="number">.53</span>:<span class="number">988</span>      R&gt; <span class="number">10.0</span><span class="number">.4</span><span class="number">.143</span>:<span class="number">1022</span>     ESTABLISHED</span><br><span class="line"><span class="number">11</span>:<span class="number">14</span>:<span class="number">40</span> <span class="number">0</span>      <span class="number">10.0</span><span class="number">.19</span><span class="number">.53</span>:<span class="number">988</span>      R&gt; <span class="number">10.0</span><span class="number">.4</span><span class="number">.143</span>:<span class="number">1022</span>     ESTABLISHED</span><br><span class="line"></span><br><span class="line">$ grep -E <span class="string">&quot;CPU0|enp1s0f0&quot;</span> /proc/<span class="built_in">int</span>errupts</span><br><span class="line">           CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7</span><br><span class="line"> <span class="number">48</span>:          <span class="number">0</span>          <span class="number">0</span>          <span class="number">1</span>          <span class="number">0</span>         <span class="number">73</span>          <span class="number">0</span>        <span class="number">154</span>          <span class="number">0</span>   PCI-MSI <span class="number">524289</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-0</span></span><br><span class="line"> <span class="number">49</span>:         <span class="number">70</span>          <span class="number">0</span>         <span class="number">51</span>         <span class="number">45</span>          <span class="number">0</span>        <span class="number">112</span>          <span class="number">0</span>        <span class="number">121</span>   PCI-MSI <span class="number">524290</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-1</span></span><br><span class="line"> <span class="number">50</span>:         <span class="number">34</span>          <span class="number">0</span>        <span class="number">273</span>         <span class="number">90</span>         <span class="number">33</span>         <span class="number">53</span>          <span class="number">0</span>          <span class="number">7</span>   PCI-MSI <span class="number">524291</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-2</span></span><br><span class="line"> <span class="number">51</span>:      <span class="number">83286</span>          <span class="number">0</span>          <span class="number">0</span>        <span class="number">229</span>          <span class="number">0</span>          <span class="number">1</span>          <span class="number">0</span>          <span class="number">0</span>   PCI-MSI <span class="number">524292</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-3</span></span><br><span class="line"> <span class="number">52</span>:          <span class="number">0</span>        <span class="number">226</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">5</span>          <span class="number">0</span>          <span class="number">1</span>          <span class="number">0</span>   PCI-MSI <span class="number">524293</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-4</span></span><br><span class="line"> <span class="number">53</span>:         <span class="number">29</span>          <span class="number">0</span>        <span class="number">192</span>         <span class="number">72</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">1</span>   PCI-MSI <span class="number">524294</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-5</span></span><br><span class="line"> <span class="number">54</span>:         <span class="number">16</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">5</span>        <span class="number">438</span>         <span class="number">11</span>   PCI-MSI <span class="number">524295</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-6</span></span><br><span class="line"> <span class="number">55</span>:         <span class="number">78</span>          <span class="number">1</span>          <span class="number">0</span>          <span class="number">0</span>          <span class="number">0</span>       <span class="number">6430</span>          <span class="number">0</span>      <span class="number">13438</span>   PCI-MSI <span class="number">524296</span>-edge      i40e-enp1s0f0-TxRx<span class="number">-7</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="kernel-improved"><a href="#kernel-improved" class="headerlink" title="kernel improved"></a>kernel improved</h5><p>linux 4.4 lockless listener<br>&lt; linux 4.4, each listener has a request queue. after insert a new request the each sync package will lock listener</p>
<blockquote>
<p>= linux 4.4 create an new tcp ehash table for reduece the lock compete </p>
</blockquote>
<p>tcp_probe<br>That function is now replaced by tcp/tcp_probe trace-event. You can use it via ftrace or perftools</p>
<h4 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -S enp1s0f0 | grep -Ei <span class="string">&#x27;fail|crc|dis|drop|miss|err|over|timeout|jabb|full|retrans|out.*of|restar|collis&#x27;</span></span><br><span class="line">     rx_errors: 0</span><br><span class="line">     tx_errors: 0</span><br><span class="line">     rx_dropped: 0</span><br><span class="line">     tx_dropped: 0</span><br><span class="line">     rx_over_errors: 0</span><br><span class="line">     rx_crc_errors: 0</span><br><span class="line">     rx_frame_errors: 0</span><br><span class="line">     fdir_miss: 710538</span><br><span class="line">     fdir_overflow: 0</span><br><span class="line">     rx_fifo_errors: 0</span><br><span class="line">     rx_missed_errors: 0</span><br><span class="line">     tx_aborted_errors: 0</span><br><span class="line">     tx_carrier_errors: 0</span><br><span class="line">     tx_fifo_errors: 0</span><br><span class="line">     tx_heartbeat_errors: 0</span><br><span class="line">     tx_timeout_count: 0</span><br><span class="line">     rx_length_errors: 0</span><br><span class="line">     rx_long_length_errors: 0</span><br><span class="line">     rx_short_length_errors: 0</span><br><span class="line">     rx_csum_offload_errors: 0</span><br><span class="line">     alloc_rx_page_failed: 0</span><br><span class="line">     alloc_rx_buff_failed: 0</span><br><span class="line">     tx_hwtstamp_timeouts: 0</span><br><span class="line">     fcoe_bad_fccrc: 0</span><br><span class="line">     rx_fcoe_dropped: 0</span><br><span class="line"></span><br><span class="line">$ ethtool -S p2p2 | grep -Ei <span class="string">&#x27;fail|crc|dis|drop|miss|err|over|timeout|jabb&#x27;</span></span><br><span class="line">     rx_errors: 0</span><br><span class="line">     tx_errors: 0</span><br><span class="line">     rx_dropped: 0</span><br><span class="line">     tx_dropped: 0</span><br><span class="line">     rx_length_errors: 0</span><br><span class="line">     rx_crc_errors: 0</span><br><span class="line">     rx_alloc_fail: 0</span><br><span class="line">     rx_pg_alloc_fail: 0</span><br><span class="line">     veb.rx_discards: 0</span><br><span class="line">     veb.tx_discards: 0</span><br><span class="line">     veb.tx_errors: 0</span><br><span class="line">     port.tx_errors: 0</span><br><span class="line">     port.rx_dropped: 0</span><br><span class="line">     port.tx_dropped_link_down: 0</span><br><span class="line">     port.rx_crc_errors: 0</span><br><span class="line">     port.tx_timeout: 0</span><br><span class="line">     port.rx_length_errors: 0</span><br><span class="line">     port.rx_oversize: 0</span><br><span class="line">     port.rx_jabber: 0</span><br><span class="line">     port.arq_overflows: 0</span><br><span class="line">     port.tx_hwtstamp_timeouts: 0</span><br></pre></td></tr></table></figure>
<p>rx_no_buffer_count,there was nowhere to DMA the packet<br>DMA skb-data to rx-buffer-info(linux RAM, soft-interrupt).</p>
<p>RNBC is a warning sign of a slow drain from the MAC and can be treated by adding more buffers.<br>There will be times when the RNBC will go up, but it will look like the stack and driver have a ton of buffers but work is not being done.  If you have a task that is eating up the CPU, the ISR or polling routines won’t refill the buffers fast enough and RNBC will happen.</p>
<p>Imagine we have a slow CPU, but a wicked fastbus.  The software is very slow to process the descriptors and return them, but once the descriptors are given to the hardware, it empties the backlog (read the FIFO) faster than the incoming frames are filling the FIFO.  Returning to our kitchen sink analogy, the water is coming in at a fairly constant rate.  But imagine the stopper is down, making the sink fill up.  Just before it over flows, the drain is opened and down it goes.  Once the water doesn’t go down the drain would be the same moment our RNBC would be incremented.  The kitchen sink itself becomes our FIFO and if the FIFO is big enough, it can save frame for quiet some time.  This is 1 Gigabit (or faster) that we’re talking about, so with a good sized FIFO (24K RX for example) that’s only 375 frames at 64 bytes, or 267microseconds of data.  That’s not very much time.  But in a world full of 2 and 3 Gigahertz CPUs that’s long enough.</p>
<p>rx_missed_error,rx_no_buffer_count happened enough times that packets were dropped<br>MPC is a failure condition leading to dropped packets and can be treated with more buffers and faster interconnect buses</p>
<p><code>fifo queues(ring buffer or kernel queue?) full will cause the error too ? and the package not go to NIC reveive ring buffer(ring buffer or kernel queue ?), if you have no any CPU or memory resource, you will got the same result, NIC/CPU/MEM resource not enough will cause the same issue</code></p>
<p><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/counters-troubleshooting-for-linux-driver">Counters Troubleshooting for Linux Driver</a><br>rx_errors: Number of received packets that were dropped due to PHY layer related errors. For example:</p>
<ul>
<li>symbol error, or an invalid block.</li>
<li>Length related errors (greater than MTU octets, length less than 64 octets, error in length)</li>
<li>Bad CRC that are not runts, jabbers, or alignment errors.</li>
<li>This counter is increased at point (1) in the figure above.</li>
</ul>
<p>rx_dropped: Number of received packets which were chosen to be discarded even though no errors had been detected to prevent them from passing to the upper layer. For example, drop due to buffer overflow.</p>
<p>rx_crc_errors: Number of received frames with a bad CRC that are not runts, jabbers, or alignment errors.</p>
<p>rx_jabbers: Number of received frames with a length greater than MTU octets and a bad CRC.</p>
<p>rx_fifo_errors: an indication that the RX interrupts cannot allocate buffers fast enough and so the adapter is dropping packets.</p>
<p>rx_over_errors: Number of received frames that were dropped due to on hardware port receive buffer overflow.</p>
<p>tx_errors: Number of frames that failed to transmit. Include frame dropped due to error in the length field.</p>
<p>tx_dropped: Number of transmitted frames that were dropped.</p>
<p>vport_rx_dropped: Received packets discarded due to luck of software receive buffers (WQEs).<br>Important indication to weather RX completion routines are keeping up with HW ingress packet rate.</p>
<p>vport_rx_filtered: Received packets dropped due to packet check that was failed. For example:</p>
<ul>
<li>Incorrect VLAN</li>
<li>Incorrect Ethertype</li>
<li>unavailable queue/QP</li>
<li>Loopback prevention<br>This counter is increased at point (2) in the figure above.<br>Note: In high performance scenarios vport_rx_filters may increment due to rx_over_errors. In addition,<br>In SRIOV configurations vport_rx_filters increments can be seen and it is a normal condition (expected).</li>
</ul>
<p>vport_tx_errors: Packets dropped due to transmit errors.</p>
<p>counter:</p>
<p>rx_lro_aggregated: The number of packets processed by the LRO (Large Receive Offload) mechanism (good for IPv4 TCP), and should be equal to rx_packets in good/normal condition.</p>
<p>rx_lro_flushed: The number of offloaded packets the LRO mechanism passed to kernel. Ideally the packet size is 64KB (depends on kernel). 64KB is the maximum packet size.</p>
<p>rx_lro_no_desc: This is abnormal condition, and mostly will not happen. The LRO mechanism has no room to receive packets from the adapter. In normal condition, it should not increase, mostly when using 64 packets budget and flush LRO descriptors every NAPI cycle. In addition, LRO has a lot of space (much more than 64).</p>
<p>tx_tso_packets: When using TCO (TCP Segmentation Offload), it offloads tasks from the CPU and improve CPU utilization. This counter shows the number of offloaded TSO packets received by the driver from the TCP layer. The rate of TSO This counter is correlated strongly with the TX performance and CPU utilization. TSO is crucial for wire speed performance, and the kernel will enable it only when the CPU is not on heavy load.</p>
<p>tx_queue_stopped: The number of times the kernel didn’t manage to send packets as the queue was full. the tx_queue_stopped and tx_wake_queue are usually equal (TX queue is stopped and later gets wake up call). This is an important indication to whether TX completion routines are keeping up with the transmit routines. If the application is sending in an higher rate than driver is evicting CQEs from the buffer this will start to go up.</p>
<p>tx_wake_queue: The number of time the kernel got message from the adapters that there is a queue to run (tx_queue_stopped is released). his is an important indication to whether TX completion routines are keeping up with the transmit routines. If the application is sending in an higher rate than driver is evicting CQEs from the buffer this will start to go up.</p>
<p>tx_timeout: This a rare event, that usually indicate on a severe issue. It means around 15 sec timeframe that passed since a packet was sent without a CQE generated. Usually a lost interrupt or a bad cable.</p>
<p>rx_csum_good: The number of packets received with good checksum (in L4).</p>
<p>rx_csum_none: The number of packets received with no checksum (in L4).</p>
<p>tx_cksum_offload: The number of packets sent with hardware checksum.</p>
<h3 id="About-TCP-fast-retrans"><a href="#About-TCP-fast-retrans" class="headerlink" title="About TCP fast retrans"></a><a target="_blank" rel="noopener" href="http://www.ietf.org/rfc/rfc2581.txt">About TCP fast retrans</a></h3><p>twice duplicated ACK because package out of order<br>Dropped packages must be triple duplicated ACK</p>
<p>If A send 4 TCP segments to B, Number is as follow, N-1 reache B because A received ACK(N) of B, As the order, The received ACK number:<br>                  A ———&gt; B<br>A send order was N-1,N,N+1,N+2</p>
<p>B received order</p>
<p>N-1，N，N+1，N+2<br>A received single ACK (N)</p>
<p>N-1，N，N+2，N+1<br>A received single ACK (N)</p>
<p>N-1，N+1，N，N+2<br>A received twice ACK (N)</p>
<p>N-1，N+1，N+2，N<br>A received triple ACK (N)</p>
<p>N-1，N+2，N，N+1<br>A received twice ACK (N)</p>
<p>N-1，N+2，N+1，N<br>A received triple ACK (N)</p>
<p>If N loss, or not reach B</p>
<p>N-1，N+1，N+2<br>A received triple ACK (N)</p>
<p>N-1，N+2，N+1<br>A received triple ACK (N)</p>
<p>TCP segment out of order, there are 2/5 = 40% cause A received triple duplicated ACK(N);<br>If N loss, the ratio is 100%</p>
<p>When A received triple duplicated ACK(N) and start a Fast Retransmit is OK , retransmit N right now, It ‘s need to Fast Recovery, for reduce the package loss problem</p>
<p>If A receive twice duplicated ACK(N),It ‘s must be out of order that means all packages has reach B, Just re-sort all packages, Don’ t need to retrans.</p>
<h5 id="ABout-TCP-segment-out-of-order"><a href="#ABout-TCP-segment-out-of-order" class="headerlink" title="ABout TCP segment out of order"></a>ABout TCP segment out of order</h5><p>TCP segment packing in IP packages，If IP package out of order,also tcp</p>
<ol>
<li>ECMP loading balance</li>
</ol>
<p>multiple path loading balance, base per-packet load balance，eg: packet 1,3,5 go path1, packet 2,4,6 go to path2, it’s hard to control packet 1 arrived early than packet 2 reach the destination</p>
<p>Per-session load balance base TCP 5 tuple(source ip,source port,des ip,des port, transfer protocol), the same TCP session will go to a same path</p>
<ol start="2">
<li>route internal traffic scheduling<br>There are multiple traffic process unit in some of route(stream process unit),eg: packet 1,3,5 process by unit1, packet 2,4,6 process by unit2, it’s hard to control packet 1 arrived early than packet 2 reach the destination</li>
</ol>
<p>kernel receive out of order TCP segment, put them to buffer and then all TCP segment has arrived, after re-sort, send all data to application<br>Out of order segment will cause buffer consumption, direct trigger B advertised window size be samller, cause send A window get smaller and smaller,to impact sender’s transmission performance.</p>
<p>If A not do fast retrans，at last it will be retrans by retransmit timer timeout(timeout retransmit),but at this time there is a little winodow size in A, sender A ‘s transmission speed will be too bad.</p>
<p>Before there is no fast retransmit/recovery, retrans by sender ‘s retransmit timeout,In timeout range, if sender not receive receiver’s ack hat means the package loss, sender will resend it.</p>
<ul>
<li>Why package loss<ul>
<li>package checksum error</li>
<li>Traffic jam/Network congestion</li>
<li>Network connection loss for some unknow reason</li>
<li>Some of convergence-algorithm in your route</li>
</ul>
</li>
</ul>
<p>But sender don ‘t know what the situation,<br>The stupid way is sender set half of speed(CWND=1/2),It ‘s good at traffic jam,if connection loss, all packages will loss no matter sender slowing down,For checksum erorr,loss packages is a happenstance.If I loss a package, sender will tuning down the speed, So fast retransmit come out because receiver could recevice the ACK ,because connection has not loss,if in timeout range not receive large than 2 duplicated ACK thaat means maybe is out of order,don ‘t need retrans, just re-sort in receiver.<br>But if sender receive &gt;= 3 x duplicated ACK,loss package has the high possibility.<br>That means sender could receive ACK,The network connection not loss,retrans it first,don ‘t slowing down the speed, if got the correct ACK that means there is no problem and drop that package, If still recive duplicated ACK, maybe it ‘s traffic jam, slowing down the speed.</p>
<h3 id="NIC-receive-data"><a href="#NIC-receive-data" class="headerlink" title="NIC receive data"></a><a target="_blank" rel="noopener" href="https://wsgzao.github.io/post/rps/">NIC receive data</a></h3><p>I guess NIC transfer data by the frame, and the frame has be splitted in sk_buff</p>
<p>packet -&gt; NIC -&gt; internal hardware buffer or ring buffer -&gt; hardware interrupt request -&gt; software interrupt operation -&gt;<br>from buffer to network stack -&gt; forwarded/discarded/rejected/passed to a socket receive queue for an application -&gt;<br>remove from network stack until no packets left in NIC buffer or a certain number of packets are transferred (/proc/sys/net/core/dev_weight)</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in"> network </span>(packages)</span><br><span class="line">  |</span><br><span class="line">  |</span><br><span class="line"> NIC   (hardware)</span><br><span class="line">  |</span><br><span class="line">  | &lt;-------DMA copy the package <span class="keyword">to</span> ring bufffer</span><br><span class="line">rx ring buffer (kernel memory)</span><br><span class="line">  | </span><br><span class="line">  | </span><br><span class="line">Driver  (kernel)  trigger a<span class="built_in"> hardware </span>interrupt <span class="keyword">to</span> kernel( ring buffer got a package)</span><br><span class="line">  |               The NIC <span class="keyword">from</span> the driver raised the<span class="built_in"> IRQ </span><span class="keyword">to</span> the kernel -- &gt; the kernel runs<span class="built_in"> IRQ </span>handler --&gt; NAPI started</span><br><span class="line">  |</span><br><span class="line">  |  &lt;---driver call into NAPI <span class="keyword">to</span> start a poll loop <span class="keyword">if</span> NAPI was <span class="keyword">not</span> running already</span><br><span class="line">NAPI <span class="keyword">or</span> backlog (ksoftirqd call NAPI poll function got the package <span class="keyword">from</span> ring buffer) </span><br><span class="line">  |  &lt;---ring buffer unmapped the memory <span class="keyword">from</span> the package</span><br><span class="line">  |  &lt;---Data that was DMA’d into memory is passed up the networking layer as an <span class="string">&#x27;skb&#x27;</span> <span class="keyword">for</span> more processing.</span><br><span class="line">  |  NAPI poller is added <span class="keyword">to</span> poll_list -&gt; softirq_pending bit <span class="builtin-name">set</span> -&gt;  run_ksoftirqd checks softirq_pending bit -&gt; Registered handler called <span class="keyword">from</span> softirq_vec handlers</span><br><span class="line">  |   (<span class="keyword">from</span> softnet_data Poll list)       (<span class="keyword">to</span> softirq_pending bits)   (ksoftirqd/0 <span class="keyword">if</span> pending -&gt; __do_softirq() -&gt; net_rx_action())</span><br><span class="line">  |  </span><br><span class="line">  | poll_list entry received -&gt; Budget <span class="keyword">and</span> Elapsed Time Checked -&gt; Driver poll function called -&gt;  Packet harvested <span class="keyword">from</span> ring buffer</span><br><span class="line">  |  </span><br><span class="line">  |  Without NAPI: 1 interrupt per packet → high CPU load                                                                     </span><br><span class="line">  |  With NAPI: polling during high packet arrival times</span><br><span class="line">  |  <span class="literal">No</span> work <span class="keyword">to</span> drop packets <span class="keyword">if</span> kernel is too busy (Ring buffer overwrite by NIC)</span><br><span class="line">  |  the ringbuffer is the RAM, <span class="keyword">if</span> there is <span class="literal">no</span> special design</span><br><span class="line">  |                                                                     </span><br><span class="line">packet steering (Incoming<span class="built_in"> network </span>data frames are distributed among multiple CPUs <span class="keyword">if</span> packet steering support)</span><br><span class="line">  |</span><br><span class="line">  |  continue by <span class="string">&quot;Driver poll function called&quot;</span> -&gt; Packets passed <span class="keyword">for</span> possible GRO -&gt; Packets coalesced <span class="keyword">or</span> passed on toward  protocol stacks</span><br><span class="line">  |</span><br><span class="line">  |  (net_rx_action() -&gt; softnet_data Poll list -&gt; mydrv_poll() -&gt; napi_gro_receive() ---------&gt; net_receive_skb)</span><br><span class="line">  |                                                    | Packet harvested <span class="keyword">from</span> ring buffer   |  Packets coalesced <span class="keyword">or</span> passed on toward protocol stacks</span><br><span class="line">  |                                                    |---&gt;ring buffer                      |---&gt;GRO list</span><br><span class="line">  |</span><br><span class="line">network protocol stacks(TCP<span class="built_in">/IP </span>Ethernet) (kernel, the data frames are handed <span class="keyword">to</span> the protocol layers <span class="keyword">from</span> the queues)</span><br><span class="line">  |</span><br><span class="line">  |</span><br><span class="line">socket buffer (kernel)</span><br><span class="line">  |</span><br><span class="line">  |</span><br><span class="line">Application  (user)</span><br></pre></td></tr></table></figure>
<p>Some devices have the ability to write incoming packets to several different regions of RAM simultaneously; each region is a separate queue. This allows the OS to use multiple CPUs to process incoming data in parallel, starting at the hardware level.</p>
<p>Interrupts are re-enabled after polling stops</p>
<ul>
<li>NAPI Exit<ul>
<li>No more NAPI poll structures to process</li>
<li>netdev_budget Exceeded<ul>
<li>Each driver hardcoded budget for one NAPI structure of 64</li>
<li>Default is 300</li>
<li>Approximately 5 driver poll calls</li>
</ul>
</li>
<li>softirq Time Window Exceeded</li>
</ul>
</li>
<li>If no structures remain, re-enable IRQ interrupt</li>
</ul>
<h4 id="NIC-lt-–-gt-driver"><a href="#NIC-lt-–-gt-driver" class="headerlink" title="NIC &lt;–&gt; driver"></a>NIC &lt;–&gt; driver</h4><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">  --<span class="number">-1.</span> Allocate sk_buffer---&gt; SKB|<span class="type">SKB</span>|<span class="type">SKB</span> (memory) &lt;-------- <span class="number">6.</span> Write packet <span class="built_in">by</span> DMA ----------</span><br><span class="line">  |                                                                                           <span class="type">|</span></span><br><span class="line"><span class="type">Driver</span>                                                                                       NIC &lt;---- <span class="number">5.</span> New packet</span><br><span class="line">|   <span class="type">|                                                                                        | |</span></span><br><span class="line"><span class="type">|   ----2</span>. Write description to rx <span class="built_in">ring</span> ---&gt; RX <span class="built_in">ring</span> (memory) &lt;--------<span class="number">-4.</span> Fetch description <span class="built_in">by</span> DMA --- |<span class="type"></span></span><br><span class="line"><span class="type">|                                                                                              |</span></span><br><span class="line"><span class="type">-------------------------------3</span>. tell NIC there are some new descriptons----------------------|<span class="type"></span></span><br><span class="line"><span class="type"></span></span><br><span class="line"><span class="type"> The</span> <span class="built_in">ring</span> buffer is a FIFO queue</span><br><span class="line">              |<span class="type"></span></span><br><span class="line"><span class="type">              V</span></span><br><span class="line">The packet descriptor one <span class="built_in">by</span> one (ready or used status)</span><br><span class="line">              |<span class="type"></span></span><br><span class="line"><span class="type">              V</span></span><br><span class="line">each ready descriptor point an empty sk_buff (? point sk_buff failed, no <span class="built_in">enough</span> mem/cpu cause issue)</span><br></pre></td></tr></table></figure>
<ul>
<li>the kernel driver speed &lt; NIC receive packets, after the ring buffer full cause packet loss (rx_fifo_errors = proc/net/dev fifo = ifconfig overruns increase)<ul>
<li>overruns/fifo counts that times when there is fifo overruns caused by the rate at which the buffer gets full and the kernel isn’t able to reclaim the buffer<ul>
<li>No cpu resource, interrupt not balance and not affinity, eg: all nic interrupt in core0<ul>
<li>/proc/net/dev fifo increase (ifconfig overrun)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>After 6. write packet to SKB by DMA (hardware to driver) –&gt; NIC send a hardware interrupt(hardware) –&gt; CPU receive the interrupt(drivers) –&gt; kernel interrupt handler, send a soft interrupt(kernel) –&gt; kernel soft interrrupt hander –&gt; copy the SKB data to tcp/ip stacks (kernel)</p>
<h4 id="NIC-Data-Processing"><a href="#NIC-Data-Processing" class="headerlink" title="NIC Data Processing"></a><a target="_blank" rel="noopener" href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf">NIC Data Processing</a></h4><h5 id="ring-buffer"><a href="#ring-buffer" class="headerlink" title="ring buffer"></a>ring buffer</h5><p>Does the ring buffer in ethernet NIC or it ‘s just server memory ?<br>Yes, NIC has the microprocess and system memory, but it’s not ring buffer in linux</p>
<p>High end ethernet cards(eg: Mellanox) will almost certainly have their own memory and microprocessors to offload work from the rest of the computer.<br>BTW: eg: if tcp stack offload by NIC and bypass kernel that means the ring buffer in NIC.</p>
<p>Low end ethernet cards may not have their own onboard memory or microprocessors, and will use the host system’s resources to handle network traffic.<br>BTW: I think if you NIC adapter could not offload anything, that means all packages will process by linux, some low end ethernet cards could bypass kernel too, could use direct memory access for some of IO</p>
<p>Infiniband cards on the other hand will tend to have their own onboard processors but no onboard memory, and will use direct memory access for all IO.<br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/17154759/how-much-memory-does-a-common-nic-have">reference</a></p>
<p><a target="_blank" rel="noopener" href="https://www.ibm.com/support/knowledgecenter/en/SSQPD3_2.6.0/com.ibm.wllm.doc/nicringbuffers.html">Ring buffers on the NIC are important to handle bursts of incoming packets especially if there is some delay when the hardware interrupt handler schedules the packet receiving software interrupt (softirq). NIC ring buffer sizes vary per NIC vendor and NIC grade (that is, server or desktop). By increasing the Rx/Tx ring buffer size as shown below, you can decrease the probability of discarding packets in the NIC during a scheduling delay. The tool used to change ring buffer settings is the Linux utility, ethtool.</a></p>
<p><a target="_blank" rel="noopener" href="https://ylgrgyq.github.io/2017/07/23/linux-receive-packet-1/">reference2</a><br><img src="/img/ring-buffer.png"><br><img src="/img/2012110119582618-tcp-reception.png"><br><img src="/img/2012110119593557-tcp-transmission.png"></p>
<h3 id="sriov-doc"><a href="#sriov-doc" class="headerlink" title="sriov doc"></a><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/www/public/us/en/documents/technology-briefs/xl710-sr-iov-config-guide-gbe-linux-brief.pdf">sriov doc</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## intel</span></span><br><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;intel_iommu=on&#x27;</span></span><br><span class="line"><span class="comment">## AMD</span></span><br><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;iommu=pt&#x27;</span></span><br></pre></td></tr></table></figure>

<p><code>Please enable sr-iov in Dell BIOS setting with the NIC</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">On Linux Kernel version 3.8.x and above, the maximum number of VFs supported by the adapter can be queried by reading the sriov_totalvfs parameter via sysfs interface.</span><br><span class="line">```bash</span><br><span class="line">$ dmesg | grep Virtualization</span><br><span class="line">[    0.994611] DMAR: Intel(R) Virtualization Technology <span class="keyword">for</span> Directed I/O</span><br><span class="line"></span><br><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_totalvfs</span><br><span class="line">64</span><br><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line">4</span><br><span class="line">$ lspci | grep Virtual</span><br><span class="line">03:02.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f1/device/sriov_numvfs</span><br><span class="line">modprobe -r i40evf</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 0 mac 52:54:00:e8:a5:78</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 1 mac 52:54:00:e8:a5:79</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 2 mac 52:54:00:e8:a5:80</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 3 mac 52:54:00:e8:a5:81</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 0 mac 52:54:00:e8:a5:82</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 1 mac 52:54:00:e8:a5:83</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 2 mac 52:54:00:e8:a5:84</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 3 mac 52:54:00:e8:a5:85</span><br><span class="line"></span><br><span class="line">$ ip link show ens5f0</span><br><span class="line">19: ens5f0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9000 qdisc mq state UP mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:aa brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:78, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:79, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:80, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:81, spoof checking on, link-state auto, trust off</span><br><span class="line">$ ip link show ens5f1</span><br><span class="line">20: ens5f1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:ab brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:82, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:83, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:84, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:85, spoof checking on, link-state auto, trust off</span><br></pre></td></tr></table></figure>

<h3 id="PCI-init"><a href="#PCI-init" class="headerlink" title="PCI init"></a>PCI init</h3><p>PCI devices are identified by registers in PCI configuration space</p>
<ul>
<li><p>Device drivers are compiled with a list of PCI device IDs that they can<br>control (MODULE_DEVICE_TABLE)</p>
</li>
<li><p>The kernel uses these tables to determine which device drivers to load<br>– Use ‘lspci -nn’ to find your device<br>– Find PCI vendor and device ID<br>– Look in /lib/modules/<code>uname -r</code>/</p>
</li>
<li><p>modules.pcimap (RHEL6 and earlier)</p>
</li>
<li><p>modules.alias (RHEL7 and later)<br> – egrep -i {vid}.*{did} /lib/modules/<code>uname -r</code>/modules.alias</p>
</li>
<li><p>PCI probe functions of the device drivers are called to set up devices</p>
</li>
<li><p>Enable the device</p>
</li>
<li><p>Request memory range &amp; I/O ports</p>
</li>
<li><p>Set DMA mask</p>
</li>
<li><p>Register ethtool functions supported by driver</p>
</li>
<li><p>Watchdog task setup</p>
</li>
<li><p>net_device_ops structure setup<br>– Function pointers for opening, sending data, setting MAC, etc.</p>
</li>
<li><p>net_device struct creation</p>
</li>
</ul>
<h3 id="softirq-Subsystem-Initialization"><a href="#softirq-Subsystem-Initialization" class="headerlink" title="softirq Subsystem Initialization"></a>softirq Subsystem Initialization</h3><p>smpboo.c </p>
<ol>
<li>Create ksoftirqd kernel threads (1 per CPU)</li>
<li>ksoftirqd processing loops started</li>
<li>Per CPU data structures created<br> softnet_data Poll list<br> softirq_pending bits<br> softirq_vec handlers<pre><code>  net/core/dev.c (net_dev_init)</code></pre>
</li>
<li>Softirq handler (net_rx_action) for NET_RX_SOFTIRQ registered</li>
</ol>
<h3 id="ethtool-setting"><a href="#ethtool-setting" class="headerlink" title="ethtool setting"></a>ethtool setting</h3><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">In <span class="regexp">/etc/</span>sysconfig<span class="regexp">/network-scripts/i</span>fcfg</span><br><span class="line">ETHTOOL_OPTS=“-G <span class="variable">$&#123;ifname&#125;</span> &#123;parm&#125; &#123;value&#125;”</span><br><span class="line"></span><br><span class="line">In <span class="regexp">/etc/</span>NetworkManager<span class="regexp">/dispatcher.d/</span></span><br><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;$1&quot;</span> = <span class="string">&quot;eth0&quot;</span> ] &amp;&amp; [ <span class="string">&quot;$2&quot;</span> = <span class="string">&quot;up&quot;</span> ]; then</span><br><span class="line"> ethtool -K <span class="string">&quot;$1&quot;</span> rx off gro off lro off</span><br><span class="line">fi</span><br></pre></td></tr></table></figure>

<h3 id="overrun-and-dropped"><a href="#overrun-and-dropped" class="headerlink" title="overrun and dropped"></a><a target="_blank" rel="noopener" href="http://www.lenky.info/archives/2012/02/1028">overrun and dropped</a></h3><p>linux-3.10.0-1127.el7/include/uapi/linux/if_link.h<br>read the info from /proc/net/dev<br>dropped =  stats-&gt;rx_dropped + stats-&gt;rx_missed_errors(no space in linux buffers/no space available + bad packets received/packet transmit problems)<br>overruns = stats-&gt;rx_fifo_errors (fifo overrun) Receiver overruns usually occur when packets come in faster than the kernel can service the last interrupt.</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/netlink.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* This struct should be in sync with struct rtnl_link_stats64 */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">rtnl_link_stats</span> &#123;</span></span><br><span class="line">        __u32   rx_packets;             <span class="comment">/* total packets received       */</span></span><br><span class="line">        __u32   tx_packets;             <span class="comment">/* total packets transmitted    */</span></span><br><span class="line">        __u32   rx_bytes;               <span class="comment">/* total bytes received         */</span></span><br><span class="line">        __u32   tx_bytes;               <span class="comment">/* total bytes transmitted      */</span></span><br><span class="line">        __u32   rx_errors;              <span class="comment">/* bad packets received         */</span></span><br><span class="line">        __u32   tx_errors;              <span class="comment">/* packet transmit problems     */</span></span><br><span class="line">        __u32   rx_dropped;             <span class="comment">/* no space in linux buffers    */</span></span><br><span class="line">        __u32   tx_dropped;             <span class="comment">/* no space available in linux  */</span></span><br><span class="line">        __u32   multicast;              <span class="comment">/* multicast packets received   */</span></span><br><span class="line">        __u32   collisions;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* detailed rx_errors: */</span></span><br><span class="line">        __u32   rx_length_errors;</span><br><span class="line">        __u32   rx_over_errors;         <span class="comment">/* receiver ring buff overflow  */</span></span><br><span class="line">        __u32   rx_crc_errors;          <span class="comment">/* recved pkt with crc error    */</span></span><br><span class="line">        __u32   rx_frame_errors;        <span class="comment">/* recv&#x27;d frame alignment error */</span></span><br><span class="line">        __u32   rx_fifo_errors;         <span class="comment">/* recv&#x27;r fifo overrun          */</span></span><br><span class="line">        __u32   rx_missed_errors;       <span class="comment">/* receiver missed packet       */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/* detailed tx_errors */</span></span><br><span class="line">        __u32   tx_aborted_errors;</span><br><span class="line">        __u32   tx_carrier_errors;</span><br><span class="line">        __u32   tx_fifo_errors;</span><br><span class="line">        __u32   tx_heartbeat_errors;</span><br><span class="line">        __u32   tx_window_errors;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* for cslip etc */</span></span><br><span class="line">        __u32   rx_compressed;</span><br><span class="line">        __u32   tx_compressed;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> __GENKSYMS__</span></span><br><span class="line">        __u32   rx_nohandler;           <span class="comment">/* dropped, no handler found    */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h3 id="82599-limit"><a href="#82599-limit" class="headerlink" title="82599 limit"></a><a target="_blank" rel="noopener" href="https://decodezp.github.io/2020/12/14/test26-82599-fdir-limit/">82599 limit</a></h3><ul>
<li>no RSS queue-region</li>
<li>ipv6 only support Signature Mode</li>
<li>Input_set global mask</li>
<li>Could not config Input_set</li>
</ul>
<h3 id="CentOS-7-packet-dropped-because-virtual-memmory-performance"><a href="#CentOS-7-packet-dropped-because-virtual-memmory-performance" class="headerlink" title="CentOS 7 packet dropped because virtual memmory performance"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/4085851">CentOS 7 packet dropped because virtual memmory performance</a></h3><p><a target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8fe809a992639b2013c0d8da2ba55cdea28a959a">add LINUX_MIB_PFMEMALLOCDROP counter</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># I trace the work flow</span></span><br><span class="line">do_IRQ</span><br><span class="line">  irq_exit</span><br><span class="line">     do_softirq</span><br><span class="line">       __do_softirq</span><br><span class="line">          net_rx_action</span><br><span class="line">            i40e_napi_poll</span><br><span class="line">              i40e_clean_rx_irq</span><br><span class="line">                napi_gro_receive</span><br><span class="line">                  netif_receive_skb_internal</span><br><span class="line">                    __netif_receive_skb</span><br><span class="line">                      __netif_receive_skb_core</span><br><span class="line">                        ip_rcv</span><br><span class="line">                          ip_rcv_finish</span><br><span class="line">                            ip_local_deliver</span><br><span class="line">                              ip_local_deliver_finish</span><br><span class="line">                                tcp_v4_rcv</span><br><span class="line">                                  tcp_md5_do_lookup</span><br><span class="line">                                    tcp_parse_md5sig_option</span><br><span class="line">                                      tcp_filter</span><br><span class="line">                                        sk_filter_trim_cap (<span class="built_in">return</span> -12 ENOMEM out of memory)</span><br><span class="line"></span><br><span class="line">linux-3.10.0-1127.el7/net/core/filter.c</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> *      sk_filter_trim_cap - run a packet through a socket filter</span><br><span class="line"> *      @sk: sock associated with &amp;sk_buff</span><br><span class="line"> *      @skb: buffer to filter</span><br><span class="line"> *      @<span class="built_in">cap</span>: <span class="built_in">limit</span> on how short the eBPF program may trim the packet</span><br><span class="line"> *</span><br><span class="line"> * Run the filter code and <span class="keyword">then</span> cut skb-&gt;data to correct size returned by</span><br><span class="line"> * sk_run_filter. If pkt_len is 0 we toss packet. If skb-&gt;len is smaller</span><br><span class="line"> * than pkt_len we keep whole skb-&gt;data. This is the socket level</span><br><span class="line"> * wrapper to sk_run_filter. It returns 0 <span class="keyword">if</span> the packet should</span><br><span class="line"> * be accepted or -EPERM <span class="keyword">if</span> the packet should be tossed.</span><br><span class="line"> *</span><br><span class="line"> */</span><br><span class="line">int sk_filter_trim_cap(struct sock *sk, struct sk_buff *skb, unsigned int <span class="built_in">cap</span>)</span><br><span class="line">&#123;</span><br><span class="line">        int err;</span><br><span class="line">        struct sk_filter *filter;</span><br><span class="line"></span><br><span class="line">        /*</span><br><span class="line">         * If the skb was allocated from pfmemalloc reserves, only</span><br><span class="line">         * allow SOCK_MEMALLOC sockets to use it as this socket is</span><br><span class="line">         * helping free memory</span><br><span class="line">         */</span><br><span class="line">        <span class="keyword">if</span> (skb_pfmemalloc(skb) &amp;&amp; !sock_flag(sk, SOCK_MEMALLOC)) &#123;</span><br><span class="line">                NET_INC_STATS(sock_net(sk), LINUX_MIB_PFMEMALLOCDROP);</span><br><span class="line">                <span class="built_in">return</span> -ENOMEM;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        err = security_sock_rcv_skb(sk, skb);</span><br><span class="line">        <span class="keyword">if</span> (err)</span><br><span class="line">                <span class="built_in">return</span> err;</span><br><span class="line"></span><br><span class="line">        rcu_read_lock();</span><br><span class="line">        filter = rcu_dereference(sk-&gt;sk_filter);</span><br><span class="line">        <span class="keyword">if</span> (filter) &#123;</span><br><span class="line">                unsigned int pkt_len = SK_RUN_FILTER(filter, skb);</span><br><span class="line"></span><br><span class="line">                err = pkt_len ? pskb_trim(skb, max(<span class="built_in">cap</span>, pkt_len)) : -EPERM;</span><br><span class="line">        &#125;</span><br><span class="line">        rcu_read_unlock();</span><br><span class="line"></span><br><span class="line">        <span class="built_in">return</span> err;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$ cat /proc/net/netstat</span><br><span class="line">$ nstat -rsz | grep TcpExtPFMemallocDrop</span><br><span class="line">TcpExtPFMemallocDrop            99821                  0.0</span><br><span class="line"></span><br><span class="line">$ ifconfig</span><br><span class="line">RX errors 0  dropped 2561429  overruns 0  frame 0</span><br><span class="line"></span><br><span class="line">$ ethtool -S eno1</span><br><span class="line">rx_dropped: 2561429</span><br></pre></td></tr></table></figure>

<p>I write bpftrace script to trace the error</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">192.168.0.222      814   -&gt; 192.168.0.111    2049 , retval -12</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">/usr/include/asm-generic/errno-base.h</span><br><span class="line"><span class="comment">#define ENOMEM          12      /* Out of memory */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/usr/bin/bpftrace</span></span><br><span class="line"><span class="comment">#include &lt;net/sock.h&gt;</span></span><br><span class="line"><span class="comment">#include &lt;linux/skbuff.h&gt;</span></span><br><span class="line"></span><br><span class="line">k:sk_filter_trim_cap</span><br><span class="line">&#123;</span><br><span class="line">        @sk[tid] = arg0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">kr:sk_filter_trim_cap</span><br><span class="line">/@sk[tid]/</span><br><span class="line">&#123;</span><br><span class="line">        <span class="variable">$sk</span> = (struct sock *)@sk[tid];</span><br><span class="line"></span><br><span class="line">        <span class="variable">$af</span> = <span class="variable">$sk</span>-&gt;__sk_common.skc_family;</span><br><span class="line">        <span class="keyword">if</span> (<span class="variable">$af</span> == AF_INET) &#123;</span><br><span class="line">            <span class="variable">$daddr</span> = ntop(<span class="variable">$af</span>, <span class="variable">$sk</span>-&gt;__sk_common.skc_daddr);</span><br><span class="line">            <span class="variable">$saddr</span> = ntop(<span class="variable">$af</span>, <span class="variable">$sk</span>-&gt;__sk_common.skc_rcv_saddr);</span><br><span class="line">            <span class="variable">$lport</span> = <span class="variable">$sk</span>-&gt;__sk_common.skc_num;</span><br><span class="line">            <span class="variable">$dport</span> = <span class="variable">$sk</span>-&gt;__sk_common.skc_dport;</span><br><span class="line"></span><br><span class="line">            <span class="variable">$dport</span> = (<span class="variable">$dport</span> &gt;&gt; 8) | ((<span class="variable">$dport</span> &lt;&lt; 8) &amp; 0xff00);</span><br><span class="line">            <span class="keyword">if</span> (retval &gt; 0) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%-15s %-5d -&gt; %-15s %-5d, retval %d\n&quot;</span>,</span><br><span class="line">                <span class="variable">$saddr</span>, <span class="variable">$lport</span>, <span class="variable">$daddr</span>, <span class="variable">$dport</span>, retval);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        delete(@sk[tid]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">or you could</span><br><span class="line">$ perf probe -a <span class="string">&#x27;sk_filter_trim_cap%return return=$retval:s32&#x27;</span></span><br><span class="line">$ perf record -e probe:sk_filter_trim_cap -agR --filter <span class="string">&#x27;return &lt; 0&#x27;</span> sleep 10</span><br><span class="line"></span><br><span class="line">$ perf probe -d probe:sk_filter_trim_cap</span><br><span class="line">or </span><br><span class="line">// or <span class="keyword">for</span> kernels &lt; 3.10.0-1062.el7 :</span><br><span class="line">$ perf record -e probe:sk_filter_trim_cap__return -agR --filter <span class="string">&#x27;return &lt; 0&#x27;</span> sleep 10</span><br><span class="line">$ perf report</span><br><span class="line"></span><br><span class="line"><span class="comment">## ftrace</span></span><br><span class="line">$ <span class="built_in">echo</span> 0 &gt; /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/<span class="built_in">enable</span></span><br><span class="line">$ <span class="built_in">echo</span>  &gt; /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">$ <span class="built_in">echo</span> <span class="string">&#x27;r:sk_filter_trim_cap sk_filter_trim_cap $retval&#x27;</span> &gt; /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">$ <span class="built_in">echo</span> 1 &gt; /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/<span class="built_in">enable</span></span><br><span class="line"></span><br><span class="line">cat /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/format</span><br><span class="line">name: sk_filter_trim_cap</span><br><span class="line">ID: 1548</span><br><span class="line">format:</span><br><span class="line">       field:unsigned short common_type;       offset:0;       size:2; signed:0;</span><br><span class="line">       field:unsigned char common_flags;       offset:2;       size:1; signed:0;</span><br><span class="line">       field:unsigned char common_preempt_count;       offset:3;       size:1; signed:0;</span><br><span class="line">       field:int common_pid;   offset:4;       size:4; signed:1;</span><br><span class="line"></span><br><span class="line">       field:unsigned long __probe_func;       offset:8;       size:8; signed:0;</span><br><span class="line">       field:unsigned long __probe_ret_ip;     offset:16;      size:8; signed:0;</span><br><span class="line">       field:u64 arg1; offset:24;      size:8; signed:0;</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> fmt: <span class="string">&quot;(%lx &lt;- %lx) arg1=0x%Lx&quot;</span>, REC-&gt;__probe_func, REC-&gt;__probe_ret_ip, REC-&gt;arg1</span><br><span class="line"></span><br><span class="line">$ cat /sys/kernel/debug/tracing/trace</span><br><span class="line"><span class="comment"># tracer: nop</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># entries-in-buffer/entries-written: 52403/52403   #P:96</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#                              _-----=&gt; irqs-off</span></span><br><span class="line"><span class="comment">#                             / _----=&gt; need-resched</span></span><br><span class="line"><span class="comment">#                            | / _---=&gt; hardirq/softirq</span></span><br><span class="line"><span class="comment">#                            || / _--=&gt; preempt-depth</span></span><br><span class="line"><span class="comment">#                            ||| /     delay</span></span><br><span class="line"><span class="comment">#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION</span></span><br><span class="line"><span class="comment">#              | |       |   ||||       |         |</span></span><br><span class="line">          &lt;idle&gt;-0     [006] d.s. 736525.098807: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">           &lt;...&gt;-156973 [006] d.s. 736532.093611: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">           &lt;...&gt;-156973 [006] d.s. 736532.093615: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">           &lt;...&gt;-156973 [006] d.s. 736532.093618: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">          &lt;idle&gt;-0     [006] dNs. 736532.093644: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">          &lt;idle&gt;-0     [006] dNs. 736532.093653: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">          &lt;idle&gt;-0     [006] dNs. 736532.093655: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line">          &lt;idle&gt;-0     [006] dNs. 736532.093656: sk_filter_trim_cap: (tcp_filter+0x2c/0x40 &lt;- sk_filter_trim_cap) arg1=0xfffffff4</span><br><span class="line"></span><br><span class="line">$ ./trace <span class="string">&#x27;r::sk_filter_trim_cap (retval != 0) &quot;%d&quot;, retval&#x27;</span></span><br><span class="line">281     281     ksoftirqd/54    sk_filter_trim_cap -12</span><br><span class="line">281     281     ksoftirqd/54    sk_filter_trim_cap -12</span><br><span class="line">20818   81613   user_app        sk_filter_trim_cap -12</span><br><span class="line">20818   81613   user_app        sk_filter_trim_cap -12</span><br><span class="line">314457  314457  kworker/54:1H   sk_filter_trim_cap -12</span><br><span class="line">314457  314457  kworker/54:1H   sk_filter_trim_cap -12</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://lore.kernel.org/patchwork/patch/648675/">min_free_kbytes - the system’s emergency reserves - which is entirely unrelated to the system’s latency requirements. In order to get kswapd to maintain a 250M buffer of free memory. the emergency reserves need to be set to 1G. That is a lot of memory wasted for no good reason.</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get mini free</span></span><br><span class="line">$ awk <span class="string">&#x27;$0~/min/&#123;sum+=$NF&#125; END&#123;print sum*4/1024 &quot;MiB&quot;&#125;&#x27;</span> /proc/zoneinfo</span><br></pre></td></tr></table></figure>

<p>But In the intel i40e and ixgbe driver work in Jumbo frame network and enabled TSO feature will cause a lot of ENOMEM.<br>In the 512G memory system, set it to 512M, the issue will gone else cause too many package dropped.</p>
<h4 id="memory-tuning"><a href="#memory-tuning" class="headerlink" title="memory tuning"></a>memory tuning</h4><p>Page scan,steal,stall will impact the performance, In 2 x Xeon 5220R, about 35% sys overhead, 65% CPU usage</p>
<h5 id="page-allocation-failure-order-2-mode-0x4020"><a href="#page-allocation-failure-order-2-mode-0x4020" class="headerlink" title="page allocation failure. order:2, mode:0x4020"></a>page allocation failure. order:2, mode:0x4020</h5><p>order:2 means 2^2=4 x 4Kpages = 16KB<br>order:4 means 16x4pages = 64KB, order:10 means 1024 x 4K pages=4096KB<br>mode:0x4020 - A bitmask flag</p>
<p><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/479983">In interrupt context it is not possible to reclaim memory, or wait for memory to be freed, to satisfy an allocation request. Therefore, if “free” privileged memory on a system is low, at the time of the allocation, the allocation will simply fail. Failed GFP_ATOMIC allocations by the network stack result in dropped packets which is likely to be received on a subsequent retransmit. They can also result in unexpected behaviour within various NIC drivers in the event that the calling codepath does not gracefully recover from the allocation failure. Note that a mode value like 0x4020 or 0x20 as reported in the “page allocation failure” message (a value ending in 0x20, the 1&lt;&lt;5 bit set) is a GFP_ATOMIC allocation. The order is the size of the allocation defined as: size = 2^order pages. For instance, an order 0 allocation request a single page (4k on most archs), an order 4 allocation request 16 pages (64k on most archs). The bigger the order, the more difficult the atomic allocation is going to be satisfied</a><br>the only other solution is to increase watermark[WMARK_MIN] via min_free_kbytes. Once there are no more free pages, nothing else can be done to avoid a “page allocation failure” message.  </p>
<p>It is also reported to help mitigate the issue to change vm.zone_reclaim_mode to 1 or 3 if it’s set to zero, so that the system can reclaim back memory from cached memory, so that the system can flush pages to disk to reclaim, and so that reclaimations occur within the same NUMA node for performance.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/proc/sys/vm/zone_reclaim_mode</span><br><span class="line">0       = Disable Zone reclaim, could reclaim from remote node</span><br><span class="line"><span class="comment">### file cache will cause performance issue, I suggest set it to 1</span></span><br><span class="line">1       = Zone reclaim on</span><br><span class="line">2       = Zone reclaim writes dirty pages out</span><br><span class="line">4       = Zone reclaim swaps pages</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/479983">Enabling the zone reclaimer actively frees memory from kernel zones, when the zone becomes full. The zone reclaimer can also be allowed to actively flush dirty pages, which also prevents a heavily-writing process from dirtying other NUMA nodes.</a></p>
<ul>
<li>Unmovable   = Pages fixed/locked in memory (mlock()’d) and cannot be moved anywhere else.</li>
<li>Reclaimable = Some of these should be allocatable although a lot of Filesystem metadata may have to be reclaimed to achieve this.</li>
<li>Movable     = All these blocks should be allocatable. We treat these pages as movable so they can be freed if necessary. </li>
<li>Reserve     = They are emergency memory reserve. Used if a memory reserve cannot be fulfilled from the mobility-specific lists (e.g. Movable, Reclaimable).</li>
<li>Isolate     = Pages isolated onto this private free list. This is required in order to move physical pages across NUMA nodes. These pages can be freed back to the allocator because they are now offlined.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/kernel/debug/extfrag/extfrag_index</span><br><span class="line">Node 0, zone      DMA -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000</span><br><span class="line">Node 0, zone    DMA32 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.989</span><br><span class="line">Node 0, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.993 0.997 0.999 0.999</span><br><span class="line">Node 1, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.984 0.992 0.996 0.998 0.999</span><br><span class="line"></span><br><span class="line">$ cat /proc/buddyinfo /proc/pagetypeinfo</span><br><span class="line">          Order =            0      1     2      3      4      5      6      7      8      9     10 </span><br><span class="line">Node      Zone               1      2     4      8     16     32     64    128    256    512   1024 &lt;=4k pages</span><br><span class="line">Node      Zone               4kB    8kB  16kB   32kB   64kB  128kB  256kB  512kB 1024kB 2048kB 4096kB &lt;=Byte size</span><br><span class="line">-------------------------------------------means--------------------------------------------------</span><br><span class="line">Node 0, zone      DMA      1      0      1      1      1      1      1      0      1      1      3</span><br><span class="line">Node 0, zone    DMA32   5393  10435   2087    968    621    731    725    504    209     29      0</span><br><span class="line">Node 0, zone   Normal  13788     61      5      1      1      0      0      0      0      0      0</span><br><span class="line">Node 1, zone   Normal 233089   1630    523    323     15      3      0      0      0      0      0</span><br><span class="line">Page block order: 9</span><br><span class="line">Pages per block:  512</span><br><span class="line"></span><br><span class="line">Free pages count per migrate <span class="built_in">type</span> at order       0      1      2      3      4      5      6      7      8      9     10</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>    Unmovable      1      0      1      1      1      1      1      0      1      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>  Reclaimable      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Movable      0      0      0      0      0      0      0      0      0      1      3</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>    Unmovable     45      0      0    212    224    707    724    503    207     29      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>  Reclaimable      1     35     14      2      1      0      1      1      1      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Movable   5347  10400   2073    754    396     24      0      0      1      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>    Unmovable  13189      1      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>  Reclaimable     32      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Movable    567     60      5      1      1      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line"></span><br><span class="line">Number of blocks <span class="built_in">type</span>     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate</span><br><span class="line">Node 0, zone      DMA            1            0            7            0            0            0</span><br><span class="line">Node 0, zone    DMA32          553          175          672            0            0            0</span><br><span class="line">Node 0, zone   Normal         8910          466       120160            0            0            0</span><br><span class="line">Page block order: 9</span><br><span class="line">Pages per block:  512</span><br><span class="line"></span><br><span class="line">Free pages count per migrate <span class="built_in">type</span> at order       0      1      2      3      4      5      6      7      8      9     10</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>    Unmovable  14085      0    165    124      8      2      0      0      0      0      0</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>  Reclaimable      1      3      7      2      6      1      0      0      0      0      0</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>      Movable &gt;100000   1627    350    197      1      0      0      0      0      0      0</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    1, zone   Normal, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line"></span><br><span class="line">Number of blocks <span class="built_in">type</span>     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate</span><br><span class="line">Node 1, zone   Normal         4620          847       125605            0            0            0</span><br><span class="line"></span><br><span class="line"><span class="comment">## for more info linux-3.10.0-1127.el7/include/linux/gfp.h</span></span><br><span class="line">Two types: </span><br><span class="line">zone modifiers</span><br><span class="line">action modifiers</span><br><span class="line">alloc_page-------------------------------single page</span><br><span class="line">get_zeroed_page--&gt;__get_free_pages</span><br><span class="line">    alloc_pages--------------------------2^order</span><br><span class="line">        alloc_pages_node-----------------node id</span><br><span class="line">            __alloc_pages</span><br><span class="line">                __alloc_pages_node_mask--nodemaks</span><br><span class="line"></span><br><span class="line">__GFP_DMA         ((__force gfp_t)    0x01u) </span><br><span class="line">__GFP_HIGHMEM     ((__force gfp_t)    0x02u)</span><br><span class="line">__GFP_DMA32       ((__force gfp_t)    0x04u)</span><br><span class="line">__GFP_MOVABLE     ((__force gfp_t)    0x08u) /* Flag that this page will be movable by the */</span><br><span class="line">                                             /* page migration mechanism or reclaimed */</span><br><span class="line">__GFP_WAIT        ((__force gfp_t)    0x10u) /* Can <span class="built_in">wait</span> and reschedule? */</span><br><span class="line">__GFP_HIGH        ((__force gfp_t)    0x20u) /* Should access emergency pools? */</span><br><span class="line">__GFP_IO          ((__force gfp_t)    0x40u) /* Can start physical IO? */</span><br><span class="line">__GFP_FS          ((__force gfp_t)    0x80u) /* Can call down to low-level FS? */</span><br><span class="line">__GFP_COLD        ((__force gfp_t)   0x100u) /* Cache-cold page required */</span><br><span class="line">__GFP_NOWARN      ((__force gfp_t)   0x200u) /* Suppress page allocation failure warning */</span><br><span class="line">__GFP_REPEAT      ((__force gfp_t)   0x400u) /* Try hard to allocate the memory, but the */</span><br><span class="line">                                             /* allocation attempt _might_ fail.  This */</span><br><span class="line">                                             /* depends upon the particular VM implementation. */</span><br><span class="line">__GFP_NOFAIL      ((__force gfp_t)   0x800u) /* The VM implementation _must_ retry infinitely: */</span><br><span class="line">                                             /* the <span class="built_in">caller</span> cannot handle allocation failures. */</span><br><span class="line">__GFP_NORETRY     ((__force gfp_t)  0x1000u) /* The VM implementation must not retry indefinitely */</span><br><span class="line">__GFP_COMP        ((__force gfp_t)  0x4000u) /* Add compound page metadata */</span><br><span class="line">__GFP_ZERO        ((__force gfp_t)  0x8000u) /* Return zeroed page on success */</span><br><span class="line">__GFP_NOMEMALLOC  ((__force gfp_t) 0x10000u) /* Don<span class="string">&#x27;t use emergency reserves */</span></span><br><span class="line"><span class="string">__GFP_HARDWALL    ((__force gfp_t) 0x20000u) /* Enforce hardwall cpuset memory allocs */</span></span><br><span class="line"><span class="string">__GFP_THISNODE    ((__force gfp_t) 0x40000u) /* No fallback, no policies */</span></span><br><span class="line"><span class="string">__GFP_RECLAIMABLE ((__force gfp_t) 0x80000u) /* Page is reclaimable */</span></span><br><span class="line"><span class="string">__GFP_NOTRACK     ((__force gfp_t)0x200000u) /* Don&#x27;</span>t track with kmemcheck */</span><br><span class="line">__GFP_NO_KSWAPD   ((__force gfp_t)0x400000u)</span><br><span class="line">__GFP_OTHER_NODE  ((__force gfp_t)0x800000u)</span><br><span class="line"></span><br><span class="line">GFP_ATOMIC        (__GFP_HIGH)               /* !<span class="built_in">wait</span> (__GFP_WAIT not <span class="built_in">set</span>) and use emergency pool *</span><br></pre></td></tr></table></figure>

<p>Set the kernel parameters will work  </p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">TcpExtPFMemallocDrop</span>            <span class="number">0</span>                  <span class="number">0</span>.<span class="number">0</span>  </span><br></pre></td></tr></table></figure>

<p>Restore the the parameters   </p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">TcpExtPFMemallocDrop</span>            <span class="number">1314</span>               <span class="number">0</span>.<span class="number">0</span>   </span><br></pre></td></tr></table></figure>

<h5 id="reduce-dirty-page-not-recommand-in-low-dirty-env"><a href="#reduce-dirty-page-not-recommand-in-low-dirty-env" class="headerlink" title="reduce dirty page (not recommand in low dirty env)"></a>reduce dirty page (not recommand in low dirty env)</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vm.dirty_background_ratio = 5</span><br><span class="line">vm.dirty_ratio = 10</span><br><span class="line">vm.dirty_expire_centisecs = 250</span><br><span class="line"></span><br><span class="line"><span class="comment">## default</span></span><br><span class="line">vm.dirty_background_ratio = 10</span><br><span class="line">vm.dirty_ratio = 20</span><br><span class="line">vm.dirty_expire_centisecs = 3000</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="http://lkml.iu.edu/hypermail/linux/kernel/0401.0/0017.html">same case1 TSO or jumbo frame</a><br><a target="_blank" rel="noopener" href="https://community.nxp.com/t5/i-MX-Processors/fec-skb-page-allocation-failure/td-p/652167">same case2 TSO or jumbo frame</a><br><a target="_blank" rel="noopener" href="https://lore.kernel.org/patchwork/patch/381731/">Dever disable the warnning v1</a><br><a target="_blank" rel="noopener" href="https://patchwork.ozlabs.org/project/netdev/patch/1369601101-23057-1-git-send-email-atomlin@redhat.com/">Dever disable the warnning v2</a><br><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/ixgb.txt">ixgbe kernel driver doc</a></p>
<p>In general, the kernel’s memory allocator does not like to fail. So, when kernel code requests memory, the memory management code will work hard to satisfy the request. If this work involves pushing other pages out to swap or removing data from the page cache, so be it. A big exception happens, though, when an atomic allocation (using the GFP_ATOMIC flag) is requested. Code requesting atomic allocations is generally not in a position where it can wait around for a lot of memory housecleaning work; in particular, such code cannot sleep. So if the memory manager is unable to satisfy an atomic allocation with the memory it has in hand, it has no choice except to fail the request.</p>
<h5 id="kmalloc-reserve"><a href="#kmalloc-reserve" class="headerlink" title="kmalloc_reserve"></a>kmalloc_reserve</h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">  <span class="number">70</span>)               |              sock_alloc_send_skb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                sock_alloc_send_pskb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                  alloc_skb_with_frags() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                    __alloc_skb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                      kmem_cache_alloc_node() &#123;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.086</span> us    |                        _cond_resched();</span><br><span class="line">  <span class="number">70</span>)               |                        <span class="comment">/* kmem_cache_alloc_node: call_site=ffffffffaa596c15 ptr=ffff90df02f24200 bytes_req=256 bytes_alloc=256 gfp_flags=GFP_KERNEL|GFP_REPEAT node=-1 */</span></span><br><span class="line">  <span class="number">70</span>)   <span class="number">1.555</span> us    |                      &#125;</span><br><span class="line">  <span class="number">70</span>)               |                      __kmalloc_reserve.isra<span class="number">.32</span>() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                        __kmalloc_node_track_caller() &#123;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.132</span> us    |                          kmalloc_slab();</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.080</span> us    |                          _cond_resched();</span><br><span class="line">  <span class="number">70</span>)               |                          <span class="comment">/* kmalloc_node: call_site=ffffffffaa596c15 ptr=ffff90e493aae800 bytes_req=576 bytes_alloc=1024 gfp_flags=GFP_KERNEL|GFP_NOWARN|GFP_REPEAT|GFP_NOMEMALLOC node=-1 */</span></span><br><span class="line">  <span class="number">70</span>)   <span class="number">2.109</span> us    |                        &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">2.924</span> us    |                      &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.484</span> us    |                      ksize();</span><br><span class="line">  <span class="number">70</span>)   <span class="number">7.259</span> us    |                    &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">8.129</span> us    |                  &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">9.136</span> us    |                &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">9.914</span> us    |              &#125;</span><br><span class="line"></span><br><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/net/core/skbuff.c</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kmalloc_reserve is a wrapper around kmalloc_node_track_caller that tells</span></span><br><span class="line"><span class="comment"> * the caller if emergency pfmemalloc reserves are being used. If it is and</span></span><br><span class="line"><span class="comment"> * the socket is later found to be SOCK_MEMALLOC then PFMEMALLOC reserves</span></span><br><span class="line"><span class="comment"> * may be used. Otherwise, the packet data may be discarded until enough</span></span><br><span class="line"><span class="comment"> * memory is free</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> kmalloc_reserve(size, gfp, node, pfmemalloc) \</span></span><br><span class="line">         __kmalloc_reserve(size, gfp, node, _RET_IP_, pfmemalloc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> *__kmalloc_reserve(<span class="keyword">size_t</span> size, <span class="keyword">gfp_t</span> flags, <span class="keyword">int</span> node,</span><br><span class="line">                               <span class="keyword">unsigned</span> <span class="keyword">long</span> ip, <span class="keyword">bool</span> *pfmemalloc)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">void</span> *obj;</span><br><span class="line">        <span class="keyword">bool</span> ret_pfmemalloc = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Try a regular allocation, when that fails and we&#x27;re not entitled</span></span><br><span class="line"><span class="comment">         * to the reserves, fail.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        obj = kmalloc_node_track_caller(size,</span><br><span class="line">                                        flags | __GFP_NOMEMALLOC | __GFP_NOWARN,</span><br><span class="line">                                        node);</span><br><span class="line">        <span class="keyword">if</span> (obj || !(gfp_pfmemalloc_allowed(flags)))</span><br><span class="line">                <span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Try again but now we are using pfmemalloc reserves */</span></span><br><span class="line">        ret_pfmemalloc = <span class="literal">true</span>;</span><br><span class="line">        obj = kmalloc_node_track_caller(size, flags, node);</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">        <span class="keyword">if</span> (pfmemalloc)</span><br><span class="line">                *pfmemalloc = ret_pfmemalloc;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Looks-like-it-is-the-malloc-slow-cause-access-hang"><a href="#Looks-like-it-is-the-malloc-slow-cause-access-hang" class="headerlink" title="Looks like it is the malloc slow cause access hang"></a>Looks like it is the malloc slow cause access hang</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">Here is I run <span class="string">&quot;ls /proc/user_app_pid/fd&quot;</span> hang too.</span><br><span class="line"></span><br><span class="line">[root@cngb-compute-f02-39 ~]<span class="comment"># ps aux |grep ls | grep root</span></span><br><span class="line">root      87739  0.0  0.0 141948  1308 pts/3    D+   16:52   0:00 ls --color=auto -l --color=auto</span><br><span class="line">root      88081  0.0  0.0 112820   972 pts/6    S+   16:53   0:00 grep --color=auto ls</span><br><span class="line">[root@cngb-compute-f02-39 ~]<span class="comment"># cat /proc/87739/stack</span></span><br><span class="line">[&lt;ffffffffc05acfe4&gt;] rpc_wait_bit_killable+0x24/0xb0 [sunrpc]</span><br><span class="line">[&lt;ffffffffc05af284&gt;] __rpc_execute+0x154/0x420 [sunrpc]</span><br><span class="line">[&lt;ffffffffc05b1a48&gt;] rpc_execute+0x68/0xc0 [sunrpc]</span><br><span class="line">[&lt;ffffffffc05a07e6&gt;] rpc_run_task+0xf6/0x150 [sunrpc]</span><br><span class="line">[&lt;ffffffffc05a0950&gt;] rpc_call_sync+0x50/0xc0 [sunrpc]</span><br><span class="line">[&lt;ffffffffc04ee72e&gt;] nfs3_rpc_wrapper.constprop.11+0x6e/0xb0 [nfsv3]</span><br><span class="line">[&lt;ffffffffc04eeae4&gt;] nfs3_proc_access+0xc4/0x1a0 [nfsv3]</span><br><span class="line">[&lt;ffffffffc0618aeb&gt;] nfs_do_access+0x1bb/0x3b0 [nfs]</span><br><span class="line">[&lt;ffffffffc0618ece&gt;] nfs_permission+0x1be/0x220 [nfs]</span><br><span class="line">[&lt;ffffffffba058e51&gt;] __inode_permission+0x71/0xd0</span><br><span class="line">[&lt;ffffffffba058ec8&gt;] inode_permission+0x18/0x50</span><br><span class="line">[&lt;ffffffffba05b5ae&gt;] link_path_walk+0x27e/0x8b0</span><br><span class="line">[&lt;ffffffffba05bd4a&gt;] path_lookupat+0x7a/0x8d0</span><br><span class="line">[&lt;ffffffffba05c5cb&gt;] filename_lookup+0x2b/0xc0</span><br><span class="line">[&lt;ffffffffba0602d7&gt;] user_path_at_empty+0x67/0xc0</span><br><span class="line">[&lt;ffffffffba060341&gt;] user_path_at+0x11/0x20</span><br><span class="line">[&lt;ffffffffba052bb3&gt;] vfs_fstatat+0x63/0xc0</span><br><span class="line">[&lt;ffffffffba052f6e&gt;] SYSC_newstat+0x2e/0x60</span><br><span class="line">[&lt;ffffffffba05342e&gt;] SyS_newstat+0xe/0x10</span><br><span class="line">[&lt;ffffffffba592ed2&gt;] system_call_fastpath+0x25/0x2a</span><br><span class="line">[&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span><br><span class="line"></span><br><span class="line">$ cat /proc/81845/stack</span><br><span class="line">[&lt;ffffffffb9fbdb04&gt;] __lock_page_killable+0x74/0x90</span><br><span class="line">[&lt;ffffffffb9fc04d8&gt;] generic_file_aio_read+0x768/0x790</span><br><span class="line">[&lt;ffffffffc061a171&gt;] nfs_file_read+0x71/0xf0 [nfs]</span><br><span class="line">[&lt;ffffffffba04c583&gt;] do_sync_read+0x93/0xe0</span><br><span class="line">[&lt;ffffffffba04cfbf&gt;] vfs_read+0x9f/0x170</span><br><span class="line">[&lt;ffffffffba04de2f&gt;] SyS_read+0x7f/0xf0</span><br><span class="line">[&lt;ffffffffba592ed2&gt;] system_call_fastpath+0x25/0x2a</span><br><span class="line">[&lt;ffffffffffffffff&gt;] 0xffffffffffffffff</span><br><span class="line">[root@cngb-compute-f02-39 ~]<span class="comment"># cd /proc/81845/fd</span></span><br><span class="line">[root@cngb-compute-f02-39 fd]<span class="comment"># ll #...hang</span></span><br><span class="line">total 0</span><br><span class="line">lr-x------ 1 zengbing1 mgi_ruijin 64 Feb  4 16:52 0 -&gt; /dev/null</span><br><span class="line">l-wx------ 1 zengbing1 mgi_ruijin 64 Feb  4 16:52 1 -&gt; /nfserver1/xxx</span><br><span class="line">l-wx------ 1 zengbing1 mgi_ruijin 64 Feb  4 16:52 2 -&gt; /nfserver2/xxx</span><br><span class="line">lr-x------ 1 zengbing1 mgi_ruijin 64 Feb  4 16:52 3 -&gt; /nfserver2/xxx</span><br></pre></td></tr></table></figure>

<h3 id="network-snmap-counter-nstat-z"><a href="#network-snmap-counter-nstat-z" class="headerlink" title="network snmap counter; nstat -z"></a><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/networking/snmp_counter.html">network snmap counter; nstat -z</a></h3><p>In this case TcpRetransSegs TcpExtTCPSackRecovery TcpExtTCPLostRetransmit TcpExtTCPFastRetrans</p>
<ul>
<li>TCP retrans<ul>
<li>TcpExtTCPSlowStartRetrans<ul>
<li>The TCP stack wants to retransmit a packet and the congestion control state is ‘Loss’</li>
</ul>
</li>
<li>TcpExtTCPFastRetrans<ul>
<li>The TCP stack wants to retransmit a packet and the congestion control state is not ‘Loss’</li>
</ul>
</li>
<li>TcpExtTCPLostRetransmit<ul>
<li>A SACK points out that a retransmission packet is lost again</li>
</ul>
</li>
<li>TcpExtTCPRetransFail<ul>
<li>The TCP stack tries to deliver a retransmission packet to lower layers but the lower layers return an error</li>
</ul>
</li>
<li>TcpExtTCPSynRetrans<ul>
<li>The TCP stack retransmits a SYN packet</li>
</ul>
</li>
<li>TcpRetransSegs</li>
<li>TcpExtTCPFastRetrans</li>
</ul>
</li>
<li>TCP out of order<ul>
<li>TcpExtTCPOFOQueue<ul>
<li>The TCP layer receives an out of order packet and has enough memory to queue it.</li>
</ul>
</li>
<li>TcpExtTCPOFODrop<ul>
<li>The TCP layer receives an out of order packet but doesn’t have enough memory, so drops it. Such packets won’t be counted into TcpExtTCPOFOQueue.</li>
</ul>
</li>
<li>TcpExtTCPOFOMerge<ul>
<li>The received out of order packet has an overlay with the previous packet. the overlay part will be dropped. All of TcpExtTCPOFOMerge packets will also be counted into TcpExtTCPOFOQueue</li>
</ul>
</li>
</ul>
</li>
<li>invalid SACK and DSACK<ul>
<li>TcpExtTCPSACKDiscard<ul>
<li>This counter indicates how many SACK blocks are invalid. If the invalid SACK block is caused by ACK recording, the TCP stack will only ignore it and won’t update this counter.</li>
</ul>
</li>
<li>TcpExtTCPDSACKIgnoredOld and TcpExtTCPDSACKIgnoredNoUndo<ul>
<li>When a DSACK block is invalid, one of these two counters would be updated. Which counter will be updated depends on the undo_marker flag of the TCP socket. If the undo_marker is not set, the TCP stack isn’t likely to re-transmit any packets, and we still receive an invalid DSACK block, the reason might be that the packet is duplicated in the middle of the network. In such scenario, TcpExtTCPDSACKIgnoredNoUndo will be updated. If the undo_marker is set, TcpExtTCPDSACKIgnoredOld will be updated. As implied in its name, it might be an old packet.</li>
</ul>
</li>
</ul>
</li>
<li>SACK shift<ul>
<li>TcpExtTCPSackShiftFallback<ul>
<li>A skb should be shifted or merged, but the TCP stack doesn’t do it for some reasons.</li>
</ul>
</li>
</ul>
</li>
<li>TCP PAWS (Protection Against Wrapped Sequence numbers)<ul>
<li>TcpExtPAWSActive<ul>
<li>Packets are dropped by PAWS in Syn-Sent status.</li>
</ul>
</li>
<li>TcpExtPAWSEstab<ul>
<li>Packets are dropped by PAWS in any status other than Syn-Sent.</li>
</ul>
</li>
</ul>
</li>
<li>TCP receive window, (Depending on current memory usage, the TCP stack tries to set receive window to zero. But the receive window might still be a no-zero value. For example, if the previous window size is 10, and the TCP stack receives 3 bytes, the current window size would be 7 even if the window size calculated by the memory usage is zero.)<ul>
<li>TcpExtTCPToZeroWindowAdv<ul>
<li>The TCP receive window is set to zero from a no-zero value.</li>
</ul>
</li>
</ul>
</li>
<li>Delayed ACK (The TCP Delayed ACK is a technique which is used for reducing the packet count in the network)<ul>
<li>TcpExtDelayedACKLocked<ul>
<li>A delayed ACK timer expires, but the TCP stack can’t send an ACK immediately due to the socket is locked by a userspace program. The TCP stack will send a pure ACK later (after the userspace program unlock the socket). When the TCP stack sends the pure ACK later, the TCP stack will also update TcpExtDelayedACKs and exit the delayed ACK mode.</li>
</ul>
</li>
<li>TcpExtDelayedACKLost<ul>
<li>It will be updated when the TCP stack receives a packet which has been ACKed. A Delayed ACK loss might cause this issue, but it would also be triggered by other reasons, such as a packet is duplicated in the network.</li>
</ul>
</li>
</ul>
</li>
<li>Tail Loss Probe<ul>
<li>TcpExtTCPLossProbes<ul>
<li>A TLP probe packet is sent.</li>
</ul>
</li>
<li>TcpExtTCPLossProbeRecovery<ul>
<li>A packet loss is detected and recovered by TLP.</li>
</ul>
</li>
</ul>
</li>
<li>TCP Fast Open description<ul>
<li>TcpExtTCPFastOpenActiveFail<ul>
<li>This counter indicates that the TCP stack initiated a TCP Fast Open, but it failed. This counter would be updated in three scenarios: (1) the other side doesn’t acknowledge the data in the SYN packet. (2) The SYN packet which has the TFO cookie is timeout at least once. (3) after the 3-way handshake, the retransmission timeout happens net.ipv4.tcp_retries1 times, because some middle-boxes may black-hole fast open after the handshake.</li>
</ul>
</li>
<li>TcpExtTCPFastOpenPassiveFail<ul>
<li>This counter indicates how many times the TCP stack rejects the fast open request. It is caused by either the TFO cookie is invalid or the TCP stack finds an error during the socket creating process.</li>
</ul>
</li>
<li>TcpExtTCPFastOpenListenOverflow<ul>
<li>When the pending fast open request number is larger than fastopenq-&gt;max_qlen, the TCP stack will reject the fast open request and update this counter.</li>
</ul>
</li>
</ul>
</li>
<li>SYN cookies, SYN cookies are used to mitigate SYN flood<ul>
<li>TcpExtSyncookiesFailed<ul>
<li>The MSS decoded from the SYN cookie is invalid</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="bonding-parameters"><a href="#bonding-parameters" class="headerlink" title="bonding parameters"></a>bonding parameters</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BONDING_OPTS=<span class="string">&quot;mode=4 millmon=100 arp_validate=0 updelay=30000 lacp_rate=fast xmit_hash_policy=layer3+4&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="Bandwidth-delay-product"><a href="#Bandwidth-delay-product" class="headerlink" title="Bandwidth-delay product"></a><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B8%A6%E5%AE%BD%E6%97%B6%E5%BB%B6%E4%B9%98%E7%A7%AF">Bandwidth-delay product</a></h3><ul>
<li>1 Gbit/s，1 ms RTT<ul>
<li>Bandwidth x Latency = 10^9 bit/s x 0.001 sec = 10^6 bit/s = 10^6/ 8 = 125 KB/s</li>
</ul>
</li>
</ul>
<h3 id="MTU"><a href="#MTU" class="headerlink" title="MTU"></a>MTU</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## set NIC</span></span><br><span class="line">$ ifconfig em1 mtu 9000</span><br><span class="line"></span><br><span class="line"><span class="comment">## set gateway</span></span><br><span class="line">$<span class="built_in"> ip route </span><span class="builtin-name">add</span><span class="built_in"> default </span>via 192.168.1.1 mtu 1400 dev em1</span><br></pre></td></tr></table></figure>

<p>Not working in my env</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_mtu_probing = 1</span><br><span class="line">net.ipv4.tcp_base_mss = 1024</span><br><span class="line"></span><br><span class="line">Enabling tcp_mtu_probing ensure the connection can recover gracefully <span class="keyword">if</span> frames larger than the WAN MTU are sent and there is no ICMP reply. Or to explain it <span class="keyword">in</span> more detail, consider <span class="keyword">if</span> linux system repeatedly sends several packets of say 1514 bytes (greater than MTUof the WAN) <span class="keyword">then</span> those packets are never responded as they are being dropped by the WAN. With tcp_mtu_probing turned on, the system should react to this <span class="built_in">type</span> of failure by trying to send a smaller packet. In this way it realizes the MTU of the link is lower.</span><br><span class="line">          0 - Disabled</span><br><span class="line">          1 - Disabled by default, enabled when an ICMP black hole detected</span><br><span class="line">          2 - Always enabled, use initial MSS of tcp_base_mss rather than value notified by peer</span><br><span class="line"></span><br><span class="line">tcp_base_mss defines the initial value of search_low to be used by the packetization layer Path MTU discovery (tcp_mtu_probing ). If MTU probing is enabled, this is the initial MSS used by the connection. Default value is 512.</span><br><span class="line"></span><br><span class="line">+----------------+                                +-----------+</span><br><span class="line"> | system <span class="comment">#1      |                                | system #2 |</span></span><br><span class="line"> |                |                                |           |</span><br><span class="line"> | mss 1460       |                                | mss 960   |</span><br><span class="line"> |                |  -----&gt; init (mss1460) -----&gt;  |           |</span><br><span class="line"> |                |  &lt;----- init (mss 960) &lt;-----  |           |</span><br><span class="line"> |                |  -----&gt; data (mss 960) -----&gt;  |           |</span><br><span class="line"> |                |  &lt;----- data (mss 960) &lt;-----  |           |</span><br><span class="line"> +----------------+                                +-----------+</span><br><span class="line"></span><br><span class="line">If MSS value is <span class="built_in">set</span> on system <span class="comment">#1, network flow is as below below:</span></span><br><span class="line">tcp_mtu_probing = 2 and tcp_base_mss = 1200</span><br><span class="line">    +--------------------+                                 +-----------+</span><br><span class="line">    | system <span class="comment">#1          |                                 | system #2 |</span></span><br><span class="line">    |                    |                                 |           |</span><br><span class="line">    | mss 1460           |                                 | mss 960   |</span><br><span class="line">    | tcp_mtu_probing=2  |   -----&gt; init (mss1460) -----&gt;  |           |</span><br><span class="line">    | tcp_base_mss=1200  |  &lt;----- init (mss 960) &lt;-----   |           |</span><br><span class="line">    |                    |                                 |           |</span><br><span class="line">    |                    |  -----&gt; data (mss 1200) -----&gt;  |           |</span><br><span class="line">    |                    |        (will be dropped)        |           |</span><br><span class="line">    |                    |  &lt;----- update  &lt;-------------  |           |</span><br><span class="line">    |                    |  -----&gt; data (mss 600) -----&gt;   |           |</span><br><span class="line">    +--------------------+                                 +-----------+ </span><br><span class="line"></span><br><span class="line"><span class="comment">## the others</span></span><br><span class="line">net.ipv4.route.mtu_expires = 600</span><br><span class="line">net.ipv4.tcp_probe_interval = 120</span><br><span class="line">net.ipv4.ip_forward_use_pmtu = 0</span><br></pre></td></tr></table></figure>

<h3 id="Deep-buffers-matter"><a href="#Deep-buffers-matter" class="headerlink" title="Deep buffers matter"></a>Deep buffers matter</h3><ul>
<li>lossless networks</li>
<li>how to they deal with incast problems ?<ul>
<li>Answer: tell everyone to stop<ul>
<li>In theory, allows small buffers</li>
<li>In practice, this leads to tree saturation</li>
<li>Causes blocking all the way to all sources<br><img src="/img/deep_buffer_matt-1.png"><table>
<thead>
<tr>
<th>Customer</th>
<th align="center">Real Buffer Utilization</th>
<th align="right">Cool</th>
</tr>
</thead>
<tbody><tr>
<td>HPC</td>
<td align="center">Storage Clustre -medium</td>
<td align="right">33MB</td>
</tr>
<tr>
<td>Animation</td>
<td align="center">Storage filer(NFS)</td>
<td align="right">6.2MB</td>
</tr>
<tr>
<td>Software vendor</td>
<td align="center">Engineering Build servers</td>
<td align="right">14.9MB</td>
</tr>
<tr>
<td>Online shopping</td>
<td align="center">Hadoop 2K servers -big data</td>
<td align="right">52.3MB</td>
</tr>
<tr>
<td>Educational</td>
<td align="center">Virtualization</td>
<td align="right">52.4MB</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="Deep-Buffers-Matter"><a href="#Deep-Buffers-Matter" class="headerlink" title="Deep Buffers Matter!"></a>Deep Buffers Matter!</h4><p>cause packets dropped per teragen<br>Improving uplink contention in mixed speed networks<br>High Density in core/spine (many-to-one, in-cast, fan-in)<br><img src="/img/deep_buffer_matt-2.png"></p>
<h4 id="Buffer-utilisation-per-port"><a href="#Buffer-utilisation-per-port" class="headerlink" title="Buffer utilisation per port"></a>Buffer utilisation per port</h4><p>some switch get the lower buffer utilisation<br>it could cause a lot of tcp retransmit</p>
<p>The question is our issues.<br>How much buffer are you using ? Any visibility ?<br>What cause your retransmits ?<br><img src="/img/deep_buffer_matt-3.png"></p>
<h3 id="Possible-SYN-flooding-on-port-xxx-Sending-cookies"><a href="#Possible-SYN-flooding-on-port-xxx-Sending-cookies" class="headerlink" title="Possible SYN flooding on port xxx. Sending cookies"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/30453">Possible SYN flooding on port xxx. Sending cookies</a></h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">tcp_max_syn_backlog - INTEGER</span><br><span class="line">Maximal number of remembered connection requests, which are still did <span class="keyword">not</span> receive an acknowledgment from connecting client. Default value is <span class="number">1024</span> <span class="keyword">for</span> systems with more than <span class="number">128</span>Mb of memory, <span class="keyword">and</span> <span class="number">128</span> <span class="keyword">for</span> low memory machines. If server suffers of overload, <span class="keyword">try</span> to increase <span class="keyword">this</span> number.</span><br><span class="line"></span><br><span class="line">#<span class="meta"># net/ipv4/tcp_ipv4.c</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_SYN_COOKIES</span></span><br><span class="line">        <span class="keyword">if</span> (sysctl_tcp_syncookies) &#123;</span><br><span class="line">                msg = <span class="string">&quot;Sending cookies&quot;</span>;</span><br><span class="line">                want_cookie = <span class="literal">true</span>;</span><br><span class="line">                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPREQQFULLDOCOOKIES);</span><br><span class="line">        &#125; <span class="keyword">else</span></span><br><span class="line">#endif</span><br><span class="line">                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_TCPREQQFULLDROP);</span><br><span class="line"></span><br><span class="line">        lopt = inet_csk(sk)-&gt;icsk_accept_queue.listen_opt;</span><br><span class="line">        <span class="keyword">if</span> (!lopt-&gt;synflood_warned &amp;&amp; sysctl_tcp_syncookies != <span class="number">2</span>) &#123;</span><br><span class="line">                lopt-&gt;synflood_warned = <span class="number">1</span>;</span><br><span class="line">                pr_info(<span class="string">&quot;%s: Possible SYN flooding on port %d. %s.  Check SNMP counters.\n&quot;</span>,</span><br><span class="line">                        proto, ntohs(tcp_hdr(skb)-&gt;dest), msg);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> want_cookie;</span><br><span class="line">&#125;</span><br><span class="line">EXPORT_SYMBOL(tcp_syn_flood_action);</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_syncookies = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_tw_reuse = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_tw_recycle = <span class="number">1</span></span><br><span class="line">net.ipv4.tcp_fin_timeout = <span class="number">30</span></span><br><span class="line">net.ipv4.tcp_max_syn_backlog = <span class="number">2048</span></span><br><span class="line">net.core.somaxconn = <span class="number">2048</span></span><br></pre></td></tr></table></figure>

<h3 id="Redhat-monitor-sh"><a href="#Redhat-monitor-sh" class="headerlink" title="Redhat monitor.sh"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/articles/1311173">Redhat monitor.sh</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># monitor.sh begins here</span></span><br><span class="line"><span class="comment"># Save this script as monitor.sh</span></span><br><span class="line"><span class="comment"># Allocate read write execute permissions: chmod +rwx monitor.sh</span></span><br><span class="line"><span class="comment"># Help available with: ./monitor.sh -h</span></span><br><span class="line"><span class="comment"># License: Creative Commons Zero - https://creativecommons.org/publicdomain/zero/1.0/</span></span><br><span class="line"></span><br><span class="line">VERSION=47</span><br><span class="line"></span><br><span class="line">USAGE=$(cat &lt;&lt;-EOM</span><br><span class="line">Usage: monitor.sh [-d DELAY] [-i ITERATIONS] [-h]</span><br><span class="line"></span><br><span class="line">This script collects data relevant to network debugging.</span><br><span class="line">Valid parameters are all optional.</span><br><span class="line"></span><br><span class="line">-d DELAY</span><br><span class="line">Specifies a delay between collections. Default is 30 seconds.</span><br><span class="line"></span><br><span class="line">    Examples:</span><br><span class="line">    ./monitor.sh -d 10   <span class="comment"># 10 seconds</span></span><br><span class="line">    ./monitor.sh -d 2    <span class="comment"># 2 seconds</span></span><br><span class="line"></span><br><span class="line">-i ITERATIONS</span><br><span class="line">Specifies the number of collections. Default is to run forever.</span><br><span class="line"></span><br><span class="line">  Examples:</span><br><span class="line">  ./monitor.sh -i 10   <span class="comment"># 10 iterations</span></span><br><span class="line">  ./monitor.sh -i 2    <span class="comment"># 2 iterations</span></span><br><span class="line"></span><br><span class="line">-p</span><br><span class="line">Disables process collection <span class="keyword">in</span> <span class="string">&quot;ss&quot;</span>, except when SS_OPTS used.</span><br><span class="line">Default is process collection enabled when SS_OPTS not provided.</span><br><span class="line"></span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -p</span><br><span class="line"></span><br><span class="line">-h</span><br><span class="line">Displays this <span class="built_in">help</span> message.</span><br><span class="line"></span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -h</span><br><span class="line"></span><br><span class="line">Options can be combined.</span><br><span class="line"></span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -d 10 -i 360    <span class="comment"># run every 10 secs, for an hour</span></span><br><span class="line"></span><br><span class="line">This script recognizes an environment variable SS_OPTS <span class="built_in">which</span> will</span><br><span class="line">override the script<span class="string">&#x27;s default command line switches when running</span></span><br><span class="line"><span class="string">the &#x27;</span>ss<span class="string">&#x27; utility.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Example:</span></span><br><span class="line"><span class="string">  env SS_OPTS=&quot;-pantoemi sport = :22&quot; bash monitor.sh</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## defaults</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">DELAY=30</span></span><br><span class="line"><span class="string">ITERATIONS=-1</span></span><br><span class="line"><span class="string">DEF_SS_OPTS=&quot;-noemitaup&quot;</span></span><br><span class="line"><span class="string">DEF_SS_OPTS_NOP=&quot;-noemitau&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## option parsing</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">REAL_SS_OPTS=$&#123;SS_OPTS:-$DEF_SS_OPTS&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">while getopts &quot;:d:i:ph&quot; OPT; do</span></span><br><span class="line"><span class="string">    case &quot;$OPT&quot; in</span></span><br><span class="line"><span class="string">        &quot;d&quot;)</span></span><br><span class="line"><span class="string">            # something was passed, check it&#x27;</span>s a positive <span class="built_in">integer</span></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> ] 2&gt;/dev/null &amp;&amp; [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -gt 0 ] 2&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">                DELAY=<span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">&quot;ERROR: <span class="variable">$OPTARG</span> not a valid option for delay. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">                <span class="built_in">exit</span> 1</span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;i&quot;</span>)</span><br><span class="line">            <span class="comment"># something was passed, check it&#x27;s a positive integer</span></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> ] 2&gt;/dev/null &amp;&amp; [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -gt 0 ] 2&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">                ITERATIONS=<span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">&quot;ERROR: <span class="variable">$OPTARG</span> not a valid option for iterations. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">                <span class="built_in">exit</span> 1</span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;p&quot;</span>)</span><br><span class="line">            REAL_SS_OPTS=<span class="variable">$&#123;SS_OPTS:-<span class="variable">$DEF_SS_OPTS_NOP</span>&#125;</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;h&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$USAGE</span>&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 0</span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;:&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;ERROR: -<span class="variable">$OPTARG</span> requires an argument. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;?&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;ERROR: -<span class="variable">$OPTARG</span> is not a valid option. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">            ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$SS_OPTS</span>&quot;</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> ! ss -S 2&gt;&amp;1 | grep -q <span class="string">&quot;invalid option&quot;</span>; <span class="keyword">then</span></span><br><span class="line">        REAL_SS_OPTS+=<span class="string">&quot;S&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## reporting</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Running network monitoring with <span class="variable">$DELAY</span> second delay for <span class="variable">$ITERATIONS</span> iterations.&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Running network monitoring with <span class="variable">$DELAY</span> second delay. Press Ctrl+c to stop...&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## one-time commands</span></span><br><span class="line"></span><br><span class="line">MQDEVS=( $(tc qdisc show | awk <span class="string">&#x27;/^qdisc mq/&#123;print $(NF-1)&#125;&#x27;</span>) )</span><br><span class="line"></span><br><span class="line"><span class="comment">## data collection loop</span></span><br><span class="line"><span class="keyword">while</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> != 0 ]; <span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#start timer in background</span></span><br><span class="line">    <span class="built_in">eval</span> sleep <span class="string">&quot;<span class="variable">$DELAY</span>&quot;</span> &amp;</span><br><span class="line"></span><br><span class="line">    now=$(date +%Y_%m_%d_%H)</span><br><span class="line">    <span class="keyword">then</span>=$(date --date=<span class="string">&quot;yesterday&quot;</span> +%Y_%m_%d_%H)</span><br><span class="line">    rm -rf <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$then</span>&quot;</span></span><br><span class="line">    mkdir -p <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;This output created with monitor.sh version <span class="variable">$VERSION</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;See https://access.redhat.com/articles/1311173&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Delay: <span class="variable">$DELAY</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Iterations: <span class="variable">$ITERATIONS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;SS_OPTS: <span class="variable">$REAL_SS_OPTS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span></span><br><span class="line">        sysctl -a 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span>  </span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span></span><br><span class="line">        ip address list &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span></span><br><span class="line">        ip route show table all &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span></span><br><span class="line">        uname -a &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip_neigh&quot;</span></span><br><span class="line">    ip neigh show &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip_neigh&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_qdisc&quot;</span></span><br><span class="line">    tc -s qdisc &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_qdisc&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$&#123;#MQDEVS[@]&#125;</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">for</span> MQDEV <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;MQDEVS[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_class_<span class="variable">$MQDEV</span>&quot;</span></span><br><span class="line">            tc -s class show dev <span class="string">&quot;<span class="variable">$MQDEV</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_class_<span class="variable">$MQDEV</span>&quot;</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netstat&quot;</span></span><br><span class="line">    netstat -s &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/nstat&quot;</span></span><br><span class="line">    nstat -az &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/nstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ss&quot;</span></span><br><span class="line">    <span class="built_in">eval</span> <span class="string">&quot;ss <span class="variable">$REAL_SS_OPTS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ss&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/interrupts&quot;</span></span><br><span class="line">    cat /proc/interrupts &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/interrupts&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softnet_stat&quot;</span></span><br><span class="line">    cat /proc/net/softnet_stat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softnet_stat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/vmstat&quot;</span></span><br><span class="line">    cat /proc/vmstat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/vmstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ps&quot;</span></span><br><span class="line">    ps -alfe &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ps&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/mpstat&quot;</span></span><br><span class="line">    <span class="built_in">eval</span> mpstat -A <span class="string">&quot;<span class="variable">$DELAY</span>&quot;</span> 1 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/mpstat&quot;</span> &amp;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/top&quot;</span></span><br><span class="line">    top -c -b -n1 &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/top&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/numastat&quot;</span></span><br><span class="line">    numastat 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/numastat&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/softirqs ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softirqs&quot;</span></span><br><span class="line">        cat /proc/softirqs &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softirqs&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat&quot;</span></span><br><span class="line">    cat /proc/net/sockstat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/net/sockstat6 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat6&quot;</span></span><br><span class="line">        cat /proc/net/sockstat6 &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat6&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netdev&quot;</span></span><br><span class="line">    cat /proc/net/dev &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netdev&quot;</span></span><br><span class="line">    <span class="keyword">for</span> DEV <span class="keyword">in</span> $(ip a l | grep mtu | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | awk -F <span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">do</span> <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ethtool_<span class="variable">$DEV</span>&quot;</span>; ethtool -S <span class="string">&quot;<span class="variable">$DEV</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ethtool_<span class="variable">$DEV</span>&quot;</span> 2&gt;/dev/null; <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">for</span> DEV <span class="keyword">in</span> $(ip a l | grep mtu | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | awk -F <span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">do</span> <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sys_statistics_<span class="variable">$DEV</span>&quot;</span>; find /sys/devices/ -<span class="built_in">type</span> f | grep <span class="string">&quot;/net/<span class="variable">$DEV</span>/statistics&quot;</span> | xargs grep . | awk -F <span class="string">&quot;/&quot;</span> <span class="string">&#x27;&#123;print $NF&#125;&#x27;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sys_statistics_<span class="variable">$DEV</span>&quot;</span>; <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/net/sctp ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-assocs&quot;</span></span><br><span class="line">        cat /proc/net/sctp/assocs &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-assocs&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-snmp&quot;</span></span><br><span class="line">        cat /proc/net/sctp/snmp &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-snmp&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span> <span class="built_in">let</span> ITERATIONS-=1; <span class="keyword">fi</span></span><br><span class="line">    <span class="comment"># Wait till background jobs are finished</span></span><br><span class="line">    <span class="built_in">wait</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># monitor.sh ends here</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   eth0 ---- vnet0 --- br0 --- eth0 ------ switch ------ eth1</span><br><span class="line">[-- VM --][------- hypervisor -------][-- physical --][-- remote --]</span><br><span class="line"></span><br><span class="line">On VM:</span><br><span class="line"><span class="comment"># tcpdump -i eth0 -w /tmp/vm_$(hostname)-$(date +&quot;%Y-%m-%d-%H-%M-%S&quot;).pcap</span></span><br><span class="line"></span><br><span class="line">On Hypervisor:</span><br><span class="line"><span class="comment"># tcpdump -i vnet0 -w /tmp/vnet_$(hostname)-$(date +&quot;%Y-%m-%d-%H-%M-%S&quot;).pcap</span></span><br><span class="line"><span class="comment"># tcpdump -i br0 -w /tmp/br0_$(hostname)-$(date +&quot;%Y-%m-%d-%H-%M-%S&quot;).pcap</span></span><br><span class="line"></span><br><span class="line">On switch:</span><br><span class="line">mirror switch port and perform a packet capture</span><br><span class="line"></span><br><span class="line">On remote host:</span><br><span class="line"><span class="comment"># tcpdump -i eth1 -w /tmp/eth1_remote.pcap</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Homer</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2018/06/01/ethernet_nic_tuning/">http://yoursite.com/2018/06/01/ethernet_nic_tuning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/network/">network</a><a class="post-meta__tags" href="/tags/benchmark/">benchmark</a><a class="post-meta__tags" href="/tags/nic/">nic</a><a class="post-meta__tags" href="/tags/irq/">irq</a></div><div class="post_share"><div class="social-share" data-image="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/07/02/mem/"><img class="prev-cover" src="https://homerl.github.io/img/operting_system_a32c6f.svg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">memory</div></div></a></div><div class="next-post pull-right"><a href="/2018/05/27/cpu/"><img class="next-cover" src="https://homerl.github.io/img/operting_system_a32c6f.svg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">cpu</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/07/22/network-benchmark-result/" title="Network bencharmk results"><img class="cover" src="https://homerl.github.io/img/kisspng-computer-icons-benchmarking-computer-software-clip-5ad795b068f297.2882681215240780004299.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-22</div><div class="title">Network bencharmk results</div></div></a></div><div><a href="/2017/01/08/tcp/" title="TCP"><img class="cover" src="https://homerl.github.io/img/operting_system_a32c6f.svg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2017-01-08</div><div class="title">TCP</div></div></a></div><div><a href="/2018/07/12/storage_benchmark/" title="storage benchmark"><img class="cover" src="https://homerl.github.io/img/kisspng-computer-icons-benchmarking-computer-software-clip-5ad795b068f297.2882681215240780004299.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-07-12</div><div class="title">storage benchmark</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2015 - 2021 By Homer</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '0b9d5b98d0a972b33cf7',
      clientSecret: '769efc11b32f6c0d03bcbf3ee800dfc4e2690459',
      repo: 'homerl.github.io',
      owner: 'homerl',
      admin: ['homerl'],
      id: 'aa2a3708a6e70b4bfa7ee619c4323c9f',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    $.getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js', initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>