<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Ethernet nic tuning | 无常无形无功;不动不破不空</title><meta name="keywords" content="network,benchmark,nic,irq"><meta name="author" content="寸劲"><meta name="copyright" content="寸劲"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="parmeters">
<meta property="og:type" content="article">
<meta property="og:title" content="Ethernet nic tuning">
<meta property="og:url" content="http://yoursite.com/2018/06/01/ethernet_nic_tuning/index.html">
<meta property="og:site_name" content="无常无形无功;不动不破不空">
<meta property="og:description" content="parmeters">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png">
<meta property="article:published_time" content="2018-06-01T02:49:42.000Z">
<meta property="article:modified_time" content="2021-11-04T06:45:50.693Z">
<meta property="article:author" content="寸劲">
<meta property="article:tag" content="network">
<meta property="article:tag" content="benchmark">
<meta property="article:tag" content="nic">
<meta property="article:tag" content="irq">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png"><link rel="shortcut icon" href="/img/stout-shield.png"><link rel="canonical" href="http://yoursite.com/2018/06/01/ethernet_nic_tuning/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-11-04 14:45:50'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="无常无形无功;不动不破不空" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/fighting-spiri-logot.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">57</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">57</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#parmeters"><span class="toc-number">1.</span> <span class="toc-text">parmeters</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#NIC-model"><span class="toc-number">1.1.</span> <span class="toc-text">NIC model</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Linux-network-performance"><span class="toc-number">1.2.</span> <span class="toc-text">Linux network performance</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#slot-status"><span class="toc-number">1.3.</span> <span class="toc-text">slot status</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Hardware-features"><span class="toc-number">1.4.</span> <span class="toc-text">Hardware features</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#XPS-support"><span class="toc-number">1.4.1.</span> <span class="toc-text">XPS support</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#busy-poll-Interrupt-Queues"><span class="toc-number">1.4.2.</span> <span class="toc-text">busy poll(Interrupt Queues)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ARFS-support"><span class="toc-number">1.4.3.</span> <span class="toc-text">ARFS support</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#RSS-support"><span class="toc-number">1.4.4.</span> <span class="toc-text">RSS support</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#THEORETICAL-MAXIMUM-RATE"><span class="toc-number">1.4.5.</span> <span class="toc-text">THEORETICAL MAXIMUM RATE</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#interface-Forward-Error-Correction"><span class="toc-number">1.4.6.</span> <span class="toc-text">interface Forward Error Correction</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CPU"><span class="toc-number">1.5.</span> <span class="toc-text">CPU</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Software-features"><span class="toc-number">1.6.</span> <span class="toc-text">Software features</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#ethtool-ETHTOOL"><span class="toc-number">1.6.1.</span> <span class="toc-text">ethtool ETHTOOL</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#driver"><span class="toc-number">1.7.</span> <span class="toc-text">driver</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ip"><span class="toc-number">1.8.</span> <span class="toc-text">ip</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux-workflow"><span class="toc-number">2.</span> <span class="toc-text">Linux workflow</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Interrupt-Queues-not-contains-busy-poll"><span class="toc-number">2.1.</span> <span class="toc-text">Interrupt Queues(not contains busy poll)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Socket-receive-queues"><span class="toc-number">2.2.</span> <span class="toc-text">Socket receive queues</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#RSS-IRQ-Affinity"><span class="toc-number">2.3.</span> <span class="toc-text">RSS IRQ Affinity</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-net-softnet-stat"><span class="toc-number">2.3.1.</span> <span class="toc-text">&#x2F;proc&#x2F;net&#x2F;softnet_stat</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Linux-sysctl"><span class="toc-number">2.4.</span> <span class="toc-text">Linux sysctl</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Memory-resource"><span class="toc-number">2.4.1.</span> <span class="toc-text">Memory resource</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Enable-jumbo-frames"><span class="toc-number">2.4.2.</span> <span class="toc-text">Enable jumbo frames</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Enabled-in-default"><span class="toc-number">2.4.3.</span> <span class="toc-text">Enabled in default</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#mtu-setting"><span class="toc-number">2.4.4.</span> <span class="toc-text">mtu setting</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ip-fragments-dropped"><span class="toc-number">2.4.5.</span> <span class="toc-text">ip fragments dropped</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Enable-bbr"><span class="toc-number">2.4.6.</span> <span class="toc-text">Enable bbr</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tcp-timestamps"><span class="toc-number">2.5.</span> <span class="toc-text">tcp_timestamps</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-window-scaling"><span class="toc-number">2.5.1.</span> <span class="toc-text">tcp_window_scaling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#keepalive"><span class="toc-number">2.5.2.</span> <span class="toc-text">keepalive</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-sack"><span class="toc-number">2.5.3.</span> <span class="toc-text">tcp_sack</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#dirty-page"><span class="toc-number">2.5.4.</span> <span class="toc-text">dirty page</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-frto"><span class="toc-number">2.5.5.</span> <span class="toc-text">tcp_frto</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-tw-reuse"><span class="toc-number">2.5.6.</span> <span class="toc-text">tcp_tw_reuse</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#netfilter"><span class="toc-number">2.5.7.</span> <span class="toc-text">netfilter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ARP-setting"><span class="toc-number">2.5.8.</span> <span class="toc-text">ARP setting</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#proc-pagetypeinfo"><span class="toc-number">2.5.9.</span> <span class="toc-text">&#x2F;proc&#x2F;pagetypeinfo</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#available-congestion-control"><span class="toc-number">2.5.10.</span> <span class="toc-text">available_congestion_control</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#if-ping-reply-the-wrong-ip-addr"><span class="toc-number">2.5.11.</span> <span class="toc-text">if ping reply the wrong ip addr</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#bonding"><span class="toc-number">2.5.12.</span> <span class="toc-text">bonding</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#cases"><span class="toc-number">3.</span> <span class="toc-text">cases</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bonding-tcp-retrans"><span class="toc-number">3.1.</span> <span class="toc-text">[bonding tcp retrans]</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Finally-verify-if-cores-were-successfully-isolated-by-checking-how-many-thread-context-switches-are-occurring-per-core"><span class="toc-number">3.2.</span> <span class="toc-text">Finally verify if cores were successfully isolated by checking how many thread context switches are occurring per core</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#RFC2544-stipulates-that-the-latency-test"><span class="toc-number">3.2.1.</span> <span class="toc-text">RFC2544 stipulates that the latency test</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#The-network-latency"><span class="toc-number">3.2.2.</span> <span class="toc-text">The network latency</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Troubleshooting-a-Zero-Window-https-wiki-wireshark-org-TCP-20ZeroWindow-For-one-reason-or-another-the-machine-alerting-the-Zero-Window-will-not-receive-any-more-data-from-the-host-It-could-be-that-the-machine-is-running-too-many-processes-at-that-moment-and-its-processor-is-maxed-Or-it-could-be-that-there-is-an-error-in-the-TCP-receiver-like-a-Windows-registry-misconfiguration-Try-to-determine-what-the-client-was-doing-when-the-TCP-Zero-Window-happened"><span class="toc-number">3.2.3.</span> <span class="toc-text">Troubleshooting a Zero Window](https:&#x2F;&#x2F;wiki.wireshark.org&#x2F;TCP%20ZeroWindow) For one reason or another, the machine alerting the Zero Window will not receive any more data from the host. It could be that the machine is running too many processes at that moment, and its processor is maxed. Or it could be that there is an error in the TCP receiver, like a Windows registry misconfiguration. Try to determine what the client was doing when the TCP Zero Window happened.</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#kernel-improved"><span class="toc-number">3.2.4.</span> <span class="toc-text">kernel improved</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#tcp-probe"><span class="toc-number">3.2.5.</span> <span class="toc-text">tcp_probe</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#backlog-test"><span class="toc-number">3.2.6.</span> <span class="toc-text">backlog test</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Driver-error"><span class="toc-number">3.2.7.</span> <span class="toc-text">Driver error</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#netstat-info"><span class="toc-number">3.2.8.</span> <span class="toc-text">netstat info</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#TCP-fast-retrans"><span class="toc-number">3.2.9.</span> <span class="toc-text">TCP fast retrans</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ABout-TCP-segment-out-of-order"><span class="toc-number">3.2.10.</span> <span class="toc-text">ABout TCP segment out of order</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#huoding-debug-process"><span class="toc-number">3.2.11.</span> <span class="toc-text">huoding debug process</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#SR-IOV-Demo"><span class="toc-number">3.2.12.</span> <span class="toc-text">SR-IOV Demo</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#PCI-init"><span class="toc-number">3.2.13.</span> <span class="toc-text">PCI init</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Softirq-Subsystem-Initialization"><span class="toc-number">3.2.14.</span> <span class="toc-text">Softirq Subsystem Initialization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#82599-limit"><span class="toc-number">3.2.15.</span> <span class="toc-text">82599 limit</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Deep-buffers-matter"><span class="toc-number">3.2.16.</span> <span class="toc-text">Deep buffers matter</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Monitor-script"><span class="toc-number">3.2.17.</span> <span class="toc-text">Monitor script</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Trace-the-twice-traceroute-hang"><span class="toc-number">3.2.18.</span> <span class="toc-text">Trace the twice traceroute hang</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Definition"><span class="toc-number">4.</span> <span class="toc-text">Definition</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Reference"><span class="toc-number">5.</span> <span class="toc-text">Reference</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">无常无形无功;不动不破不空</a></span><span id="menus"><div id="search_button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">Ethernet nic tuning</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-06-01T02:49:42.000Z" title="Created 2018-06-01 10:49:42">2018-06-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-11-04T06:45:50.693Z" title="Updated 2021-11-04 14:45:50">2021-11-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Network/">Network</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h3 id="parmeters"><a href="#parmeters" class="headerlink" title="parmeters"></a>parmeters</h3><a id="more"></a>

<h4 id="NIC-model"><a href="#NIC-model" class="headerlink" title="NIC model"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/2898381">NIC model</a></h4><p>Eg: qede</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2f:00.0 Ethernet controller [0200]: QLogic Corp. FastLinQ QL41000 Series 10/25/40/50GbE Controller [1077:8070] (rev 02)</span><br><span class="line">2f:00.1 Ethernet controller [0200]: QLogic Corp. FastLinQ QL41000 Series 10/25/40/50GbE Controller [1077:8070] (rev 02)</span><br><span class="line"></span><br><span class="line">$ cat ~/fastlinq-8.50.25.0/qede-8.50.25.0/src/qede_main.c</span><br><span class="line"></span><br><span class="line"><span class="comment">#define CHIP_NUM_57980S_IOV             0x1664</span></span><br><span class="line"><span class="comment">#define CHIP_NUM_AH                     0x8070</span></span><br><span class="line"><span class="comment">#define CHIP_NUM_AH_IOV                 0x8090</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_57980S_IOV        CHIP_NUM_57980S_IOV</span></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_AH                CHIP_NUM_AH</span></span><br><span class="line"><span class="comment">#define PCI_DEVICE_ID_AH_IOV            CHIP_NUM_AH_IOV</span></span><br></pre></td></tr></table></figure>

<h4 id="Linux-network-performance"><a href="#Linux-network-performance" class="headerlink" title="Linux network performance"></a>Linux network performance</h4><p><a target="_blank" rel="noopener" href="https://lwn.net/Articles/629155/">The problem, Jesper said, is that the kernel developers have focused on scaling out to large numbers of cores. In the process, they have been able to hide regressions in per-core efficiency. The networking stack, as a result, works well for many workloads, but workloads that are especially latency-sensitive have suffered. The kernel, today, can only forward something between 1M and 2M packets per core every second, while some of the bypass alternatives approach a rate of 15M packets per core per second. Then there is the cost of performing a system call. On a system with SELinux and auditing enabled, that cost is just over 75ns — over the time budget on its own. Disabling auditing and SELinux reduces the time required to just under 42ns, which is better, but that is still a big part of the time budget. There are ways of amortizing that cost over multiple packets; they include system calls like sendmmsg(), recvmmsg(), sendfile(), and splice().</a>    </p>
<h4 id="slot-status"><a href="#slot-status" class="headerlink" title="slot status"></a>slot status</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">05:00.0 Ethernet controller: Intel Corporation Ethernet Controller XXV710 <span class="keyword">for</span> 25GbE SFP28 (rev 02)</span><br><span class="line"></span><br><span class="line">$ lspci -s 05:00.0 -vvv | grep -Ei <span class="string">&#x27;8G|MSI-X&#x27;</span></span><br><span class="line">      Capabilities: [70] MSI-X: Enable+ Count=129 Masked-</span><br><span class="line">              LnkCap: Port <span class="comment">#0, Speed 8GT/s, Width x8, ASPM L1, Latency L0 &lt;2us, L1 &lt;16us</span></span><br><span class="line">              LnkSta: Speed 8GT/s, Width x8, TrErr- Train- SlotClk+ DLActive- BWMgmt- ABWMgmt-</span><br></pre></td></tr></table></figure>

<h4 id="Hardware-features"><a href="#Hardware-features" class="headerlink" title="Hardware features"></a>Hardware features</h4><table>
<thead>
<tr>
<th>Features</th>
<th>status</th>
</tr>
</thead>
<tbody><tr>
<td>TSO TCP Segmentation Offload</td>
<td>hardware off, outdated</td>
</tr>
<tr>
<td>GSO Generic Segmentation Offload,hard TSO</td>
<td>GSO replaced TSO</td>
</tr>
<tr>
<td>GRO Generic Receive Offload/LRO</td>
<td>GRO replaced LRO; options ixgbe LRO=1,  LRO hard outdated</td>
</tr>
<tr>
<td>UFO UDP Fragmentation Offload</td>
<td>hardware off, outdated</td>
</tr>
<tr>
<td>rx-checksumming</td>
<td>hardware on</td>
</tr>
<tr>
<td>tx-checksumming</td>
<td>hardware on</td>
</tr>
<tr>
<td>scatter-gather</td>
<td>hardware on</td>
</tr>
<tr>
<td>RSS Receive side scaling</td>
<td>hardware on (hardware support)</td>
</tr>
<tr>
<td>RPS software RSS</td>
<td>software off, if not support, enable it</td>
</tr>
<tr>
<td>RFS Receive Flow Streering,UDP support ?</td>
<td>software off</td>
</tr>
<tr>
<td>ACCELERATED RFS</td>
<td>hardware on, looks like deps software RFS ?</td>
</tr>
<tr>
<td>XPS Transmit Packet Steering</td>
<td>software on</td>
</tr>
<tr>
<td>TOE tcp offloading engine</td>
<td>not support linux, <a target="_blank" rel="noopener" href="https://wiki.linuxfoundation.org/networking/toe">why not support</a></td>
</tr>
<tr>
<td>busy-poll: on fixed</td>
<td>hw and sw, work with sysctl.net.core.busy_poll &gt; 0</td>
</tr>
<tr>
<td>tx-udp_tnl-segmentation</td>
<td>hardware on</td>
</tr>
<tr>
<td>tx-udp_tnl-csum-segmentation</td>
<td>hardware on</td>
</tr>
</tbody></table>
<p>TSO = LSO (also called large segmentation offload)<br>RFS and XPS has the same function from receive or transmit, avoid cache miss, numa overhead<br>Receive Packet Steering (RPS) is logically a software implementation of RSS<br>Generic segmentation offload (GSO) is logically a software implementation of TSO</p>
<p>if TSO was on, disable GSO, same with RSS and RPS, generally, the GSO will be enabled, TSO has outted   </p>
<p>Enabling the RFS requires enabling the ‘ntuple’ flag via the ethtool,RFS requires the kernel to be compiled with the CONFIG_RFS_ACCEL option. This options is available in kernels 2.6.39 and above. Furthermore, RFS requires Device Managed Flow Steering support.    </p>
<h5 id="XPS-support"><a href="#XPS-support" class="headerlink" title="XPS support"></a>XPS support</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/class/net/enp2s0f0/queues/tx-0/xps_cpus </span><br><span class="line">01</span><br><span class="line">$ cat /sys/class/net/enp2s0f0/queues/tx-1/xps_cpus </span><br><span class="line">02</span><br></pre></td></tr></table></figure>

<h5 id="busy-poll-Interrupt-Queues"><a href="#busy-poll-Interrupt-Queues" class="headerlink" title="busy poll(Interrupt Queues)"></a>busy poll(Interrupt Queues)</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Busy polling behavior is supported by the following drivers. These drivers are also supported on Red Hat Enterprise Linux 7.1</span><br><span class="line">driver support: bnx2x,be2net,ixgbe,mlx4,myri10ge</span><br><span class="line"></span><br><span class="line">$ cat /boot/config-3.10.0-1127.el7.x86_64 | grep BUSY_POLL</span><br><span class="line">CONFIG_NET_RX_BUSY_POLL=y</span><br><span class="line"></span><br><span class="line">$ ethtool -k em1  |grep busy</span><br><span class="line">busy-poll: off [fixed]</span><br><span class="line">$ ethtool -K <span class="variable">$nic_dev</span> busy-poll on</span><br></pre></td></tr></table></figure>
<ul>
<li>The busy polling helps reduce latency in the network receive path by allowing socket layer code to poll the receive queue of a network device, and disabling network interrupts   </li>
<li><code>This removes delays caused by the interrupt and the resultant context switch.</code>  </li>
<li>However, <code>it also increases CPU utilization</code>. Busy polling also prevents the CPU from sleeping, which can incur additional power consumption.  </li>
<li>single queue map single cpu core, avoid lock or race cpu resource    </li>
</ul>
<p>kernel 3.11 support SO_BUSY_POLL    </p>
<ul>
<li>Busy polling is disabled by default (sysctl.net.core.busy_poll = 0)    <ul>
<li>This parameter controls the number of microseconds to wait for packets on the device queue for socket reads.<br>This parameter controls the number of microseconds to wait for packets on the device queue for socket poll and selects. Red Hat recommends a value of 50<br>Red Hat recommends a value of 50 for a small number of sockets, and a value of 100 for large numbers of sockets. For extremely large numbers of sockets (more than several hundred), use epoll(kernel 4.12) instead.<br><a target="_blank" rel="noopener" href="https://oxnz.github.io/2016/05/03/performance-tuning-networking/">Busy polling helps reduce latency in the network receive path by</a><br>it allowing socket layer code to poll the receive queue of a network device and disable network interrupts  </li>
</ul>
</li>
</ul>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#sw</span></span><br><span class="line">net.core.busy_poll = 50 #<span class="built_in"> default </span>0</span><br><span class="line">net.core.busy_read = 100 #<span class="built_in"> default </span>0, redhat recommand only 50</span><br><span class="line"></span><br><span class="line"><span class="comment">#hw</span></span><br><span class="line">$ ethtool -k device | grep <span class="string">&quot;busy-poll&quot;</span></span><br><span class="line">busy-poll: on [fixed]</span><br></pre></td></tr></table></figure>

<p>mlx4 driver with busy polling</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rx-usecs: 16</span><br><span class="line">rx-frames: 44</span><br></pre></td></tr></table></figure>
<p>rx-frames[-irq] rx-usecs[-irq] tx-frames[-irq] tx-usecs[-irq]<br>The range of 0-235 microseconds provides an effective range of 4,310 to 250,000 interrupts per second. The value of rx-µsecs-high can be set independent of rx-µsecs and tx-µsecs in the same ethtool command, and is also independent of the adaptive interrupt moderation algorithm. The underlying hardware supports granularity in 2-microsecond intervals, so adjacent values might result in the same interrupt rate.    </p>
<ul>
<li>rx-usecs This is the number of microseconds to wait before raising an RX interrupt after a packet has been received. When rx-usecs is set to 0 rx-frames is used</li>
<li>rx-frames     This is the number of frames to queue up before raising an RX interrupt.</li>
<li>adaptive-tx Dynamic control to decrease TX latency at low packet rates and increase throughput at high packet rates</li>
<li>tx-usecs This is the number of microseconds to wait before raising an TX interrupt after a packet has been sent. When tx-usecs is set to 0 tx-frames is used</li>
<li>tx-frames This is the number of frames to queue up before raising an TX interrupt<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#To turn on adaptive interrupt moderation, recommand</span></span><br><span class="line">$ ethtool -C ethX adaptive-rx on adaptive-tx on</span><br><span class="line"></span><br><span class="line"><span class="comment">#To turn off adaptive interrupt moderation</span></span><br><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off</span><br><span class="line"></span><br><span class="line">$ ethtool -c enp4s0f1</span><br><span class="line">Coalesce parameters <span class="keyword">for</span> enp4s0d1:</span><br><span class="line">Adaptive RX: off  TX: off</span><br><span class="line">stats-block-usecs: 0</span><br><span class="line">sample-interval: 0</span><br><span class="line">pkt-rate-low: 400000</span><br><span class="line">pkt-rate-high: 450000</span><br><span class="line"></span><br><span class="line">rx-usecs: 0</span><br><span class="line">rx-frames: 0</span><br><span class="line">rx-usecs-irq: 0</span><br><span class="line">rx-frames-irq: 0</span><br><span class="line"></span><br><span class="line">tx-usecs: 8</span><br><span class="line">tx-frames: 16</span><br><span class="line">tx-usecs-irq: 0</span><br><span class="line">tx-frames-irq: 256</span><br><span class="line"></span><br><span class="line">rx-usecs-low: 0</span><br><span class="line">rx-frame-low: 0</span><br><span class="line">tx-usecs-low: 0</span><br><span class="line">tx-frame-low: 0</span><br><span class="line"></span><br><span class="line">rx-usecs-high: 128</span><br><span class="line">rx-frame-high: 0</span><br><span class="line">tx-usecs-high: 0</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>If you require low latency performance and/or have plenty of CPU to devote to network processing, you can disable interrupt moderation entirely, which enables the interrupts to fire as fast as possible.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -C ethX adaptive-rx off adaptive-tx off rx-usecs 0 tx-usecs 0</span><br></pre></td></tr></table></figure>
<p>Totaly, tx,rx-usecs value the lower means the smaller frame to interrupt moderation. the more cpu overhead and the lower latency<br>increase tx,tx-usecs that means high latency and get the biger frame to interrupt moderation, the lower cpu overhead and high latency and high througput, it will impact tcp performance, so increase tcp_tso_win_divisor to 30<br>maybe busy-poll is the better choice    </p>
<p><a target="_blank" rel="noopener" href="http://www.cnhalo.net/2017/07/24/linux-busy-poll/">netperf TCP_RR 1 byte payload each way, 3.11 kernel,default 17500tps, busy poll could reach 63000 tps</a>   </p>
<h5 id="ARFS-support"><a href="#ARFS-support" class="headerlink" title="ARFS support"></a>ARFS support</h5><p>CPU to queue mapping is deduced based on the IRQ affinities configured by the driver for each receive queue.</p>
<ul>
<li>RFS enabled</li>
<li>CONFIG_RFS_ACCEL enabled</li>
<li>Enable ntuple</li>
<li>Configure your IRQ settings to ensure each RX queue is handled by one of your desired network processing CPUs</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">$ grep RFS /boot/config-4.18.0-305.el8.x86_64</span><br><span class="line">CONFIG_RFS_ACCEL=y</span><br><span class="line">CONFIG_MLX5_EN_ARFS=y</span><br><span class="line"></span><br><span class="line">$ ethtool -K ens6 ntuple on</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/rps_sock_flow_entries</span><br><span class="line">$ cat /sys/class/net/&lt;dev&gt;/queues/rx-&lt;n&gt;/rps_flow_cnt</span><br><span class="line"> </span><br><span class="line">$ <span class="built_in">echo</span> 32768 &gt; /proc/sys/net/core/rps_sock_flow_entries</span><br><span class="line">$ <span class="keyword">for</span> f <span class="keyword">in</span> /sys/class/net/ens6/queues/rx-*/rps_flow_cnt; <span class="keyword">do</span> <span class="built_in">echo</span> 4096 &gt; <span class="variable">$f</span>; <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">Set the value of the net.core.rps_sock_flow_entries kernel value to the maximum expected number of concurrently active connections</span><br><span class="line"></span><br><span class="line">Set the value of the sys/class/net/device/queues/rx-queue/rps_flow_cnt file to the value of the (rps_sock_flow_entries/N)</span><br><span class="line"><span class="built_in">where</span> N is the number of receive queues on a device</span><br><span class="line"></span><br><span class="line">Replace N with the number of configured receive queues. For example, <span class="keyword">if</span> the rps_flow_entries is <span class="built_in">set</span> to 32768 and there are 16 configured receive queues, the rps_flow_cnt = 32786/16= 2048 (that is, rps_flow_cnt = rps_flow_enties/N ).</span><br></pre></td></tr></table></figure>

<ul>
<li><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/howto-configure-arfs-on-connectx-4">Mellanox demo</a><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">$ ethtool -S eno1 | egrep rx.*pack</span><br><span class="line"><span class="comment"># disable</span></span><br><span class="line">$ ethtool -K ens6 ntuple off</span><br><span class="line"></span><br><span class="line">$ taskset -c 5 netserver &amp;</span><br><span class="line">$ netperf -H <span class="variable">$ipaddr</span> -l 200 -t TCP_STREAM &amp;</span><br><span class="line"></span><br><span class="line">$ ethtool -S ens6 | egrep rx.*pack</span><br><span class="line"><span class="comment"># only rx8 improved</span></span><br><span class="line">rx7_packets: 0</span><br><span class="line">rx7_lro_packets: 0</span><br><span class="line">rx8_packets: 6296748</span><br><span class="line">rx8_lro_packets: 0</span><br><span class="line">rx9_packets: 0</span><br><span class="line"></span><br><span class="line">$ ethtool -K ens6 ntuple on</span><br><span class="line">$ taskset -c 5 netserver &amp;</span><br><span class="line">$ netperf -H 11.134.201.5 -l 200 -t TCP_STREAM &amp;</span><br><span class="line">$ ethtool -S ens6 | egrep rx.*pack</span><br><span class="line">rx5_packets: 234532 <span class="comment"># only rx5 increase, it &#x27;s worked</span></span><br><span class="line">rx5_lro_packets: 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># mellanox enable the driver arfs</span></span><br><span class="line">$ enable_arfs.sh ens6</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="RSS-support"><a href="#RSS-support" class="headerlink" title="RSS support"></a>RSS support</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -n enp2s0f0</span><br><span class="line">8 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"></span><br><span class="line">$ lspci -v -s 83:00.0 | grep <span class="string">&quot;MSI-X: Enable+&quot;</span></span><br><span class="line">83:00.0<span class="built_in"> Ethernet </span>controller: Intel Corporation 82599ES 10-Gigabit SFI/SFP+<span class="built_in"> Network Connection </span>(rev 01)</span><br><span class="line">        Flags: bus master, fast devsel, latency 0,<span class="built_in"> IRQ </span>247, NUMA node 1</span><br><span class="line">        I/O ports at d020 [<span class="attribute">size</span>=32]</span><br><span class="line">        Capabilities: [50] MSI: Enable- <span class="attribute">Count</span>=1/1 Maskable+ 64bit+</span><br><span class="line">        Capabilities: [70] MSI-X: Enable+ <span class="attribute">Count</span>=64 Masked-</span><br></pre></td></tr></table></figure>
<p>Some devices have the ability to write incoming packets to several different regions of RAM simultaneously; each region is a separate queue. This allows the OS to use multiple CPUs to process incoming data in parallel, starting at the hardware level     </p>
<h5 id="THEORETICAL-MAXIMUM-RATE"><a href="#THEORETICAL-MAXIMUM-RATE" class="headerlink" title="THEORETICAL MAXIMUM RATE"></a><a target="_blank" rel="noopener" href="https://support-kb.spirent.com/resources/sites/SPIRENT/content/live/FAQS/10000/FAQ10597/en_US/How_to_Test_10G_Ethernet_WhitePaper_RevB.PDF">THEORETICAL MAXIMUM RATE</a></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">There are two important concepts related to 10GbE performance: frame rate and throughput. The MAC bit rate of 10GbE, defined <span class="keyword">in</span> the IEEE standard 802.3ae, is 10 billion bits per second. Frame rate is a simple arithmetic calculation based on the bit rate and frame format definitions. Throughput, defined <span class="keyword">in</span> IETF RFC 1242, is the highest rate at <span class="built_in">which</span> the system under <span class="built_in">test</span> can forward the offered load, without loss. Manufacturers can claim line-rate throughput only <span class="keyword">if</span> their switch forwards all the traffic offered at the 10Gb/s line rate <span class="keyword">for</span> the entire duration of the <span class="built_in">test</span>. The bit rate at <span class="built_in">which</span> 10GbE Media Access Layer (MAC) operates, 10 billion bits per second, is only one of the parameters <span class="keyword">in</span> defining the transmission rate <span class="keyword">for</span> this important new technology. The usual description of <span class="literal">true</span> network performance is frame rate, <span class="built_in">which</span> indicates how many Ethernet frames are moving across the network. The maximum frame rate <span class="keyword">for</span> 10GbE is determined by a formula that divides the 10 billion bits per second by the preamble, frame length, and inter-frame gap fields, expressed <span class="keyword">in</span> bits. The maximum frame rate is calculated using the minimum values of the following parameters, as described <span class="keyword">in</span> the IEEE 802.3ae standard:</span><br><span class="line">* Preamble - 8 bytes * 8 = 64 bits</span><br><span class="line">* Frame length - 64 bytes (minimum) * 8 = 512 bits</span><br><span class="line">* Inter-frame gap - 12 bytes (minimum) * 8 = 96 bits</span><br><span class="line">Therefore,</span><br><span class="line">Maximum Frame Rate =</span><br><span class="line">MAC Transmit Bit Rate/</span><br><span class="line">(Preamble + Frame Length + Inter-frame Gap)</span><br><span class="line">= 10,000,000,000 / (64 + 512 + 96)</span><br><span class="line">= 10,000,000,000 / 672</span><br><span class="line">= 14,880,952.38 frame per second (fps)</span><br></pre></td></tr></table></figure>

<h5 id="interface-Forward-Error-Correction"><a href="#interface-Forward-Error-Correction" class="headerlink" title="interface Forward Error Correction"></a><a href="(https://solarflare.hammer-europe.com/assets/uploads/resources/QLogic%20-%20White%20Paper%20-%2025Gb%20Ethernet.pdf">interface Forward Error Correction</a></h5><table>
<thead>
<tr>
<th align="center">Phy layer</th>
<th align="center">Name</th>
<th align="center">error Correction</th>
</tr>
</thead>
<tbody><tr>
<td align="center">MMF Optics</td>
<td align="center">25GBASE-SR</td>
<td align="center">RS-FEC</td>
</tr>
<tr>
<td align="center">Direct Attach Copper</td>
<td align="center">25GBASE-CR</td>
<td align="center">BASE-R FEC or RS-FEC</td>
</tr>
<tr>
<td align="center">Direct Attach Copper</td>
<td align="center">25GBASE-CR-S</td>
<td align="center">BASE-R FEC or disabled</td>
</tr>
<tr>
<td align="center">Electrical Backplane</td>
<td align="center">25GBASE-KR</td>
<td align="center">BASE-R FEC or RS-FEC</td>
</tr>
<tr>
<td align="center">Electrical Backplane</td>
<td align="center">25GBASE-KR-S</td>
<td align="center">BASE-R FEC or disabled</td>
</tr>
<tr>
<td align="center">Twisted Pair</td>
<td align="center">25GBASE-T</td>
<td align="center">N/A</td>
</tr>
</tbody></table>
<p>The IEEE standard specifies two backplane and copper interfaces. These have different goals, hence the different interface. The -S short reach interfaces aim to support high-quality cables without Forward Error Correction (FEC) to minimize latency. Full reach interfaces aimto support the lowest possible cable or backplane cost and the longest possible reach, which do require the use of FEC. FEC options include BASE-R FEC (also referred to as Fire Code) and RS-FEC (also referred to as Reed-Solomon). RS-FEC has been used for a range of applications including data storage satellite transmissions. BASE-R FEC is a newer technology that is particularly well suited for correction of the burst errors typical in a backplane channel resulting from error propagation in the receive equalizer.</p>
<p>IEEE 标准指定了两个底板和铜接口。这些接口的目标不同，因此接口存在不同。-S 短距离接口旨在支持无需转发纠错（FEC）的高质量电缆，以最大限度地降低延迟。全距离接口旨在实现尽可能低的电缆或背板成本以及尽可能长的距离，这需要使用FEC。FEC 选项包括 BASE-R FEC（也称为 Fire Code）和 RS-FEC（也称为 Reed-Solomon）。RS-FEC 已用于一系列应用，包括数据存储卫星传播。BASE-R FEC 是一种新型技术，特别适合纠正背板通道中由于接收均<br>衡器的错误传播而导致的突发错误。</p>
<h4 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">$ cpupower idle-set -d 3</span><br><span class="line">$ cpupower idle-set -d 2</span><br><span class="line">$ cpupower idle-set -d 1</span><br><span class="line">$ cpupower idle-set -d 0</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line"></span><br><span class="line">$ cpupower idle-set -D 133 <span class="comment">##enable 0,1,2,3 and disable 4</span></span><br><span class="line">$ cpupower idle-set -D 33  <span class="comment">##enable 0,1,2 and disable 4</span></span><br><span class="line"></span><br><span class="line">$ cpupower  frequency-set -g performance</span><br><span class="line">$ <span class="built_in">echo</span> performance &gt; /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor</span><br><span class="line"></span><br><span class="line">$ cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_max_freq</span><br><span class="line">$ cat /sys/devices/system/cpu/cpu*/cpufreq/cpuinfo_cur_freq</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get local cpus</span></span><br><span class="line">$ cat /sys/class/net/eth7/device/local_cpus</span><br><span class="line">0000,000fffc0,00000000,0fffc000</span><br></pre></td></tr></table></figure>

<h4 id="Software-features"><a href="#Software-features" class="headerlink" title="Software features"></a>Software features</h4><h5 id="ethtool-ETHTOOL"><a href="#ethtool-ETHTOOL" class="headerlink" title="ethtool ETHTOOL"></a>ethtool ETHTOOL</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ vi /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line">ETHTOOL_OPTS=<span class="string">&quot;-G <span class="variable">$&#123;ifname&#125;</span> &#123;parm&#125; &#123;value&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##Link delay</span></span><br><span class="line">LINKDELAY=30 <span class="keyword">in</span> /etc/sysconfig/network-scripts/ifcfg-eth0</span><br><span class="line">or</span><br><span class="line">kernel parameter: rd.net.timeout.carrier=30</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ ls /etc/NetworkManager/dispatcher.d/</span><br><span class="line">01-ifupdown  99tlp-rdw-nm  no-wait.d  pre-down.d  pre-up.d</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$1</span>&quot;</span> = <span class="string">&quot;eth0&quot;</span> ] &amp;&amp; [ <span class="string">&quot;<span class="variable">$2</span>&quot;</span> = <span class="string">&quot;up&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line"> ethtool -K <span class="string">&quot;<span class="variable">$1</span>&quot;</span> rx off gro off lro off</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>set message level</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># set interface messages level</span></span><br><span class="line">Old level   Name   Bit position</span><br><span class="line">    <span class="number">0</span>    NETIF_MSG_DRV          <span class="number">0x0001</span></span><br><span class="line">    <span class="number">1</span>    NETIF_MSG_PROBE        <span class="number">0x0002</span></span><br><span class="line">    <span class="number">2</span>    NETIF_MSG_LINK         <span class="number">0x0004</span></span><br><span class="line">    <span class="number">2</span>    NETIF_MSG_TIMER        <span class="number">0x0004</span></span><br><span class="line">    <span class="number">3</span>    NETIF_MSG_IFDOWN       <span class="number">0x0008</span></span><br><span class="line">    <span class="number">3</span>    NETIF_MSG_IFUP         <span class="number">0x0008</span></span><br><span class="line">    <span class="number">4</span>    NETIF_MSG_RX_ERR       <span class="number">0x0010</span></span><br><span class="line">    <span class="number">4</span>    NETIF_MSG_TX_ERR       <span class="number">0x0010</span></span><br><span class="line">    <span class="number">5</span>    NETIF_MSG_TX_QUEUED    <span class="number">0x0020</span></span><br><span class="line">    <span class="number">5</span>    NETIF_MSG_INTR         <span class="number">0x0020</span></span><br><span class="line">    <span class="number">6</span>    NETIF_MSG_TX_DONE      <span class="number">0x0040</span></span><br><span class="line">    <span class="number">6</span>    NETIF_MSG_RX_STATUS    <span class="number">0x0040</span></span><br><span class="line">    <span class="number">7</span>    NETIF_MSG_PKTDATA      <span class="number">0x0080</span></span><br></pre></td></tr></table></figure>

<p>NIC log     </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool -s em1 msglvl 0x0020000</span><br><span class="line">$ ethtool -d em3 | head -n 20</span><br><span class="line">Offset          Values</span><br><span class="line">------          ------</span><br><span class="line">0x0000:         03 00 00 00 11 11 11 61 ff 1f 00 00 10 02 00 00</span><br><span class="line">0x0010:         00 00 00 00 00 20 00 00 c0 31 00 00 00 00 00 00</span><br><span class="line">0x0020:         00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br><span class="line">0x0030:         00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br><span class="line">0x0040:         00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br><span class="line">0x0050:         00 00 08 00 00 00 00 00 00 00 00 00 00 00 00 00</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<p>set parameters</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># boot set</span></span><br><span class="line">$ ethtool -L <span class="variable">$nic_dev</span> combined <span class="variable">$num</span> <span class="comment">## CPU cores &lt; 8 , set num = cpu cores else set 16~32, not the more the better</span></span><br><span class="line">$ cat /proc/interrupts  | grep <span class="variable">$nic_dev</span></span><br><span class="line">$ grep -E <span class="string">&quot;CPU0|enp1s0f0&quot;</span> /proc/interrupts</span><br><span class="line">           CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7</span><br><span class="line"> 48:          0          0          1          0         73          0        154          0   PCI-MSI 524289-edge      i40e-enp1s0f0-TxRx-0</span><br><span class="line"> 49:         70          0         51         45          0        112          0        121   PCI-MSI 524290-edge      i40e-enp1s0f0-TxRx-1</span><br><span class="line"> 50:         34          0        273         90         33         53          0          7   PCI-MSI 524291-edge      i40e-enp1s0f0-TxRx-2</span><br><span class="line"> 51:      83286          0          0        229          0          1          0          0   PCI-MSI 524292-edge      i40e-enp1s0f0-TxRx-3</span><br><span class="line"> 52:          0        226          0          0          5          0          1          0   PCI-MSI 524293-edge      i40e-enp1s0f0-TxRx-4</span><br><span class="line"> 53:         29          0        192         72          0          0          0          1   PCI-MSI 524294-edge      i40e-enp1s0f0-TxRx-5</span><br><span class="line"> 54:         16          0          0          0          0          5        438         11   PCI-MSI 524295-edge      i40e-enp1s0f0-TxRx-6</span><br><span class="line"> 55:         78          1          0          0          0       6430          0      13438   PCI-MSI 524296-edge      i40e-enp1s0f0-TxRx-7</span><br><span class="line"></span><br><span class="line">$ ethtool -l <span class="variable">$nic_dev</span></span><br><span class="line">$ numactl --hardware  | grep <span class="string">&quot;node <span class="subst">$(cat /sys/class/net/$&#123;nic_dev&#125;/device/numa_node)</span> cpu&quot;</span> | awk -F: <span class="string">&#x27;&#123;print $2&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">$ ethtool -K <span class="variable">$nic_dev</span> rx on tx on sg on gro on lro off gso on tso off ntuple on</span><br><span class="line">$ ethtool -G <span class="variable">$nic_dev</span> RX 1024 TX 1024 <span class="comment">#10/25GbE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Layer 2 flow control can impact TCP performance considerably and is recommended to be disabled for most workloads ??</span></span><br><span class="line"><span class="comment">#diable autoneg and flow control</span></span><br><span class="line">$ ethtool -A eth2 autoneg off rx off</span><br><span class="line">$ ethtool -S eth2 | grep -Ei <span class="string">&#x27;pause|flow_con&#x27;</span></span><br><span class="line">     rx_pause_frames: 0</span><br><span class="line">     rx_constant_pause_events: 0</span><br><span class="line">     tx_pause_frames: 489</span><br><span class="line"></span><br><span class="line"><span class="comment">## if ringbuff not overflow, please don&#x27;t set it too large, if too large means too high latency</span></span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/rps_sock_flow_entries</span><br><span class="line">$ cat /sys/class/net/&lt;dev&gt;/queues/rx-&lt;n&gt;/rps_flow_cnt</span><br><span class="line"></span><br><span class="line"><span class="comment">#82599</span></span><br><span class="line"><span class="comment"># unsupport optical module</span></span><br><span class="line">$ modprobe ixgbe allow_unsupported_sfp=1,1</span><br><span class="line"></span><br><span class="line"><span class="comment"># the others</span></span><br><span class="line">$ ethtool -set-priv-flags eth2 vf-true-promisc-support on</span><br><span class="line"></span><br><span class="line"><span class="comment">#Typically this involves blinking one or more LEDs on the specific network port</span></span><br><span class="line">$ ethtool -p eth2</span><br><span class="line"></span><br><span class="line">-N to config</span><br><span class="line">rx-flow-hash tcp4|udp4|ah4|esp4|sctp4|tcp6|udp6|ah6|esp6|sctp6 m|v|t|s|d|f|n|r...</span><br><span class="line"><span class="comment">## hash algorithms</span></span><br><span class="line">udp4 UDP over IPv4</span><br><span class="line">udp6 UDP over IPv6</span><br><span class="line">     f   on the <span class="built_in">hash</span> bytes 0 and 1 of the Layer 4 header of the rx packet.</span><br><span class="line">     n   on the <span class="built_in">hash</span> bytes 2 and 3 of the Layer 4 header of the rx packet.</span><br><span class="line">     s   on the <span class="built_in">hash</span> src ipaddr</span><br><span class="line">     d   on the <span class="built_in">hash</span> dst ipaddr</span><br><span class="line"></span><br><span class="line">$ ethtool -n em1 rx-flow-hash tcp4</span><br><span class="line">TCP over IPV4 flows use these fields <span class="keyword">for</span> computing Hash flow key:</span><br><span class="line">IP SA</span><br><span class="line">IP DA</span><br><span class="line">L4 bytes 0 &amp; 1 [TCP/UDP src port]</span><br><span class="line">L4 bytes 2 &amp; 3 [TCP/UDP dst port]</span><br><span class="line"></span><br><span class="line">https://downloadmirror.intel.com/22919/eng/README.txt</span><br><span class="line"><span class="comment">#To include UDP port numbers in RSS hashing run</span></span><br><span class="line">$ ethtool -N ethX rx-flow-hash udp4 sdfn</span><br><span class="line"></span><br><span class="line"><span class="comment">#To exclude UDP port numbers from RSS hashing run</span></span><br><span class="line">$ ethtool -N ethX rx-flow-hash udp4 sd</span><br><span class="line"></span><br><span class="line"><span class="comment">#To display UDP hashing current configuration run</span></span><br><span class="line">$ ethtool -n ethX rx-flow-hash udp4</span><br><span class="line"></span><br><span class="line"><span class="comment">##modify</span></span><br><span class="line">$ ethtool -N em1 rx-flow-hash udp4 sdfn</span><br><span class="line"></span><br><span class="line"><span class="comment">##policy</span></span><br><span class="line">$ ethtool -N ethX flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 src-port 2000 dst-port 2001 action 2 [loc 1]</span><br><span class="line">$ ethtool -N ethX flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 action 2 [loc 1]</span><br><span class="line">$ ethtool -N ethX flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 user-def 0xffffffff00000001 m 0x40 action 2 [loc 1]</span><br><span class="line"><span class="comment">## 0xffffffff00000001 mode, offset: 0x40</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ethtool -U &lt;device&gt; flow-type &lt;type&gt; src-ip &lt;ip&gt; dstip &lt;ip&gt; src-port &lt;port&gt; dst-port &lt;port&gt; action &lt;queue&gt;</span></span><br><span class="line">$ ethtool -u eth2</span><br><span class="line">$ ethtool -U enp130s0 flow-type tcp4 src-ip 192.168.0.1 dst-ip 192.168.0.5 src-port 5300 dst-port 80 action 7</span><br><span class="line"><span class="comment">## from 192.168.0.1:5300 -----packages to queue 7-------&gt; 192.168.0.5:80</span></span><br><span class="line"></span><br><span class="line">$ ethtool -U enp130s0 flow-type ip4 src-ip 192.168.0.1 src-port 5300 action 7</span><br><span class="line">$ ethtool -U enp130s0 flow-type ip4 src-ip 192.168.0.5 src-port 55 action 10</span><br><span class="line"></span><br><span class="line"><span class="comment">#In case “tx-nocache-copy” is enabled, (this is the case for some kernels, e.g. kernel 3.10, which is the default for RH7.0) “tx-nocache-copy” should be disabled.</span></span><br><span class="line">$ ethtool -K ethX tx-nocache-copy off</span><br><span class="line"><span class="comment"># tx-nocache-copy is a feature which bypasses local cache and writes user-space data directly into memory.</span></span><br><span class="line"></span><br><span class="line">$ ethtool -u eth0</span><br><span class="line">40 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"><span class="comment">### dest port 80 go to rx queue 2</span></span><br><span class="line">$ ethtool -U eth0 flow-type tcp4 dst-port 80 action 2</span><br><span class="line"></span><br><span class="line"><span class="comment"># if you are mellanox NIC</span></span><br><span class="line">$ show_irq_affinity.sh ens6</span><br><span class="line"></span><br><span class="line"><span class="comment">### Custom policy, EP(Externally Programed) mode</span></span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type ip4 src-ip 192.168.100.1  action -1</span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type tcp4 src-port 80  action 2</span><br><span class="line">$ ethtool --config-ntuple eth2 flow-type udp4 src-port 80  action 2</span><br><span class="line"></span><br><span class="line"><span class="comment">#To specify that all traffic from 10.23.4.6 to 10.23.4.18 be placed in queue 4, issue this command:</span></span><br><span class="line">$ ethtool --config-ntuple flow-type tcp4 src-ip 10.23.4.6 dst-ip 10.23.4.18 action 4</span><br><span class="line"></span><br><span class="line"><span class="comment">#Forwards to queue 2 all IPv4 TCP traffic from 192.168.10.1:2000 that is going to 192.168.10.2:2001, placing the filter at position 33 of the Perfect-Match filter table (and overwriting any rule currently in that position):</span></span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; flow-type tcp4 src-ip 192.168.10.1 dst-ip 192.168.10.2 src-port 2000 dst-port 2001 action 2 loc 33</span><br><span class="line"></span><br><span class="line"><span class="comment">#Drops all UDP packets from 10.4.83.2:</span></span><br><span class="line">$ ethtool --config-ntuple flow-type udp4 src-ip 10.4.82.2 action -1</span><br><span class="line"><span class="comment">#Note: The VLAN field is not a supported filter with the i40e driver (Intel Ethernet Controller XL710 and Intel Ethernet Controller X710 NICs).</span></span><br><span class="line"><span class="comment">#For more information and options, see the ethtool man page documentation on the -U, -N, or --config-ntuple option.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List</span></span><br><span class="line">$ ethtool --show-ntuple p2p1</span><br><span class="line">10 RX rings available</span><br><span class="line">Total 0 rules</span><br><span class="line"></span><br><span class="line"><span class="comment"># Remove</span></span><br><span class="line">$ ethtool --config-ntuple &lt;interface name&gt; delete N</span><br><span class="line"></span><br><span class="line"><span class="comment"># There&#x27;s generic flow steering rule configuration interface on ethtool, called RX NFC.</span></span><br><span class="line">$ ethtool --config-nfc ix00 flow-type tcp4 src-ip 10.0.0.1 dst-ip 10.0.0.2 src-port 10000 dst-port 10001 action 6</span><br><span class="line">Added rule with ID 2045</span><br><span class="line">$ ethtool --show-nfc ix00</span><br><span class="line">12 RX rings available</span><br><span class="line">Total 1 rules</span><br><span class="line">Filter: 2045</span><br><span class="line">     Rule Type: TCP over IPv4</span><br><span class="line">     Src IP addr: 10.0.0.1 mask: 0.0.0.0</span><br><span class="line">     Dest IP addr: 10.0.0.2 mask: 0.0.0.0</span><br><span class="line">     TOS: 0x0 mask: 0xff</span><br><span class="line">     Src port: 10000 mask: 0x0</span><br><span class="line">     Dest port: 10001 mask: 0x0</span><br><span class="line">     VLAN EtherType: 0x0 mask: 0xffff</span><br><span class="line">     VLAN: 0x0 mask: 0xffff</span><br><span class="line">     User-defined: 0x0 mask: 0xffffffffffffffff</span><br><span class="line">     Action: Direct to queue 6</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://www.ichenfu.com/2020/05/07/intel-x700-i40e-do-not-receive-LLDP-frames/">i40e disable lldp</a>    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool --set-priv-flags eth0 disable-fw-lldp on</span><br><span class="line">or</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;lldp stop&quot;</span> &gt; /sys/kernel/debug/i40e/&lt;pci bus address&gt;/<span class="built_in">command</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#check status</span></span><br><span class="line">$ ethtool --show-priv-flags eth0|grep disable-fw-lldp</span><br><span class="line">$ lldpctl</span><br></pre></td></tr></table></figure>


<h4 id="driver"><a href="#driver" class="headerlink" title="driver"></a>driver</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">ixgbe InterruptThrottleRate=0,0</span><br><span class="line">- 在基于 82598 的适配器上，禁用InterruptThrottleRate 还会导致禁用 LRO</span><br><span class="line">当 igbvf 以默认设置加载并同时使用多个适配器时，CPU 利用率可能呈非线性增大。要限制 CPU 的利用率</span><br><span class="line">而不影响总体吞吐量，建议按以下所述加载驱动程序：</span><br><span class="line">modprobe igbvf InterruptThrottleRate=3000,3000,3000</span><br><span class="line">此命令为驱动程序的第一个、第二个和第三个实例设定 InterruptThrottleRate 为 3000 中断、秒。每秒</span><br><span class="line">2000 到 3000 中断的范围在大多数系统上有效，而且是一个良好的起点，但是最佳值则应根据平台而具体</span><br><span class="line">设置。如果 CPU 利用率不是问题的话，则使用默认驱动程序设置。</span><br><span class="line"></span><br><span class="line"><span class="built_in">disable</span> LRO</span><br><span class="line">$ make CFLAGS_EXTRA=<span class="string">&quot;-DIGB_LRO&quot;</span> install</span><br><span class="line"></span><br><span class="line"><span class="built_in">disable</span> MSI-X interrupt</span><br><span class="line">$ make CFLAGS_EXTRA=-DDISABLE_PCI_MSI install</span><br><span class="line"></span><br><span class="line"><span class="comment"># support PTP(IEEE 1588)精密时间协议, 支持PTP</span></span><br><span class="line">$ ethtool -T ethX</span><br><span class="line">make CFLAGS_EXTRA=<span class="string">&quot;-DIGB_PTP&quot;</span> install</span><br><span class="line"></span><br><span class="line"><span class="comment"># vxlan offloading</span></span><br><span class="line">$ ethtool -K ethX tx-udp_tnl-segmentation [off|on]</span><br><span class="line"></span><br><span class="line"><span class="comment"># disable hw rsc</span></span><br><span class="line">$ make CFLAGS_EXTRA=<span class="string">&quot;-DIXGBE_NO_HW_RSC&quot;</span> install</span><br></pre></td></tr></table></figure>

<h4 id="ip"><a href="#ip" class="headerlink" title="ip"></a>ip</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># promisc mode</span></span><br><span class="line">$ ip link <span class="built_in">set</span> eth2 allmulticast on</span><br><span class="line"></span><br><span class="line"><span class="comment">## add vlan to vf interface</span></span><br><span class="line">$ ip link add link eth2 name eth2.100 <span class="built_in">type</span> vlan id 100</span><br></pre></td></tr></table></figure>

<h3 id="Linux-workflow"><a href="#Linux-workflow" class="headerlink" title="Linux workflow"></a>Linux workflow</h3><h4 id="Interrupt-Queues-not-contains-busy-poll"><a href="#Interrupt-Queues-not-contains-busy-poll" class="headerlink" title="Interrupt Queues(not contains busy poll)"></a>Interrupt Queues(not contains busy poll)</h4><h4 id="Socket-receive-queues"><a href="#Socket-receive-queues" class="headerlink" title="Socket receive queues"></a>Socket receive queues</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## disable NAPI</span></span><br><span class="line">$ ethtool -C ethx rx-usecs 0 <span class="comment">##if disabled, tons of CPU interrupts</span></span><br><span class="line"></span><br><span class="line">seq_printf(seq,</span><br><span class="line">           <span class="string">&quot;%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n&quot;</span>,</span><br><span class="line">           sd-&gt;processed, sd-&gt;dropped, sd-&gt;time_squeeze, 0,</span><br><span class="line">           0, 0, 0, 0, /* was fastroute */</span><br><span class="line">           sd-&gt;cpu_collision, sd-&gt;received_rps, flow_limit_count);</span><br><span class="line"></span><br><span class="line">cat /proc/net/softnet_stat</span><br><span class="line">00119a6b 00000000 00000095</span><br><span class="line">00000000 00000000 00000000</span><br><span class="line">0007cb46 00000000 00000291</span><br><span class="line">                      |</span><br><span class="line">                      |time_squeeze parameters</span><br><span class="line">                      V</span><br><span class="line">$ cat /proc/sys/net/core/dev_weight</span><br><span class="line">64</span><br><span class="line">Maximum number of packets the driver can receive during a NAPI interrupt, per CPU</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/core.netdev_budget</span><br><span class="line">300</span><br><span class="line">Maximum number of packets received <span class="keyword">in</span> one NAPI polling cycle, total <span class="keyword">for</span> all interfaces/CPUs. Cannot exceed</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/netdev_budget_usecs</span><br><span class="line">8000</span><br><span class="line">Time <span class="keyword">in</span> microseconds of one NAPI polling cycle</span><br></pre></td></tr></table></figure>
<p>The maximum number of packets that kernel can handle on a NAPI interrupt, it’s a Per-CPU variable. For drivers that support LRO HW or GRO_HW, a hardware aggregated packet is counted as one packet in this context</p>
<p>Altering the drain rate of a queue is usually the simplest way to mitigate poor network performance. However, increasing the number of packets that a device can receive at one time uses additional processor time, during which no other processes can be scheduled, so this can cause other performance problems</p>
<p>netdev_budget is the maximum number of packets taken from all interfaces in one polling cycle (NAPI poll). In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted.<br>Maximum number of packets received in one NAPI polling cycle, total for all interfaces/CPUs. Cannot exceed</p>
<ul>
<li>The diff<ul>
<li>The maximum number of packets that kernel can handle on a NAPI interrupt, it’s a Per-CPU variable. For drivers that support LRO or GRO_HW, a hardware aggregated packet is counted as one packet in this context.</li>
<li>Maximum number of packets taken from all interfaces in one polling cycle (NAPI poll).<ul>
<li>In one polling cycle interfaces which are registered to polling are probed in a round-robin manner. Also, a polling cycle may not exceed netdev_budget_usecs microseconds, even if netdev_budget has not been exhausted</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="RSS-IRQ-Affinity"><a href="#RSS-IRQ-Affinity" class="headerlink" title="RSS IRQ Affinity"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/2144921">RSS IRQ Affinity</a></h4><p>Get the PCIE device numa node</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /sys/class/net/[interface]/device/numa_node</span><br><span class="line">$ cat /sys/devices/[PCI root]/[PCIe <span class="keyword">function</span>]/numa_node</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>CPU</th>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
</tr>
</thead>
<tbody><tr>
<td>bin</td>
<td>0001</td>
<td>0010</td>
<td>0100</td>
<td>1000</td>
<td>10000</td>
<td></td>
<td></td>
<td>10000000</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Deci</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>8</td>
<td>16</td>
<td>32</td>
<td>64</td>
<td>128</td>
<td>256</td>
<td>512</td>
<td>1024</td>
<td>2048</td>
<td>4096</td>
</tr>
<tr>
<td>Hex</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>8</td>
<td>10</td>
<td>20</td>
<td>40</td>
<td>80</td>
<td>100</td>
<td>200</td>
<td>400</td>
<td>800</td>
<td>1000</td>
</tr>
</tbody></table>
<p><a target="_blank" rel="noopener" href="https://bitsum.com/tools/cpu-affinity-calculator/">cpu affinity calculator</a><br><a target="_blank" rel="noopener" href="https://unix.stackexchange.com/questions/649013/why-does-awk-print-0xffffffffbb6002e0-as-ffffffffbb600000-using-printf">awk calculate limit</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">For calculations, this will default to the same 53 bits of precision as available with IEEE-754 doubles, but the PREC variable can be used to control that. See the manual linked above <span class="keyword">for</span> extensive details.</span><br><span class="line">There is a difference <span class="keyword">in</span> handling <span class="keyword">for</span> large integers and floating-point values requiring more than the default precision, <span class="built_in">which</span> can result <span class="keyword">in</span> surprising behaviour; large integers are parsed correctly with -M and its default settings (only subsequent calculations are affected by PREC), whereas floating-point values are stored with the precision defined at the time they are parsed</span><br><span class="line"></span><br><span class="line">                   ----------- core63 (0 to 63), the 64th cpu core</span><br><span class="line">                   |</span><br><span class="line">$ awk <span class="string">&#x27;BEGIN&#123;cnum=63; printf 2^(cnum%4);  for (i=1;i&lt;=(cnum/4);i++) &#123;printf 0&#125;; print&#125;&#x27;</span></span><br><span class="line">8000000000000000</span><br><span class="line"></span><br><span class="line">nic_dev=enp129s0f0</span><br><span class="line">           -------------------CPU cores, 7 15 46 47 48 49 50 51 52 53 54 62</span><br><span class="line">           |</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(numactl --hardware  | grep <span class="string">&quot;node <span class="subst">$(cat /sys/class/net/$&#123;nic_dev&#125;/device/numa_node)</span> cpu&quot;</span> | awk -F: <span class="string">&#x27;&#123;print $2&#125;&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> 112 113 114 115 240 241 242 243</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> $(awk -v cnum=<span class="variable">$i</span> <span class="string">&#x27;BEGIN&#123;printf &quot;0x&quot;2^(cnum%4);  for (i=1;i&lt;=(cnum/4);i++) &#123;printf 0&#125;; print&#125;&#x27;</span>);</span><br><span class="line"><span class="keyword">done</span> | awk -M -vPREC=500  --non-decimal-data <span class="string">&#x27;&#123;sum=sum+$1&#125; END&#123;printf &quot;%x\n&quot;,sum&#125;&#x27;</span></span><br><span class="line">f0000000000000000000000000000000f0000000000000000000000000000</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> f0000000000000000000000000000000f0000000000000000000000000000 &gt; /proc/irq/404/smp_affinity</span><br><span class="line">-bash: <span class="built_in">echo</span>: write error: Value too large <span class="keyword">for</span> defined data <span class="built_in">type</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> f000000,00000000,00000000,0000000,00f00000,00000000,0000000,00000000 &gt; /proc/irq/404/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> $?</span><br><span class="line">0</span><br><span class="line"><span class="comment">#I test it ok in gawk 5.1, not work in gawk 4.0.2</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0</span><br><span class="line">$ ls /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0/msi_irqs</span><br><span class="line">56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85</span><br><span class="line">$ ls -l /sys/devices/pci0000:17/0000:17:02.0/0000:18:00.0/msi_irqs</span><br><span class="line"></span><br><span class="line"><span class="comment">#scripts in driver</span></span><br><span class="line"><span class="comment">#intel</span></span><br><span class="line">$ set_irq_affinity -x all ethX</span><br><span class="line">$ set_irq_affinity -x <span class="built_in">local</span> ethX</span><br><span class="line">$ set_irq_affinity 1-2 ethX</span><br><span class="line"></span><br><span class="line"><span class="comment">#mellanox</span></span><br><span class="line">set_irq_affinity_bynode.sh 0 p7p1</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">printf</span> %0.2x<span class="string">&#x27;\n&#x27;</span> 1024</span><br><span class="line">400</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">printf</span> %0.2x<span class="string">&#x27;\n&#x27;</span> 4096</span><br><span class="line">1000</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> 400 &gt; /proc/irq/66/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 400 &gt; /proc/irq/67/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 1000 &gt; /proc/irq/69/smp_affinity</span><br><span class="line">$ <span class="built_in">echo</span> 1000 &gt; /proc/irq/70/smp_affinity</span><br></pre></td></tr></table></figure>
<p>When configuring RSS, Red Hat recommends <code>limiting the number of queues to one per physical CPU core</code><br>Hyper-threads are often represented as separate cores in analysis tools, but configuring queues for all cores including logical cores such as <code>hyper-threads has not proven beneficial to network performance</code></p>
<p>When enabled, RSS distributes network processing equally between available CPUs based on the amount of processing each CPU has queued. However, you can use the ethtool –show-rxfh-indir and –set-rxfh-indir parameters to modify how network activity is distributed, and weight certain types of network activity as more important than others.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool --set-rxfh-indir enp1s0f0 equal 4</span><br><span class="line">$ watch -d  -n 1 <span class="string">&quot;cat /proc/interrupts | grep enp1s0f0&quot;</span></span><br><span class="line"><span class="comment"># You could see only 4 interrupt number increase a lot</span></span><br><span class="line"></span><br><span class="line">$ ethtool --show-rxfh-indir enp1s0f0</span><br><span class="line">$ ethtool -x enp1s0f0</span><br><span class="line"><span class="comment">## You can set priority for each queue.</span></span><br><span class="line">RX flow <span class="built_in">hash</span> indirection table <span class="keyword">for</span> p4p1 with 48 RX ring(s):</span><br><span class="line">    0:      0     1     2     3     4     5     6     7</span><br><span class="line">    8:      8     9    10    11    12    13    14    15</span><br><span class="line">   16:     16    17    18    19    20    21    22    23</span><br><span class="line">   24:     24    25    26    27    28    29    30    31</span><br><span class="line">   32:     32    33    34    35    36    37    38    39</span><br><span class="line">   40:     40    41    42    43    44    45    46    47</span><br><span class="line">   48:      0     1     2     3     4     5     6     7</span><br><span class="line">   56:      8     9    10    11    12    13    14    15</span><br><span class="line">   64:     16    17    18    19    20    21    22    23</span><br><span class="line">   72:     24    25    26    27    28    29    30    31</span><br><span class="line">   80:     32    33    34    35    36    37    38    39</span><br><span class="line">   88:     40    41    42    43    44    45    46    47</span><br><span class="line">   96:      0     1     2     3     4     5     6     7</span><br><span class="line">  104:      8     9    10    11    12    13    14    15</span><br><span class="line">  112:     16    17    18    19    20    21    22    23</span><br><span class="line">  120:     24    25    26    27    28    29    30    31</span><br><span class="line"><span class="comment">### 16 (line) x 8 (column) = 128, total 128 value, that means indirection table = 128, total 48 RX rings</span></span><br><span class="line"><span class="comment">### eg: line &quot;96:&quot; second field(1), means 98th hash data equal 2, the data will go to second queue</span></span><br><span class="line"><span class="comment">### ethtool -X eth0 weight 6 5 4 3 2 1 .... , you can set 48 x weights, 48 data sum will not large than 128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set weight for the queue</span></span><br><span class="line">$ ethtool --set-rxfh-indir eth3 weight 6 2</span><br><span class="line">$ ethtool --set-rxfh-indir eth3 weight 1 2</span><br></pre></td></tr></table></figure>
<p><code>The irqbalance daemon can be used in conjunction with RSS to reduce the likelihood of cross-node memory transfers and cache line bouncing. This lowers the latency of processing network packets.</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ systemctl <span class="built_in">enable</span> irqbalance</span><br><span class="line">$ systemctl start irqbalance</span><br><span class="line"></span><br><span class="line"><span class="comment"># debug irqblaance</span></span><br><span class="line">$ irqbalance -d -f</span><br></pre></td></tr></table></figure>

<p>disable PCIE power save</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># disable pcie power save</span></span><br><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;pcie_aspm=off scsi_mod.use_blk_mq=y dm_mod.use_blk_mq=y consoleblank=0&#x27;</span></span><br></pre></td></tr></table></figure>

<h5 id="proc-net-softnet-stat"><a href="#proc-net-softnet-stat" class="headerlink" title="/proc/net/softnet_stat"></a>/proc/net/softnet_stat</h5><p><a target="_blank" rel="noopener" href="https://blog.cloudflare.com/how-to-achieve-low-latency/">achieve low lat</a><br><a target="_blank" rel="noopener" href="https://github.com/majek/dump/blob/master/how-to-receive-a-packet/softnet.sh">softnet.sh</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/net/softnet_stat</span><br><span class="line"><span class="comment"># 4 cores, each line means a &quot;struct softnet_data&quot;, each line each core</span></span><br><span class="line">000cc282 00000000 000004e7 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">0000b828 00000000 00000053 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">0000945b 00000000 00000046 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">0003d716 00000000 000001f7 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000</span><br><span class="line">-----    -----    --------                                              -------  -------</span><br><span class="line">|         \             \                                                  \        \-flow <span class="built_in">limit</span> count</span><br><span class="line">- sd-&gt;processe frame num \                                                  \-- cpu collision, transmit packages lock collision</span><br><span class="line">            \             \- time sequeeze, <span class="keyword">if</span> the count increase, increase the net.core.netdev_budget/net.core.dev_weight </span><br><span class="line">             \             \- and keep more cpu/mem resource, the budget or time <span class="built_in">limit</span> exhausted, no enough time to softirq</span><br><span class="line">              \----sd-&gt;dropped, The netdev_max_backlog is a queue within the Linux kernel <span class="built_in">where</span> traffic is stored after reception from the NIC, one backlog queue per CPU core.</span><br><span class="line"></span><br><span class="line"><span class="comment">#Each line of /proc/net/softnet_stat corresponds to a struct softnet_data structure, of which there is 1 per CPU.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The values are separated by a single space and are displayed in hexadecimal</span></span><br><span class="line"><span class="comment">#The first value, sd-&gt;processed, is the number of network frames processed. This can be more than the total number of network frames received if you are using ethernet bonding. There are cases where the ethernet bonding driver will trigger network data to be re-processed, which would increment the sd-&gt;processed count more than once for the same packet.</span></span><br><span class="line"></span><br><span class="line">The second value, sd-&gt;dropped, is the number of network frames dropped because there was no room on the processing queue. More on this later. If second values are gorwing, improve sysctl -w net.core.netdev_max_backlog = 2000, A value over 10000 is unlikely to be very helpful.</span><br><span class="line">The second colume number of frames dropped due to netdev_max_backlog being exceeded</span><br><span class="line"></span><br><span class="line">The netdev_max_backlog is a queue within the Linux kernel <span class="built_in">where</span> traffic is stored after reception from the NIC, but before processing by the protocol stacks (IP, TCP, etc). There is one backlog queue per CPU core.</span><br><span class="line">In CentOS 7.8 the default is 1000</span><br><span class="line"></span><br><span class="line"><span class="comment">#The third value, sd-&gt;time_squeeze, is (as we saw) the number of times the net_rx_action loop terminated because the budget was consumed or the time limit was reached, but more work could have been. Increasing the budget as explained earlier can help reduce this.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#If 3rd column is growing,improve sysctl -w net.core.netdev_budget=600</span></span><br><span class="line">Be careful of increasing this value unless there is a very good reason. A value exceeding 1000 is unlikely to be very helpful. In fact increasing this value too much can have detrimental effect and <span class="keyword">in</span> the worse <span class="keyword">case</span> scenario lead to softirq hangs or performance problems, as the softirqs can run <span class="keyword">for</span> too long and starve other processes of CPU</span><br><span class="line">3rd colume is number of <span class="built_in">times</span> ksoftirqd ran out of netdev_budget or CPU time when there was still work to be <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#This is much faster, but brings up another problem. What happens if we have so many packets to process that we spend all our time processing packets from the NIC, but we never have time to let the userspace processes actually drain those queues (read from TCP connections, etc.)? Eventually the queues would fill up, and we&#x27;d start dropping packets. To try and make this fair, the kernel limits the amount of packets processed in a given softirq context to a certain budget. Once this budget is exceeded, it wakes up a separate thread called ksoftirqd (you&#x27;ll see one of these in ps for each core) which processes these softirqs outside of the normal syscall/interrupt path. This thread is scheduled using the standard process scheduler, which already tries to be fair.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#net.core.netdev_budget=300 (default), This will cause the SoftIRQ process to drain 300 messages from the NIC before getting off the CPU, let the CPU do the others job</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The next 5 values are always 0.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The ninth value, sd-&gt;cpu_collision, is a count of the number of times a collision occurred when trying to obtain a device lock when transmitting packets. This article is about receive, so this statistic will not be seen below.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The tenth value, sd-&gt;received_rps, is a count of the number of times this CPU has been woken up to process packets via an Inter-processor Interrupt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The last value, flow_limit_count, is a count of the number of times the flow limit has been reached. Flow limiting is an optional Receive Packet Steering feature that will be examined shortly.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#If you decide to monitor this file and graph the results, you must be extremely careful that the ordering of these fields hasn&#x27;t changed and that the meaning of each field has been preserved. You will need to read the kernel source to verify this.</span></span><br><span class="line"></span><br><span class="line">seq_printf(seq,</span><br><span class="line">       <span class="string">&quot;%08x %08x %08x %08x %08x %08x %08x %08x %08x %08x %08x\n&quot;</span>,</span><br><span class="line">       sd-&gt;processed, sd-&gt;dropped, sd-&gt;time_squeeze, 0,</span><br><span class="line">       0, 0, 0, 0, /* was fastroute */</span><br><span class="line">       sd-&gt;cpu_collision, sd-&gt;received_rps, flow_limit_count);</span><br><span class="line"></span><br><span class="line"><span class="comment">#convert these data by bash</span></span><br><span class="line"></span><br><span class="line">cat ./softnet_stat.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">awk <span class="string">&#x27;BEGIN &#123;</span></span><br><span class="line"><span class="string">     t[1]=&quot;sd-&gt;processed&quot;</span></span><br><span class="line"><span class="string">     t[2]=&quot;sd-&gt;dropped&quot;</span></span><br><span class="line"><span class="string">     t[3]=&quot;sd-&gt;time_squeeze&quot;</span></span><br><span class="line"><span class="string">     t[9]=&quot;sd-&gt;cpu_collision&quot;</span></span><br><span class="line"><span class="string">     t[10]=&quot;sd-&gt;received_rps&quot;</span></span><br><span class="line"><span class="string">     printf &quot;%s %s %s %s %s\n&quot;,t[1],t[2],t[3],t[9],t[10];</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">   printf &quot;%d %d %d %d %d\n&quot;, strtonum( &quot;0x&quot;$1 ),strtonum( &quot;0x&quot;$2 ),strtonum( &quot;0x&quot;$3 ),strtonum( &quot;0x&quot;$9 ),strtonum( &quot;0x&quot;$10 )</span></span><br><span class="line"><span class="string">&#125;&#x27;</span>  /proc/net/softnet_stat | column -t</span><br><span class="line"></span><br><span class="line">$ watch -d sh ./softnet_stat.sh</span><br><span class="line">Every 2.0s: sh ./softnet_stat.sh                                                                                                  Mon Feb 17 00:23:15 2020</span><br><span class="line"></span><br><span class="line">sd-&gt;processed  sd-&gt;dropped  sd-&gt;time_squeeze  sd-&gt;cpu_collision  sd-&gt;received_rps</span><br><span class="line">46897674       0            15                0                  0</span><br><span class="line">33150875       0            4                 0                  0</span><br><span class="line">46371491       0            10                0                  0</span><br><span class="line">64446426       0            7                 0                  0</span><br><span class="line">57994272       0            11                0                  0</span><br><span class="line">34935375       0            90                0                  0</span><br><span class="line"></span><br><span class="line"><span class="comment">#when I was watch it, the time_squeeze not increased. only slowly increasing at rx_steer_missed_packets: 1623</span></span><br><span class="line"><span class="comment">#Herer is mellanox doc: Number of packets that was received by the NIC, however was discarded because it did not match any flow in the NIC flow table. supported from kernel 4.16</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># here is 2 v 1 test case,  node 1 and node 2 send and receive to node 3, there is no tcp retrans in node(little , 0.5/s), but it was full throughput (bond, dual port, tx:2.4GB/s tx 2.4GB/s), only a lot of tcp retrans in node 1 and node 2 (190~200/s) </span></span><br><span class="line"></span><br><span class="line">If you follow the softnet_break label you stumble upon something interesting. From net/core/dev.c:</span><br><span class="line">softnet_break:</span><br><span class="line">  sd-&gt;time_squeeze++;</span><br><span class="line">  __raise_softirq_irqoff(NET_RX_SOFTIRQ);</span><br><span class="line">  goto out;</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">cmd=<span class="string">&quot;<span class="variable">$&#123;0##*/&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">usage</span></span>() &#123;</span><br><span class="line">cat &gt;&amp;2 &lt;&lt;EOI</span><br><span class="line">usage: <span class="variable">$cmd</span> [ -h ]</span><br><span class="line">Output column definitions:</span><br><span class="line">      cpu  <span class="comment"># of the cpu </span></span><br><span class="line">    total  <span class="comment"># of packets (not including netpoll) received by the interrupt handler</span></span><br><span class="line">             There might be some double counting going on:</span><br><span class="line">                net/core/dev.c:1643: __get_cpu_var(netdev_rx_stat).total++;</span><br><span class="line">                net/core/dev.c:1836: __get_cpu_var(netdev_rx_stat).total++;</span><br><span class="line">             I think the intention was that these were originally on separate</span><br><span class="line">             receive paths ... </span><br><span class="line">  dropped  <span class="comment"># of packets that were dropped because netdev_max_backlog was exceeded</span></span><br><span class="line"> squeezed  <span class="comment"># of times ksoftirq ran out of netdev_budget or time slice with work</span></span><br><span class="line">             remaining</span><br><span class="line">collision  <span class="comment"># of times that two cpus collided trying to get the device queue lock.</span></span><br><span class="line">EOI</span><br><span class="line">	<span class="built_in">exit</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">softnet_stats_header</span></span>() &#123;</span><br><span class="line">	<span class="built_in">printf</span> <span class="string">&quot;%3s %10s %10s %10s %10s %10s %10s\n&quot;</span> cpu total dropped squeezed collision rps flow_limit</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">softnet_stats_format</span></span>() &#123;</span><br><span class="line">	<span class="built_in">printf</span> <span class="string">&quot;%3u %10lu %10lu %10lu %10lu %10lu %10lu\n&quot;</span> <span class="string">&quot;<span class="variable">$1</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$2</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$3</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$4</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$5</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$6</span>&quot;</span> <span class="string">&quot;0x<span class="variable">$7</span>&quot;</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">getopts</span> h flag &amp;&amp; usage</span><br><span class="line"></span><br><span class="line">cpu=0</span><br><span class="line">softnet_stats_header</span><br><span class="line"><span class="keyword">while</span> <span class="built_in">read</span> total dropped squeezed j1 j2 j3 j4 j5 collision rps flow_limit_count</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	<span class="comment"># the last field does not appear on older kernels</span></span><br><span class="line">	<span class="comment"># https://github.com/torvalds/linux/commit/99bbc70741903c063b3ccad90a3e06fc55df9245#diff-5dd540e75b320a50866267e9c52b3289R165</span></span><br><span class="line">	softnet_stats_format $((cpu++)) <span class="string">&quot;<span class="variable">$total</span>&quot;</span> <span class="string">&quot;<span class="variable">$dropped</span>&quot;</span> <span class="string">&quot;<span class="variable">$squeezed</span>&quot;</span> <span class="string">&quot;<span class="variable">$collision</span>&quot;</span> <span class="string">&quot;<span class="variable">$rps</span>&quot;</span> <span class="string">&quot;<span class="variable">$&#123;flow_limit_count:-0&#125;</span>&quot;</span></span><br><span class="line"><span class="keyword">done</span> &lt; /proc/net/softnet_stat</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="Linux-sysctl"><a href="#Linux-sysctl" class="headerlink" title="Linux sysctl"></a>Linux sysctl</h4><p>centos 7    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br></pre></td><td class="code"><pre><span class="line">vm.min_free_kbytes=700000</span><br><span class="line"><span class="comment">#the system&#x27;s emergency reserves - which is entirely unrelated to the system&#x27;s latency requirements. In order to get kswapd to maintain a 250M buffer of free memory. the emergency reserves need to be set to 1G. That is a lot of memory wasted for no good reason.](https://lore.kernel.org/patchwork/patch/648675/)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#increase watermark[WMARK_MIN] via min_free_kbytes</span></span><br><span class="line"><span class="comment">#awk &#x27;$0~/min/&#123;sum+=$NF&#125; END&#123;print sum*4/1024 &quot;MiB&quot;&#125;&#x27; /proc/zoneinfo</span></span><br><span class="line"><span class="comment">#issue record</span></span><br><span class="line"><span class="comment">#But In the intel i40e and ixgbe driver work in Jumbo frame network and enabled TSO feature will cause a lot of ENOMEM. In the 512G memory system, set it to 512M, the issue will gone else cause too many package dropped.</span></span><br><span class="line"></span><br><span class="line">vm.zone_reclaim_mode=1</span><br><span class="line">Enabling the zone reclaimer actively frees memory from kernel zones, when the zone becomes full. The zone reclaimer can also be allowed to actively flush dirty pages, <span class="built_in">which</span> also prevents a heavily-writing process from dirtying other NUMA nodes  </span><br><span class="line"><span class="comment">#It is also reported to help mitigate the issue to change vm.zone_reclaim_mode to 1 or 3 if it&#x27;s set to zero, so that the system can reclaim back memory from cached memory, so that the system can flush pages to disk to reclaim, and so that reclaimations occur within the same NUMA node for performance.</span></span><br><span class="line">0       = Disable Zone reclaim, could reclaim from remote node</span><br><span class="line"><span class="comment">### file cache will cause performance issue, I suggest set it to 1</span></span><br><span class="line">2^0 = 1       = Zone reclaim on <span class="comment">## only local node reclaim</span></span><br><span class="line">2^1 = 2       = Zone reclaim writes dirty pages out</span><br><span class="line">2^2 = 4       = Zone reclaim swaps pages</span><br><span class="line"></span><br><span class="line"><span class="comment">#Enabling the zone reclaimer actively frees memory from kernel zones, when the zone becomes full</span></span><br><span class="line"><span class="comment">#The zone reclaimer can also be allowed to actively flush dirty pages</span></span><br><span class="line"><span class="comment">#which also prevents a heavily-writing process from dirtying other NUMA nodes</span></span><br><span class="line"><span class="comment">#I think reclaim writes tirty pages out will cause too many sync IO cause the kernel tcp buff traffic jam and waste memory too</span></span><br><span class="line">vm.zone_reclaim_mode = 3 (11=3)</span><br><span class="line"></span><br><span class="line"><span class="comment">#Enable all</span></span><br><span class="line">vm.zone_reclaim_mode = 7 (111=7)</span><br><span class="line"></span><br><span class="line"><span class="comment"># suggest set the vm.zone_reclaim_mode to 1 to avoid the remote node, in my env, it &#x27;s the good choice</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/vm/zone_reclaim_mode</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">dev.raid.speed_limit_max=8000000</span><br><span class="line">dev.raid.speed_limit_min=2000000</span><br><span class="line"></span><br><span class="line">kernel.unknown_nmi_panic = 1</span><br><span class="line">kernel.panic_on_unrecovered_nmi = 1</span><br><span class="line">kernel.panic_on_io_nmi = 1</span><br><span class="line">kernel.nmi_watchdog = 0</span><br><span class="line">kernel.numa_balancing=0</span><br><span class="line"></span><br><span class="line"><span class="comment">#Interrupt Coalescing (soft IRQ) and Ingress QDisc</span></span><br><span class="line"></span><br><span class="line">net.core.netdev_max_backlog=8192</span><br><span class="line"><span class="comment">#the maximum number of packets, queued on the INPUT side (the ingress qdisc), when the interface receives packets faster than kernel can process them</span></span><br><span class="line"><span class="comment"># Sets the maximum number of packets allowed to queue when a particular interface receives packets faster than the kernel can process them.</span></span><br><span class="line"><span class="comment"># Each CPU core can hold a number of packets in a ring buffer before the network stack is able to process them. If the buffer is filled faster than TCP stack can process them, a dropped packet counter is incremented and they will be dropped. The net.core.netdev_max_backlog setting should be increased to maximize the number of packets queued for processing on servers with high burst traffic.</span></span><br><span class="line"></span><br><span class="line">                                             softirq                              s o f t --------- i r q</span><br><span class="line">             |normal workload   | syscall  | handle 0|               | syscall |handle 1|handle 2|handle 3|</span><br><span class="line">---CPU core--------------------------------------------------------------------------------------------------</span><br><span class="line">             |                             |                                   |</span><br><span class="line">             |                             |                                   |</span><br><span class="line">       <span class="built_in">disable</span> irqs                      poll                                 poll</span><br><span class="line">             |                             |                                   |</span><br><span class="line">             |                             |                                   |</span><br><span class="line">---NIC------------------------------------------------------------------------------------------------------</span><br><span class="line">                                  pkg1         pkg1 pkg2                pkg3</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.core.somaxconn=4096 &lt;--After Linux 4.3------------before Linux 4.3-------&gt; tcp_max_syn_backlog</span><br><span class="line">              ^                             |</span><br><span class="line">recv SYN----  |     send SYN+ACK            |</span><br><span class="line">           |  |      ^                      |</span><br><span class="line">           V  |      |                      |</span><br><span class="line">        SYN queue---------recv ACK-----&gt; Accept queue------&gt; accept()------&gt; Application</span><br><span class="line">https://blog.cloudflare.com/syn-packet-handling-in-the-wild</span><br><span class="line">The tale of two queues</span><br><span class="line">https://github.com/torvalds/linux/commit/ef547f2ac16bd9d77a780a0e7c70857e69e8f23f<span class="comment">#diff-56ecfd3cd70d57cde321f395f0d8d743L43</span></span><br><span class="line"></span><br><span class="line">SYN Queue</span><br><span class="line">The SYN Queue stores inbound SYN packets[1] (specifically: struct inet_request_sock). It<span class="string">&#x27;s responsible for sending out SYN+ACK packets and retrying them on timeout.</span></span><br><span class="line"><span class="string">Accept Queue</span></span><br><span class="line"><span class="string">The Accept Queue contains fully established connections: ready to be picked up by the application. When a process calls accept(), the sockets are de-queued and passed to the application.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Each slot in SYN Queue uses some memory. During a SYN Flood it makes no sense to waste resources on storing attack packets. Each struct inet_request_sock entry in SYN Queue takes 256 bytes of memory on kernel 4.14.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">The NIC transfer data by the frame, and the frame has be splitted in sk_buff</span></span><br><span class="line"><span class="string">./drivers/net/ethernet/intel/ixgb/ixgb.h:99</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/* wrapper around a pointer to a socket buffer,</span></span><br><span class="line"><span class="string"> * so a DMA handle can be stored along with the buffer */</span></span><br><span class="line"><span class="string">struct ixgb_buffer &#123;</span></span><br><span class="line"><span class="string">        struct sk_buff *skb;</span></span><br><span class="line"><span class="string">        dma_addr_t dma;</span></span><br><span class="line"><span class="string">        unsigned long time_stamp;</span></span><br><span class="line"><span class="string">        u16 length;</span></span><br><span class="line"><span class="string">        u16 next_to_watch;</span></span><br><span class="line"><span class="string">        u16 mapped_as_page;</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">struct ixgb_desc_ring &#123;</span></span><br><span class="line"><span class="string">        /* pointer to the descriptor ring memory */</span></span><br><span class="line"><span class="string">        void *desc;</span></span><br><span class="line"><span class="string">        /* physical address of the descriptor ring */</span></span><br><span class="line"><span class="string">        dma_addr_t dma;</span></span><br><span class="line"><span class="string">        /* length of descriptor ring in bytes */</span></span><br><span class="line"><span class="string">        unsigned int size;</span></span><br><span class="line"><span class="string">        /* number of descriptors in the ring */</span></span><br><span class="line"><span class="string">        unsigned int count;</span></span><br><span class="line"><span class="string">        /* next descriptor to associate a buffer with */</span></span><br><span class="line"><span class="string">        unsigned int next_to_use;</span></span><br><span class="line"><span class="string">        /* next descriptor to check for DD status bit */</span></span><br><span class="line"><span class="string">        unsigned int next_to_clean;</span></span><br><span class="line"><span class="string">        /* array of buffer information structs */</span></span><br><span class="line"><span class="string">        struct ixgb_buffer *buffer_info;</span></span><br><span class="line"><span class="string">&#125;;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/**</span></span><br><span class="line"><span class="string"> * ixgb_setup_rx_resources - allocate Rx resources (Descriptors)</span></span><br><span class="line"><span class="string"> * @adapter: board private structure</span></span><br><span class="line"><span class="string"> *</span></span><br><span class="line"><span class="string"> * Returns 0 on success, negative on failure</span></span><br><span class="line"><span class="string"> **/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">int</span></span><br><span class="line"><span class="string">ixgb_setup_rx_resources(struct ixgb_adapter *adapter)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">i40e_clean_rx_irq_zc - Consumes Rx packets from the hardware ring</span></span><br><span class="line"><span class="string">  i40e_construct_skb_zc - Create skbufff from zero-copy Rx buffer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">i40e_add_rx_frag - Add contents of Rx buffer to sk_buff</span></span><br><span class="line"><span class="string">  skb_add_rx_frag</span></span><br><span class="line"><span class="string">    skb_fill_page_desc</span></span><br><span class="line"><span class="string">      __skb_fill_page_desc - initialise a paged fragment in an skb</span></span><br><span class="line"><span class="string">https://wsgzao.github.io/post/rps/</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">packet -&gt; NIC -&gt; internal hardware buffer/ring buffer in main memory -&gt; hardware interrupt request -&gt; software interrupt operation -&gt; </span></span><br><span class="line"><span class="string">from buffer to network stack -&gt; forwarded/discarded/rejected/passed to a socket receive queue for an application -&gt;</span></span><br><span class="line"><span class="string">remove from network stack until no packets left in NIC buffer or a certain number of packets are transferred (/proc/sys/net/core/dev_weight)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">                        network (packages)</span></span><br><span class="line"><span class="string">                         |---&lt;&lt;&lt;---5. new packages</span></span><br><span class="line"><span class="string">                         ||</span></span><br><span class="line"><span class="string">                        NIC  (hardware)-------------------------------------------------</span></span><br><span class="line"><span class="string">                         |                                                             | </span></span><br><span class="line"><span class="string">                         |                                                             V</span></span><br><span class="line"><span class="string">           ----------rx ring buffer(linux mem, fifo queue, ready/used status)&lt;--DMA copy the package to ring bufffer(Fetch description)                </span></span><br><span class="line"><span class="string">           |             |          ^                       |</span></span><br><span class="line"><span class="string">           |             |          |                       |</span></span><br><span class="line"><span class="string">6.write packs to SKB(DMA)|          |                       |</span></span><br><span class="line"><span class="string">           |             |          |  Each ready descriptor point an empty sk_buff(point sk_buff fail/timeout means something slow ? overflow/fifo err ???)</span></span><br><span class="line"><span class="string">           |             |          |  The kernel driver speed &lt; NIC receive packets = the ring buffer full cause packet loss(overrun/fifo err/ proc/net/dev)</span></span><br><span class="line"><span class="string">           |             |          |  No mem resource, The fifo overruns caused by the rate at which the buffer gets full and the kernel isn&#x27;</span>t to reclaim the buffer</span><br><span class="line">           |             |          |  No cpu resource, interrupt not balance and not affinity, eg: all nic interrupt <span class="keyword">in</span> core0</span><br><span class="line">           |             |          |  </span><br><span class="line">           |             |          |  6.write packet to SKB by DMA(hardware to driver)</span><br><span class="line">           |             |          |    The process: NIC send a hardware interrupt</span><br><span class="line">           |             |          |      --&gt; CPU receive the interrupt from drivers--&gt;kernel interrupt handler, send a soft interrupt</span><br><span class="line">           |             |          |        --&gt; kernel soft interrrupt hander --&gt;copy the SKB data to tcp/ip stacks</span><br><span class="line">           |             |          |</span><br><span class="line">           |             |         3. tell NIC there are some new descriptons</span><br><span class="line">           V             |                       ^</span><br><span class="line">    SKB|SKB|SKB(mem)     |                       |</span><br><span class="line">           ^             |                       |</span><br><span class="line">           |             |  ------&gt;2. Write description to rx ring</span><br><span class="line">           |             |  |</span><br><span class="line">  1.alloc sk_buff&lt;-----Driver  (kernel)  trigger a hardware interrupt to kernel( got packages from ring buffer)</span><br><span class="line">                         |               The NIC from the driver raised the IRQ to the kernel -- &gt; the kernel runs IRQ handler --&gt; NAPI started</span><br><span class="line">                         |</span><br><span class="line">                         |  &lt;---driver call into NAPI to start a poll loop <span class="keyword">if</span> NAPI was not running already</span><br><span class="line">                       NAPI or backlog (ksoftirqd call NAPI poll <span class="keyword">function</span> got the package from ring buffer)</span><br><span class="line">                         |  &lt;---ring buffer unmapped the memory from the package</span><br><span class="line">                         |  &lt;---Data that was DMA<span class="string">&#x27;d into memory is passed up the networking layer as an &#x27;</span>skb<span class="string">&#x27; for more processing.</span></span><br><span class="line"><span class="string">                         |  NAPI poller is added to poll_list -&gt; softirq_pending bit set -&gt;  run_ksoftirqd checks softirq_pending bit </span></span><br><span class="line"><span class="string">                         |                                                                                   |</span></span><br><span class="line"><span class="string">                         |                                                                                   -&gt; Registered handler called from softirq_vec handlers</span></span><br><span class="line"><span class="string">                         |   (from softnet_data Poll list)       (to softirq_pending bits)   (ksoftirqd/0 if pending -&gt; __do_softirq() -&gt; net_rx_action())</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         | poll_list entry received -&gt; Budget and Elapsed Time Checked -&gt; Driver poll function called -&gt;  Packet harvested from ring buffer</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         |  Without NAPI: 1 interrupt per packet → high CPU load</span></span><br><span class="line"><span class="string">                         |  With NAPI: polling during high packet arrival times</span></span><br><span class="line"><span class="string">                         |  No work to drop packets if kernel is too busy (Ring buffer overwrite by NIC)</span></span><br><span class="line"><span class="string">                         |  the ringbuffer is the RAM, if there is no special design, each ringbuffer(ring buff) store the package descriptor and it point the sk_buff (ready/used status)</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                       packet steering (Incoming network data frames are distributed among multiple CPUs if packet steering support)</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         |  continue by &quot;Driver poll function called&quot; -&gt; Packets passed for possible GRO -&gt; Packets coalesced or passed on toward  protocol stacks</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         |  (net_rx_action() -&gt; softnet_data Poll list -&gt; mydrv_poll() -&gt; napi_gro_receive() ---------&gt; net_receive_skb)</span></span><br><span class="line"><span class="string">                         |                                                    | Packet harvested from ring buffer   |  Packets coalesced or passed on toward protocol stacks</span></span><br><span class="line"><span class="string">                         |                                                    |---&gt;ring buffer                      |---&gt;GRO list</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                       network protocol stacks(TCP/IP Ethernet) (kernel, the data frames are handed to the protocol layers from the queues)</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                       socket buffer (kernel)</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                         |</span></span><br><span class="line"><span class="string">                       Application  (user)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">NAPI Exit</span></span><br><span class="line"><span class="string">  No more NAPI poll structures to process</span></span><br><span class="line"><span class="string">    netdev_budget Exceeded</span></span><br><span class="line"><span class="string">         Each driver hardcoded budget for one NAPI structure of 64</span></span><br><span class="line"><span class="string">         Default is 300</span></span><br><span class="line"><span class="string">         Approximately 5 driver poll calls</span></span><br><span class="line"><span class="string">    softirq Time Window Exceeded</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">If no structures remain, re-enable IRQ interrupt</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#trace stack</span></span><br><span class="line"><span class="string">do_IRQ ----&gt; driver trigger the softirq, set NET_RX_SOFTIRQ flag</span></span><br><span class="line"><span class="string">  irq_exit  ----&gt; not now ??</span></span><br><span class="line"><span class="string">     do_softirq ----&gt; the kernel think it need to do softirq</span></span><br><span class="line"><span class="string">       __do_softirq</span></span><br><span class="line"><span class="string">          net_rx_action</span></span><br><span class="line"><span class="string">            i40e_napi_poll ----&gt; NAPI poll (loop check the network device), util 300 frames (net.core.netdev_budget) or timeout(net.core.netdev_budget_usecs)</span></span><br><span class="line"><span class="string">              i40e_clean_rx_irq</span></span><br><span class="line"><span class="string">                napi_gro_receive</span></span><br><span class="line"><span class="string">                  netif_receive_skb(no RPS, only RPS need netdev_max_backlog)</span></span><br><span class="line"><span class="string">                    -&gt; netif_receive_skb_internal-&gt; malloc sk_buff, write metadata, remove the others, NET_RX_DROP for congestion control or protocol layer</span></span><br><span class="line"><span class="string">                    __netif_receive_skb ----&gt; set the skb to kernel tcp protocol stack</span></span><br><span class="line"><span class="string">                                    -&gt; if (sk_memalloc_socks() &amp;&amp; skb_pfmemalloc(skb)) ret = __netif_receive_skb_core(skb, true);</span></span><br><span class="line"><span class="string">                                                 --&gt;static_key_false</span></span><br><span class="line"><span class="string">                                    -&gt; tsk_restore_flags(current, pflags, PF_MEMALLOC); else ret = __netif_receive_skb_core(skb, false);</span></span><br><span class="line"><span class="string">                      __netif_receive_skb_core ----&gt; to protocol stack or tcpdump tap, goto qdisc (netdev_max_backlog)</span></span><br><span class="line"><span class="string">                               -&gt; net_timestamp_check</span></span><br><span class="line"><span class="string">                               -&gt; deliver_skb -&gt; ENOMEM DROP</span></span><br><span class="line"><span class="string">                               -&gt; static_key_false -&gt; sch_handle_ingress</span></span><br><span class="line"><span class="string">                               -&gt; pfmemalloc &amp;&amp; !skb_pfmemalloc_protocol -&gt; DROP</span></span><br><span class="line"><span class="string">                                   -&gt; Limit the use of PFMEMALLOC reserves to those protocols that implement the special handling of PFMEMALLOC skbs.</span></span><br><span class="line"><span class="string">                               -&gt; skb_orphan_frags orphan the frags contained in a buffer</span></span><br><span class="line"><span class="string">                                   For each frag in the SKB which needs a destructor (i.e. has an owner)</span></span><br><span class="line"><span class="string">                                   create a copy of that frag and release the original page by calling the destructor.</span></span><br><span class="line"><span class="string">                                   -&gt; skb_copy_ubufs to copy page and release the orgi page</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">net.core.dev_weight=128</span></span><br><span class="line"><span class="string"># the maximum number of packets that kernel can handle on a NAPI interrupt, it&#x27;</span>s a Per-CPU variable. For drivers that support LRO or GRO_HW, a hardware aggregated packet is counted as one packet <span class="keyword">in</span> this.</span><br><span class="line"></span><br><span class="line">net.core.netdev_budget=600</span><br><span class="line"><span class="comment">#is the maximum number of packets, queued on the INPUT side (the ingress qdisc), when the interface receives packets faster than kernel can process them.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## centos 7 not support, default value</span></span><br><span class="line"><span class="comment">#net.core.netdev_budget_usecs = 8000</span></span><br><span class="line"><span class="comment">#netdev_budget_usecs maximum number of microseconds in one NAPI polling cycle. Polling will exit when either netdev_budget_usecs have elapsed during the poll cycle or the number of packets processed reaches netdev_budget</span></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_reordering=128</span><br><span class="line"><span class="comment">## centos 7 not support, default value</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_max_reordering = 300</span></span><br><span class="line"><span class="comment">#Maximal reordering level of packets in a TCP stream. 300 is a fairly conservative value, but you might increase it if paths are using per packet load balancing (like bonding rr mode) Default: 300</span></span><br><span class="line"><span class="comment">## CentOS 7</span></span><br><span class="line"><span class="comment">#define TCP_MAX_REORDERING      127</span></span><br><span class="line">tcp_update_reordering -&gt; tp-&gt;reordering = min(TCP_MAX_REORDERING, metric);</span><br><span class="line"></span><br><span class="line">tcp_update_metrics-&gt;</span><br><span class="line">                /* Else slow start did not finish, cwnd is non-sense,</span><br><span class="line">                 * ssthresh may be also invalid.</span><br><span class="line">                 */</span><br><span class="line">-&gt;                             tp-&gt;reordering != sysctl_tcp_reordering)</span><br><span class="line">                                tcp_metric_set(tm, TCP_METRIC_REORDERING,</span><br><span class="line">                                               tp-&gt;reordering);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">net.ipv4.neigh.default.base_reachable_time_ms=30000000</span><br><span class="line">net.ipv4.neigh.bond0.base_reachable_time_ms=30000000</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_slow_start_after_idle=0</span><br><span class="line"><span class="comment">#disable tcp slow start in the LAN</span></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_fastopen=3</span><br><span class="line"></span><br><span class="line"><span class="comment">#avoid the bad udp package</span></span><br><span class="line">net.inet.udp.checksum=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#the others</span></span><br><span class="line">kernel.unknown_nmi_panic = 1</span><br><span class="line">kernel.panic_on_unrecovered_nmi = 1</span><br><span class="line">kernel.panic_on_io_nmi = 1</span><br><span class="line">kernel.nmi_watchdog = 0</span><br><span class="line">dev.raid.speed_limit_max=8000000</span><br><span class="line">dev.raid.speed_limit_min=2000000</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## if the NIC firmware support busy poll and enough CPU resource</span></span><br><span class="line"><span class="comment"># net.core.busy_poll = 50</span></span><br><span class="line"><span class="comment"># This parameter controls the number of microseconds to wait for packets on the device queue for socket poll and selects </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net.core.busy_read = 50</span></span><br><span class="line"><span class="comment"># This parameter controls the number of microseconds to wait for packets on the device queue for socket reads</span></span><br><span class="line"><span class="comment">#bnx2x</span></span><br><span class="line"><span class="comment">#be2net</span></span><br><span class="line"><span class="comment">#ixgbe</span></span><br><span class="line"><span class="comment">#mlx4</span></span><br><span class="line"><span class="comment">#myri10ge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#default</span></span><br><span class="line">net.ipv4.tcp_moderate_rcvbuf = 1</span><br><span class="line"><span class="comment">#disable ipv6</span></span><br><span class="line">net.ipv6.conf.all.disable_ipv6=1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#If set, TCP performs receive buffer auto-tuning, attempting to automatically size the buffer</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## default buffer is good enough for 10/25GbE in the low latency env, don&#x27;t to reset them </span></span><br><span class="line"><span class="comment">#net.core.rmem_default=425984</span></span><br><span class="line"><span class="comment">#net.core.rmem_max=425984</span></span><br><span class="line"><span class="comment">#net.core.wmem_default=425984</span></span><br><span class="line"><span class="comment">#net.core.wmem_max=425984</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_mem=6170046 8226732 12340092</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_rmem=8192       164760   12582912</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_wmem=8192       32768   8388608</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># default value</span></span><br><span class="line"><span class="comment">#net.core.rmem_default=212992</span></span><br><span class="line"><span class="comment">#This parameter controls the maximum size in bytes of a socket&#x27;s receive buffer. Use getsockopt to get current value</span></span><br><span class="line"><span class="comment">#net.core.rmem_max=212992</span></span><br><span class="line"><span class="comment">#This parameter controls the default size of the receive buffer used by sockets. This value must be smaller than or equal to the value of /proc/sys/net/core/rmem_max.</span></span><br><span class="line"><span class="comment">#This parameter controls the maximum size in bytes of a socket&#x27;s receive buffer. Use the getsockopt system call to determine the current value of the buffer.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#net.core.wmem_default=212992</span></span><br><span class="line"><span class="comment">#net.core.wmem_max=212992</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#ubuntu 20.04 default</span></span><br><span class="line">net.core.wmem_max = 16154422</span><br><span class="line">net.core.rmem_max = 16154422</span><br><span class="line">net.core.wmem_default = 8288608</span><br><span class="line">net.core.rmem_default = 8288608</span><br><span class="line">                                           -----------$((<span class="number">2097152</span>*<span class="number">4096</span>/<span class="number">1024</span>/<span class="number">1024</span>/<span class="number">1024</span>))=8G</span><br><span class="line">                                           |</span><br><span class="line">net.ipv4.tcp_mem = 32768	131072	2097152</span><br><span class="line">net.ipv4.tcp_rmem = 32768	65536	1048576</span><br><span class="line">net.ipv4.tcp_wmem = 32768	65536	1048576</span><br><span class="line"><span class="comment"># min (size used under memory pressure), default (initial size), max (maximum size) - size of receive buffer used by TCP sockets.</span></span><br><span class="line"><span class="comment"># default (initial size), max (maximum size) - size of send buffer used by TCP sockets.</span></span><br><span class="line"><span class="comment"># the number of pages(default 4K) allocated falls below the low, pressure, high mark.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#net.ipv4.tcp_early_retrans=3 (default)</span></span><br><span class="line">Probe Timeout(PTO), TCPLossProbes</span><br><span class="line"></span><br><span class="line"><span class="comment">#Egress qdisc</span></span><br><span class="line"><span class="comment">#default_qdisc is the default queuing discipline to use for network devices</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#default</span></span><br><span class="line">$ cat /proc/sys/net/core/default_qdisc</span><br><span class="line">pfifo_fast</span><br><span class="line"></span><br><span class="line">$ sysctl net.core.default_qdisc</span><br><span class="line">pfifo_fast/fq_codel/fq</span><br><span class="line"></span><br><span class="line">$ ifconfig ethX txqueuelen 1500</span><br><span class="line">txqueuelen is the maximum number of packets, queued on the OUTPUT side.</span><br><span class="line">default it <span class="string">&#x27;s the 1000 x skb, if it too long cause the bufferbloat   </span></span><br><span class="line"><span class="string">[如果没有一种机制公平地限定各个连接的发送数量，底层的qdisc/网卡队列就会被高发包率的应用占用，同时造成上层tcp计算RTT和cwnd的偏差，以及bufferbloat问题](http://www.cnhalo.net/2016/09/13/linux-tcp-small-queue/)   </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#This tunable is not present within RHEL kernels</span></span><br><span class="line"><span class="string">#This tunable is present in Red Hat MRG Realtime kernels</span></span><br><span class="line"><span class="string">#Control TCP delayed ACK and delayed sending</span></span><br><span class="line"><span class="string">net.ipv4.tcp_delack_min</span></span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/47450231/what-is-the-relationship-of-dma-ring-buffer-and-tx-rx-ring-for-a-network-card">The Ring Buffer</a> Contains Start and End Address of Buffer in RAM. TX Ring will contain addresses of Buffer in RAM that contains data to be transmitted. RX Ring will contains address of Buffer in RAM where NIC will place data.These rings are present in RAM.TX buffer and RX buffer are in RAM pointed by TX/RX rings. Now Network Card Register has Location of Rings Buffer in RAM.    </p>
<p><a target="_blank" rel="noopener" href="https://www.flamingbytes.com/2021/03/04/ring-buffer/">Receive ring buffers are shared between the device driver and NIC</a><br>The device driver drains the RX ring, typically via SoftIRQs which puts the incoming packets into a kernel data structure called an sk_buff or “skb” to begin its journey through the kernel and up to the application which owns the relevant socket.<br>The TX ring buffer is used to hold outgoing packets which are destined for the wire. When a NIC receives incoming data, it copies the data into kernel buffers using DMA. The NIC notifies the kernel of this data by raising a hard interrupt.  These interrupts are processed by interrupt handlers which do minimal work, as they have already interrupted another task and cannot be interrupted themselves. Hard interrupts can be expensive in terms of CPU usage, especially when holding kernel locks. The hard interrupt handler then leaves the majority of packet reception to a software interrupt, or SoftIRQ, process which can be scheduled more fairly.      </p>
<p>High end ethernet cards(eg: Mellanox) will almost certainly have their own memory and microprocessors to offload work from the rest of the computer. BTW: if tcp stack offload by NIC and bypass kernel that means the ring buffer in NIC.    </p>
<p>Low end ethernet cards may not have their own onboard memory or microprocessors, and will use the host system’s resources to handle network traffic.   </p>
<p>BTW: I think if you NIC adapter could not offload anything, that means all packages will process by linux, some low end ethernet cards could bypass kernel too, could use direct memory access for some of IO   </p>
<p>Infiniband cards on the other hand will tend to have their own onboard processors but no onboard memory, and will use direct memory access for all IO.     </p>
<p>Consider 9K jumbo frames, how long time will it take to empty 1024 jumbo frames on a 10G link:  </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">(9000*8)/(10000*10^6)*1000*1024 = 7.37ms</span><br><span class="line">But with 9K MTU and 512, we already have:</span><br><span class="line"> (9000*8)/(10000*10^6)*1000*512 = 3.69ms</span><br><span class="line">Guess the more normal use-case would be 1500+38 (Ethernet overhead)</span><br><span class="line"> (1538*8)/(10000*10^6)*1000*1024 = 1.25ms</span><br><span class="line">   |         |               |</span><br><span class="line">   |         |               -------1024 x Frames, the ring buffer</span><br><span class="line">   |         ---------10GbE</span><br><span class="line">   ----1500 + 38 (ethernet overhead)</span><br><span class="line"></span><br><span class="line">On top of V1 patchset:</span><br><span class="line"> - 6,747,016 pps - rx-usecs:  1 tx-ring: 1024 (irqs: 9492)</span><br><span class="line"> - 6,684,612 pps - rx-usecs: 10 tx-ring: 1024 (irqs:99322)</span><br><span class="line"> - 7,005,226 pps - rx-usecs: 20 tx-ring: 1024 (irqs:50444)</span><br><span class="line"> - 7,113,048 pps - rx-usecs: 30 tx-ring: 1024 (irqs:34004)</span><br><span class="line"> - 7,133,019 pps - rx-usecs: 40 tx-ring: 1024 (irqs:25845)</span><br><span class="line"> - 7,168,399 pps - rx-usecs: 50 tx-ring: 1024 (irqs:20896)</span><br><span class="line"></span><br><span class="line">Look same performance with 512 TX ring.</span><br><span class="line"></span><br><span class="line">Lowering TX ring size to (default) 512:</span><br><span class="line"> (On top of V1 patchset)</span><br><span class="line"> - 3,934,674 pps - rx-usecs:  1 tx-ring: 512 (irqs: 9602)</span><br><span class="line"> - 6,684,066 pps - rx-usecs: 10 tx-ring: 512 (irqs:99370)</span><br><span class="line"> - 7,001,235 pps - rx-usecs: 20 tx-ring: 512 (irqs:50567)</span><br><span class="line"> - 7,115,047 pps - rx-usecs: 30 tx-ring: 512 (irqs:34105)</span><br><span class="line"> - 7,130,250 pps - rx-usecs: 40 tx-ring: 512 (irqs:25741)</span><br><span class="line"> - 7,165,296 pps - rx-usecs: 50 tx-ring: 512 (irqs:20898)</span><br><span class="line"></span><br><span class="line">Look how even a 256 TX ring is enough, <span class="keyword">if</span> we cleanup the TX ring fast ennough, and how performance decrease <span class="keyword">if</span> we cleanup to slowly.</span><br><span class="line"></span><br><span class="line">Lowering TX ring size to (default) 256:</span><br><span class="line"> (On top of V1 patchset)</span><br><span class="line"> - 1,883,360 pps - rx-usecs:  1 tx-ring: 256 (irqs: 9800)</span><br><span class="line"> - 6,683,552 pps - rx-usecs: 10 tx-ring: 256 (irqs:99786)</span><br><span class="line"> - 7,005,004 pps - rx-usecs: 20 tx-ring: 256 (irqs:50749)</span><br><span class="line"> - 7,108,776 pps - rx-usecs: 30 tx-ring: 256 (irqs:34536)</span><br><span class="line"> - 5,734,301 pps - rx-usecs: 40 tx-ring: 256 (irqs:25909)</span><br><span class="line"> - 4,590,093 pps - rx-usecs: 50 tx-ring: 256 (irqs:21183)</span><br><span class="line"></span><br><span class="line"><span class="comment">## disable NAPI</span></span><br><span class="line">$ ethtool -C ethx rx-usecs 0 <span class="comment">##if disabled, tons of CPU interrupts</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://patchwork.ozlabs.org/project/netdev/patch/20140514141748.20309.83121.stgit@dragon/">About rx,tx-usecs, here is the test, just for reference</a><br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/17154759/how-much-memory-does-a-common-nic-have">how much memroy does a common nic have</a><br><a target="_blank" rel="noopener" href="https://ylgrgyq.github.io/2017/07/23/linux-receive-packet-1/">linux receive packet</a><br><a target="_blank" rel="noopener" href="https://people.redhat.com/pladd/MHVLUG_2017-04_Network_Receive_Stack.pdf">NIC Data Processing</a><br><img src="/img/ring-buffer.png"><br><img src="/img/2012110119582618-tcp-reception.png"><br><img src="/img/2012110119593557-tcp-transmission.png">   </p>
<p>txqueuelen = qdisc length = default 1000 x skb<br><a target="_blank" rel="noopener" href="https://www.nas.nasa.gov/assets/pdf/papers/NAS_Technical_Report_NAS-2014-01.pdf">This queue parameter is mostly applicable for high-speed WAN transfers. For low-latency networks, the default setting of 1000 is sufficient. The receiving end is configured with the sysctl setting net.core.netdev_max_backlog. The default for this setting is also 1000 and does not need to be modified unless there is significant latency</a>   </p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">$</span> ip link <span class="keyword">set</span> dev <span class="comment">bond0 txqueuelen 1500</span></span><br><span class="line">$ ip <span class="comment">link set dev enp5s0 txqueuelen 1500</span></span><br><span class="line">$ ip <span class="comment">link set dev enp5s0d1 txqueuelen 1500</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Default TSQ limit of four TSO segments */</span></span><br><span class="line">net.ipv4.tcp_limit_output_bytes <span class="comment">= 262144</span></span><br></pre></td></tr></table></figure>

<h5 id="Memory-resource"><a href="#Memory-resource" class="headerlink" title="Memory resource"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/4085851">Memory resource</a></h5><p><a target="_blank" rel="noopener" href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=8fe809a992639b2013c0d8da2ba55cdea28a959a">add LINUX_MIB_PFMEMALLOCDROP counter</a>   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/net/netstat</span><br><span class="line">$ nstat -sz TcpExtPFMemallocDrop</span><br><span class="line">TcpExtPFMemallocDrop            183623                  0.0</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">include/net/sock.h</span><br><span class="line">SOCK_MEMALLOC, <span class="comment">/* VM depends on this socket for swapping */</span></span><br><span class="line"></span><br><span class="line">./include/linux/mm_types.h:<span class="number">62</span></span><br><span class="line">        <span class="comment">/* Second double word */</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">                <span class="keyword">union</span> &#123;</span><br><span class="line">                        <span class="keyword">pgoff_t</span> index;          <span class="comment">/* Our offset within mapping. */</span></span><br><span class="line">                        <span class="keyword">void</span> *freelist;         <span class="comment">/* slub/slob first free object */</span></span><br><span class="line">                        RH_KABI_DEPRECATE(<span class="keyword">bool</span>, pfmemalloc)</span><br><span class="line">                                                <span class="comment">/* If set by the page allocator,</span></span><br><span class="line"><span class="comment">                                                 * ALLOC_NO_WATERMARKS was set</span></span><br><span class="line"><span class="comment">                                                 * and the low watermark was not</span></span><br><span class="line"><span class="comment">                                                 * met implying that the system</span></span><br><span class="line"><span class="comment">                                                 * is under some pressure. The</span></span><br><span class="line"><span class="comment">                                                 * caller should try ensure</span></span><br><span class="line"><span class="comment">                                                 * this page is only used to</span></span><br><span class="line"><span class="comment">                                                 * free other pages.</span></span><br><span class="line"><span class="comment">                                                 */</span></span><br></pre></td></tr></table></figure>
<p>if set by the page allocator ALLOC_NO_WATERMARKS was set and the low watermark was not met implying that the system is under some pressure. the caller should try ensure this page is only used to free other pages     </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br></pre></td><td class="code"><pre><span class="line">./include/linux/skbuff.h:<span class="number">634</span>: * @pfmemalloc: skbuff was allocated from PFMEMALLOC reserves</span><br><span class="line"></span><br><span class="line">If the skb was allocated from pfmemalloc reserves, only allow SOCK_MEMALLOC sockets to use it as <span class="keyword">this</span> socket is helping <span class="built_in">free</span> memory</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">sk_filter_trim_cap</span><span class="params">(struct sock *sk, struct sk_buff *skb, <span class="keyword">unsigned</span> <span class="keyword">int</span> cap)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> err;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">sk_filter</span> *<span class="title">filter</span>;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * If the skb was allocated from pfmemalloc reserves, only</span></span><br><span class="line"><span class="comment">         * allow SOCK_MEMALLOC sockets to use it as this socket is</span></span><br><span class="line"><span class="comment">         * helping free memory</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (skb_pfmemalloc(skb) &amp;&amp; !sock_flag(sk, SOCK_MEMALLOC)) &#123;</span><br><span class="line">                NET_INC_STATS(sock_net(sk), LINUX_MIB_PFMEMALLOCDROP);</span><br><span class="line">                <span class="keyword">return</span> -ENOMEM;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                        ip_rcv ----&gt; process the ip protocol</span><br><span class="line">                          ip_rcv_finish</span><br><span class="line">                            ip_local_deliver</span><br><span class="line">                              ip_local_deliver_finish</span><br><span class="line">                                -&gt; __skb_pull <span class="comment">// remove data from the start of a buffer</span></span><br><span class="line">                                tcp_v4_rcv ----&gt; Layer <span class="number">4</span> tcp_v4_rec</span><br><span class="line">                                  tcp_md5_do_lookup</span><br><span class="line">                                    tcp_parse_md5sig_option</span><br><span class="line">                                      tcp_filter</span><br><span class="line">                                        sk_filter_trim_cap (<span class="keyword">return</span> <span class="number">-12</span> ENOMEM out of memory) ----&gt; kmalloc <span class="keyword">or</span> sock_kmalloc mem timeout</span><br><span class="line"></span><br><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/include/linux/gfp.h</span><br><span class="line">warn_alloc_failed: <span class="number">776</span> callbacks suppressed</span><br><span class="line">page allocation failure: order:<span class="number">2</span>, mode:<span class="number">0x4020</span></span><br><span class="line">                                          |</span><br><span class="line">                                          ---gpf_mask</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ___GFP_HIGH             0x20u       <span class="comment">//This allocation has high priority and may use emergency pools.</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ___GFP_COMP             0x4000u     <span class="comment">//https://stackoverflow.com/questions/62486827/about-the-usage-of-gfp-comp</span></span></span><br><span class="line"></span><br><span class="line">order:<span class="number">2</span> means <span class="number">2</span>^<span class="number">2</span>=<span class="number">4</span> x <span class="number">4</span>Kpages = <span class="number">16</span>KB</span><br><span class="line">order:<span class="number">4</span> means <span class="number">16</span>x4pages = <span class="number">64</span>KB, order:<span class="number">10</span> means <span class="number">1024</span> x <span class="number">4</span>K pages=<span class="number">4096</span>KB</span><br><span class="line">mode:<span class="number">0x4020</span> - A bitmask flag</span><br><span class="line"># In interrupt context it is <span class="keyword">not</span> possible to reclaim memory, <span class="keyword">or</span> wait <span class="keyword">for</span> memory to be freed, to satisfy an allocation request. Therefore, <span class="keyword">if</span> <span class="string">&quot;free&quot;</span> privileged memory on a system is low, at the time of the allocation, the allocation will simply fail. Failed GFP_ATOMIC allocations by the network <span class="built_in">stack</span> result in dropped packets which is likely to be received on a subsequent retransmit. They can also result in unexpected behaviour within various NIC drivers in the event that the calling codepath does <span class="keyword">not</span> gracefully recover from the allocation failure. Note that a mode value like <span class="number">0x4020</span> <span class="keyword">or</span> <span class="number">0x20</span> as reported in the <span class="string">&quot;page allocation failure&quot;</span> message (a value ending in <span class="number">0x20</span>, the <span class="number">1</span>&lt;&lt;<span class="number">5</span> bit <span class="built_in">set</span>) is a GFP_ATOMIC allocation. The order is the size of the allocation defined as: size = <span class="number">2</span>^order pages. For instance, an order <span class="number">0</span> allocation request a single page (<span class="number">4</span>k on most archs), an order <span class="number">4</span> allocation request <span class="number">16</span> pages (<span class="number">64</span>k on most archs). The bigger the order, the more difficult the atomic allocation is going to be satisfied</span><br><span class="line">#https:<span class="comment">//access.redhat.com/solutions/479983</span></span><br><span class="line"></span><br><span class="line">#linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/include/linux/gfp.h</span><br><span class="line">Two types:</span><br><span class="line">zone modifiers</span><br><span class="line">action modifiers</span><br><span class="line">alloc_page-------------------------------single page</span><br><span class="line">get_zeroed_page--&gt;__get_free_pages</span><br><span class="line">    alloc_pages-------------------------<span class="number">-2</span>^order</span><br><span class="line">        alloc_pages_node-----------------node id</span><br><span class="line">            __alloc_pages</span><br><span class="line">                __alloc_pages_node_mask--nodemaks</span><br><span class="line"></span><br><span class="line">__GFP_DMA         ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x01</span>u)</span><br><span class="line">__GFP_HIGHMEM     ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x02</span>u)</span><br><span class="line">__GFP_DMA32       ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x04</span>u)</span><br><span class="line">__GFP_MOVABLE     ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x08</span>u) <span class="comment">/* Flag that this page will be movable by the */</span></span><br><span class="line">                                             <span class="comment">/* page migration mechanism or reclaimed */</span></span><br><span class="line">__GFP_WAIT        ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x10</span>u) <span class="comment">/* Can wait and reschedule? */</span></span><br><span class="line">__GFP_HIGH        ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x20</span>u) <span class="comment">/* Should access emergency pools? */</span></span><br><span class="line">__GFP_IO          ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x40</span>u) <span class="comment">/* Can start physical IO? */</span></span><br><span class="line">__GFP_FS          ((__force <span class="keyword">gfp_t</span>)    <span class="number">0x80</span>u) <span class="comment">/* Can call down to low-level FS? */</span></span><br><span class="line">__GFP_COLD        ((__force <span class="keyword">gfp_t</span>)   <span class="number">0x100</span>u) <span class="comment">/* Cache-cold page required */</span></span><br><span class="line">__GFP_NOWARN      ((__force <span class="keyword">gfp_t</span>)   <span class="number">0x200</span>u) <span class="comment">/* Suppress page allocation failure warning */</span></span><br><span class="line">__GFP_REPEAT      ((__force <span class="keyword">gfp_t</span>)   <span class="number">0x400</span>u) <span class="comment">/* Try hard to allocate the memory, but the */</span></span><br><span class="line">                                             <span class="comment">/* allocation attempt _might_ fail.  This */</span></span><br><span class="line">                                             <span class="comment">/* depends upon the particular VM implementation. */</span></span><br><span class="line">__GFP_NOFAIL      ((__force <span class="keyword">gfp_t</span>)   <span class="number">0x800</span>u) <span class="comment">/* The VM implementation _must_ retry infinitely: */</span></span><br><span class="line">                                             <span class="comment">/* the caller cannot handle allocation failures. */</span></span><br><span class="line">__GFP_NORETRY     ((__force <span class="keyword">gfp_t</span>)  <span class="number">0x1000</span>u) <span class="comment">/* The VM implementation must not retry indefinitely */</span></span><br><span class="line">__GFP_COMP        ((__force <span class="keyword">gfp_t</span>)  <span class="number">0x4000</span>u) <span class="comment">/* Add compound page metadata */</span></span><br><span class="line">__GFP_ZERO        ((__force <span class="keyword">gfp_t</span>)  <span class="number">0x8000</span>u) <span class="comment">/* Return zeroed page on success */</span></span><br><span class="line">__GFP_NOMEMALLOC  ((__force <span class="keyword">gfp_t</span>) <span class="number">0x10000</span>u) <span class="comment">/* Don&#x27;t use emergency reserves */</span></span><br><span class="line">__GFP_HARDWALL    ((__force <span class="keyword">gfp_t</span>) <span class="number">0x20000</span>u) <span class="comment">/* Enforce hardwall cpuset memory allocs */</span></span><br><span class="line">__GFP_THISNODE    ((__force <span class="keyword">gfp_t</span>) <span class="number">0x40000</span>u) <span class="comment">/* No fallback, no policies */</span></span><br><span class="line">__GFP_RECLAIMABLE ((__force <span class="keyword">gfp_t</span>) <span class="number">0x80000</span>u) <span class="comment">/* Page is reclaimable */</span></span><br><span class="line">__GFP_NOTRACK     ((__force <span class="keyword">gfp_t</span>)<span class="number">0x200000</span>u) <span class="comment">/* Don&#x27;t track with kmemcheck */</span></span><br><span class="line">__GFP_NO_KSWAPD   ((__force <span class="keyword">gfp_t</span>)<span class="number">0x400000</span>u)</span><br><span class="line">__GFP_OTHER_NODE  ((__force <span class="keyword">gfp_t</span>)<span class="number">0x800000</span>u)</span><br><span class="line"></span><br><span class="line">GFP_ATOMIC        (__GFP_HIGH)               <span class="comment">/* !wait (__GFP_WAIT not set) and use emergency pool *</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">https://www.kernel.org/doc/htmldocs/kernel-api/API-kmalloc.html</span></span><br><span class="line"><span class="comment">/* To avoid unnecessary overhead, we pass through large allocation requests</span></span><br><span class="line"><span class="comment"> * directly to the page allocator. We use __GFP_COMP, because we will need to</span></span><br><span class="line"><span class="comment"> * know the allocation order to free the pages properly in kfree. */</span></span><br><span class="line"></span><br><span class="line">当__alloc_pages分配标志gfp_flags指定了__GFP_COMP，那么内核必须将这些页组合成复合页compound page。第一个页称为head page,其余所有的页称为tail page。复合页的尺寸要远大于当前分&gt;页系统支持的页面大小。并且一定是<span class="number">2</span>^order * PAGE_SIZE大小。复合页主要用在HugeTLB相关的代码</span><br><span class="line">当页面分配函数使用GFP_COMP进行页面分配时，分配函数会为每一个增加标志PG_Compound，我们称复合页中的第一个<span class="number">4</span>KB页面为head page，后面的所有page 为tail page。每个page的<span class="keyword">private</span>保存&gt;一个指针，head page的<span class="keyword">private</span>指向本身，tail page的<span class="keyword">private</span>指向head page</span><br><span class="line"></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line"><span class="number">192.168</span><span class="number">.0</span><span class="number">.222</span>      <span class="number">814</span>   -&gt; <span class="number">192.168</span><span class="number">.0</span><span class="number">.111</span>    <span class="number">2049</span> , retval <span class="number">-12</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">/usr/include/<span class="keyword">asm</span>-generic/errno-base.h</span><br><span class="line">#define ENOMEM          <span class="number">12</span>      <span class="comment">/* Out of memory */</span></span><br><span class="line"></span><br><span class="line">#!/usr/bin/bpftrace</span><br><span class="line">#include &lt;net/sock.h&gt;</span><br><span class="line">#include &lt;linux/skbuff.h&gt;</span><br><span class="line"></span><br><span class="line">k:sk_filter_trim_cap</span><br><span class="line">&#123;</span><br><span class="line">        @sk[tid] = arg0;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">kr:sk_filter_trim_cap</span><br><span class="line">/@sk[tid]/</span><br><span class="line">&#123;</span><br><span class="line">        $sk = (struct sock *)@sk[tid];</span><br><span class="line"></span><br><span class="line">        $af = $sk-&gt;__sk_common.skc_family;</span><br><span class="line">        <span class="keyword">if</span> ($af == AF_INET) &#123;</span><br><span class="line">            $daddr = ntop($af, $sk-&gt;__sk_common.skc_daddr);</span><br><span class="line">            $saddr = ntop($af, $sk-&gt;__sk_common.skc_rcv_saddr);</span><br><span class="line">            $lport = $sk-&gt;__sk_common.skc_num;</span><br><span class="line">            $dport = $sk-&gt;__sk_common.skc_dport;</span><br><span class="line"></span><br><span class="line">            $dport = ($dport &gt;&gt; <span class="number">8</span>) | (($dport &lt;&lt; <span class="number">8</span>) &amp; <span class="number">0xff00</span>);</span><br><span class="line">            <span class="keyword">if</span> (retval &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%-15s %-5d -&gt; %-15s %-5d, retval %d\n&quot;</span>,</span><br><span class="line">                $saddr, $lport, $daddr, $dport, retval);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">delete</span>(@sk[tid]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">or</span> you could</span><br><span class="line">$ perf probe -a &#x27;sk_filter_trim_cap%return return=$retval:s32&#x27;</span><br><span class="line">$ perf record -e probe:sk_filter_trim_cap -agR --filter &#x27;return &lt; 0&#x27; sleep 10</span><br><span class="line"></span><br><span class="line">$ perf probe -d probe:sk_filter_trim_cap</span><br><span class="line"><span class="keyword">or</span></span><br><span class="line"><span class="comment">// or for kernels &lt; 3.10.0-1062.el7 :</span></span><br><span class="line">$ perf record -e probe:sk_filter_trim_cap__return -agR --filter &#x27;return &lt; 0&#x27; sleep 10</span><br><span class="line">$ perf report</span><br><span class="line"></span><br><span class="line">#<span class="meta"># ftrace</span></span><br><span class="line">$ echo <span class="number">0</span> &gt; /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/enable</span><br><span class="line">$ echo  &gt; /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">$ echo &#x27;r:sk_filter_trim_cap sk_filter_trim_cap $retval&#x27; &gt; /sys/kernel/debug/tracing/kprobe_events</span><br><span class="line">$ echo <span class="number">1</span> &gt; /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/enable</span><br><span class="line"></span><br><span class="line">cat /sys/kernel/debug/tracing/events/kprobes/sk_filter_trim_cap/format</span><br><span class="line">name: sk_filter_trim_cap</span><br><span class="line">ID: <span class="number">1548</span></span><br><span class="line">format:</span><br><span class="line">       field:<span class="keyword">unsigned</span> <span class="keyword">short</span> common_type;       offset:<span class="number">0</span>;       size:<span class="number">2</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">       field:<span class="keyword">unsigned</span> <span class="keyword">char</span> common_flags;       offset:<span class="number">2</span>;       size:<span class="number">1</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">       field:<span class="keyword">unsigned</span> <span class="keyword">char</span> common_preempt_count;       offset:<span class="number">3</span>;       size:<span class="number">1</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">       field:<span class="keyword">int</span> common_pid;   offset:<span class="number">4</span>;       size:<span class="number">4</span>; <span class="keyword">signed</span>:<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">       field:<span class="keyword">unsigned</span> <span class="keyword">long</span> __probe_func;       offset:<span class="number">8</span>;       size:<span class="number">8</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">       field:<span class="keyword">unsigned</span> <span class="keyword">long</span> __probe_ret_ip;     offset:<span class="number">16</span>;      size:<span class="number">8</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">       field:u64 arg1; offset:<span class="number">24</span>;      size:<span class="number">8</span>; <span class="keyword">signed</span>:<span class="number">0</span>;</span><br><span class="line">print fmt: <span class="string">&quot;(%lx &lt;- %lx) arg1=0x%Lx&quot;</span>, REC-&gt;__probe_func, REC-&gt;__probe_ret_ip, REC-&gt;arg1</span><br><span class="line"></span><br><span class="line">$ cat /sys/kernel/debug/tracing/trace</span><br><span class="line"><span class="meta"># tracer: nop</span></span><br><span class="line">#</span><br><span class="line"><span class="meta"># entries-in-buffer/entries-written: 52403/52403   #P:96</span></span><br><span class="line">#</span><br><span class="line">#                              _-----=&gt; irqs-off</span><br><span class="line">#                             / _----=&gt; need-resched</span><br><span class="line">#                            | / _---=&gt; hardirq/softirq</span><br><span class="line">#                            || / _--=&gt; preempt-depth</span><br><span class="line">#                            ||| /     delay</span><br><span class="line">#           TASK-PID   CPU#  ||||    TIMESTAMP  FUNCTION</span><br><span class="line">#              | |       |   ||||       |         |</span><br><span class="line">          &lt;idle&gt;<span class="number">-0</span>     [<span class="number">006</span>] d.s. <span class="number">736525.098807</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">           &lt;...&gt;<span class="number">-156973</span> [<span class="number">006</span>] d.s. <span class="number">736532.093611</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">           &lt;...&gt;<span class="number">-156973</span> [<span class="number">006</span>] d.s. <span class="number">736532.093615</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">           &lt;...&gt;<span class="number">-156973</span> [<span class="number">006</span>] d.s. <span class="number">736532.093618</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">          &lt;idle&gt;<span class="number">-0</span>     [<span class="number">006</span>] dNs. <span class="number">736532.093644</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">          &lt;idle&gt;<span class="number">-0</span>     [<span class="number">006</span>] dNs. <span class="number">736532.093653</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">          &lt;idle&gt;<span class="number">-0</span>     [<span class="number">006</span>] dNs. <span class="number">736532.093655</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line">          &lt;idle&gt;<span class="number">-0</span>     [<span class="number">006</span>] dNs. <span class="number">736532.093656</span>: sk_filter_trim_cap: (tcp_filter+<span class="number">0x2c</span>/<span class="number">0x40</span> &lt;- sk_filter_trim_cap) arg1=<span class="number">0xfffffff4</span></span><br><span class="line"></span><br><span class="line">$ ./trace &#x27;r::sk_filter_trim_cap (retval != 0) &quot;%d&quot;, retval&#x27;</span><br><span class="line"><span class="number">281</span>     <span class="number">281</span>     ksoftirqd/<span class="number">54</span>    sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"><span class="number">281</span>     <span class="number">281</span>     ksoftirqd/<span class="number">54</span>    sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"><span class="number">20818</span>   <span class="number">81613</span>   user_app        sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"><span class="number">20818</span>   <span class="number">81613</span>   user_app        sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"><span class="number">314457</span>  <span class="number">314457</span>  kworker/<span class="number">54</span>:<span class="number">1</span>H   sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"><span class="number">314457</span>  <span class="number">314457</span>  kworker/<span class="number">54</span>:<span class="number">1</span>H   sk_filter_trim_cap <span class="number">-12</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#transmit</span></span><br><span class="line">$ echo <span class="number">1</span> &gt; /sys/kernel/debug/tracing/events/sock/sock_exceed_buf_limit/enable</span><br><span class="line"><span class="meta">#too many tcp connection or tcp_mem limit the send packages</span></span><br><span class="line">$ cat /sys/kernel/debug/tracing/trace_pipe</span><br><span class="line"></span><br><span class="line"><span class="meta">#https:<span class="comment">//sourceware.org/systemtap/examples/network/sk_stream_wait_memory.stp</span></span></span><br></pre></td></tr></table></figure>
<p>In interrupt context it is not possible to reclaim memory, or wait for memory to be freed, to satisfy an allocation request. Therefore, if “free” privileged memory on a system is low, at the time of the allocation, the allocation will simply fail. Failed GFP_ATOMIC allocations by the network stack result in dropped packets which is likely to be received on a subsequent retransmit. They can also result in unexpected behaviour within various NIC drivers in the event that the calling codepath does not gracefully recover from the allocation failure. Note that a mode value like 0x4020 or 0x20 as reported in the “page allocation failure” message (a value ending in 0x20, the 1&lt;&lt;5 bit set) is a GFP_ATOMIC allocation. The order is the size of the allocation defined as: size = 2^order pages. For instance, an order 0 allocation request a single page (4k on most archs), an order 4 allocation request 16 pages (64k on most archs). The bigger the order, the more difficult the atomic allocation is going to be satisfied</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">  <span class="number">70</span>)               |              sock_alloc_send_skb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                sock_alloc_send_pskb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                  alloc_skb_with_frags() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                    __alloc_skb() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                      kmem_cache_alloc_node() &#123;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.086</span> us    |                        _cond_resched();</span><br><span class="line">  <span class="number">70</span>)               |                        <span class="comment">/* kmem_cache_alloc_node: call_site=ffffffffaa596c15 ptr=ffff90df02f24200 bytes_req=256 bytes_alloc=256 gfp_flags=GFP_KERNEL|GFP_REPEAT node=-1 */</span></span><br><span class="line">  <span class="number">70</span>)   <span class="number">1.555</span> us    |                      &#125;</span><br><span class="line">  <span class="number">70</span>)               |                      __kmalloc_reserve.isra<span class="number">.32</span>() &#123;</span><br><span class="line">  <span class="number">70</span>)               |                        __kmalloc_node_track_caller() &#123;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.132</span> us    |                          kmalloc_slab();</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.080</span> us    |                          _cond_resched();</span><br><span class="line">  <span class="number">70</span>)               |                          <span class="comment">/* kmalloc_node: call_site=ffffffffaa596c15 ptr=ffff90e493aae800 bytes_req=576 bytes_alloc=1024 gfp_flags=GFP_KERNEL|GFP_NOWARN|GFP_REPEAT|GFP_NOMEMALLOC node=-1 */</span></span><br><span class="line">  <span class="number">70</span>)   <span class="number">2.109</span> us    |                        &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">2.924</span> us    |                      &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">0.484</span> us    |                      ksize();</span><br><span class="line">  <span class="number">70</span>)   <span class="number">7.259</span> us    |                    &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">8.129</span> us    |                  &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">9.136</span> us    |                &#125;</span><br><span class="line">  <span class="number">70</span>)   <span class="number">9.914</span> us    |              &#125;</span><br><span class="line"></span><br><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/net/core/skbuff.c</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * kmalloc_reserve is a wrapper around kmalloc_node_track_caller that tells</span></span><br><span class="line"><span class="comment"> * the caller if emergency pfmemalloc reserves are being used. If it is and</span></span><br><span class="line"><span class="comment"> * the socket is later found to be SOCK_MEMALLOC then PFMEMALLOC reserves</span></span><br><span class="line"><span class="comment"> * may be used. Otherwise, the packet data may be discarded until enough</span></span><br><span class="line"><span class="comment"> * memory is free</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> kmalloc_reserve(size, gfp, node, pfmemalloc) \</span></span><br><span class="line">         __kmalloc_reserve(size, gfp, node, _RET_IP_, pfmemalloc)</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span> *__kmalloc_reserve(<span class="keyword">size_t</span> size, <span class="keyword">gfp_t</span> flags, <span class="keyword">int</span> node,</span><br><span class="line">                               <span class="keyword">unsigned</span> <span class="keyword">long</span> ip, <span class="keyword">bool</span> *pfmemalloc)</span><br><span class="line">&#123;</span><br><span class="line">        <span class="keyword">void</span> *obj;</span><br><span class="line">        <span class="keyword">bool</span> ret_pfmemalloc = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Try a regular allocation, when that fails and we&#x27;re not entitled</span></span><br><span class="line"><span class="comment">         * to the reserves, fail.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        obj = kmalloc_node_track_caller(size,</span><br><span class="line">                                        flags | __GFP_NOMEMALLOC | __GFP_NOWARN,</span><br><span class="line">                                        node);</span><br><span class="line">        <span class="keyword">if</span> (obj || !(gfp_pfmemalloc_allowed(flags)))</span><br><span class="line">                <span class="keyword">goto</span> out;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Try again but now we are using pfmemalloc reserves */</span></span><br><span class="line">        ret_pfmemalloc = <span class="literal">true</span>;</span><br><span class="line">        obj = kmalloc_node_track_caller(size, flags, node);</span><br><span class="line"></span><br><span class="line">out:</span><br><span class="line">        <span class="keyword">if</span> (pfmemalloc)</span><br><span class="line">                *pfmemalloc = ret_pfmemalloc;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> obj;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="Enable-jumbo-frames"><a href="#Enable-jumbo-frames" class="headerlink" title="Enable jumbo frames"></a><a target="_blank" rel="noopener" href="http://ehealth-aussie.blogspot.com/2011/11/in-depth-look-into-path-mtu-discovery.html">Enable jumbo frames</a></h5><p>not pass test ???</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_mtu_probing = 1</span><br><span class="line">net.ipv4.tcp_base_mss = 512</span><br><span class="line">net.ipv4.ip_no_pmtu_disc = 0</span><br><span class="line"></span><br><span class="line">net.ipv4.route.mtu_expires = 600</span><br><span class="line">net.ipv4.tcp_probe_interval = 120</span><br><span class="line">net.ipv4.ip_forward_use_pmtu = 0</span><br><span class="line"></span><br><span class="line">Enabling tcp_mtu_probing ensure the connection can recover gracefully <span class="keyword">if</span> frames larger than the WAN MTU are sent and there is no ICMP reply. Or to explain it <span class="keyword">in</span> more detail, consider <span class="keyword">if</span> linux system repeatedly sends several packets of say 1514 bytes (greater than MTUof the WAN) <span class="keyword">then</span> those packets are never responded as they are being dropped by the WAN. With tcp_mtu_probing turned on, the system should react to this <span class="built_in">type</span> of failure by trying to send a smaller packet. In this way it realizes the MTU of the link is lower.</span><br><span class="line">          0 - Disabled</span><br><span class="line">          1 - Disabled by default, enabled when an ICMP black hole detected</span><br><span class="line">          2 - Always enabled, use initial MSS of tcp_base_mss rather than value notified by peer</span><br><span class="line"></span><br><span class="line">tcp_base_mss defines the initial value of search_low to be used by the packetization layer Path MTU discovery (tcp_mtu_probing ). If MTU probing is enabled, this is the initial MSS used by the connection. Default value is 512.</span><br><span class="line"></span><br><span class="line">+----------------+                                +-----------+</span><br><span class="line"> | system <span class="comment">#1      |                                | system #2 |</span></span><br><span class="line"> |                |                                |           |</span><br><span class="line"> | mss 1460       |                                | mss 960   |</span><br><span class="line"> |                |  -----&gt; init (mss1460) -----&gt;  |           |</span><br><span class="line"> |                |  &lt;----- init (mss 960) &lt;-----  |           |</span><br><span class="line"> |                |  -----&gt; data (mss 960) -----&gt;  |           |</span><br><span class="line"> |                |  &lt;----- data (mss 960) &lt;-----  |           |</span><br><span class="line"> +----------------+                                +-----------+</span><br><span class="line"></span><br><span class="line">If MSS value is <span class="built_in">set</span> on system <span class="comment">#1, network flow is as below below:</span></span><br><span class="line">tcp_mtu_probing = 2 and tcp_base_mss = 1200</span><br><span class="line">    +--------------------+                                 +-----------+</span><br><span class="line">    | system <span class="comment">#1          |                                 | system #2 |</span></span><br><span class="line">    |                    |                                 |           |</span><br><span class="line">    | mss 1460           |                                 | mss 960   |</span><br><span class="line">    | tcp_mtu_probing=2  |   -----&gt; init (mss1460) -----&gt;  |           |</span><br><span class="line">    | tcp_base_mss=1200  |  &lt;----- init (mss 960) &lt;-----   |           |</span><br><span class="line">    |                    |                                 |           |</span><br><span class="line">    |                    |  -----&gt; data (mss 1200) -----&gt;  |           |</span><br><span class="line">    |                    |        (will be dropped)        |           |</span><br><span class="line">    |                    |  &lt;----- update  &lt;-------------  |           |</span><br><span class="line">    |                    |  -----&gt; data (mss 600) -----&gt;   |           |</span><br><span class="line">    +--------------------+                                 +-----------+</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="Enabled-in-default"><a href="#Enabled-in-default" class="headerlink" title="Enabled in default"></a>Enabled in default</h5><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># don&#x27;t cache ssthresh from previous connection</span></span><br><span class="line"><span class="string">net.ipv4.tcp_no_metrics_save</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#use cookies to process SYN queue overflow</span></span><br><span class="line"><span class="string">net.ipv4.tcp_syncookies</span> <span class="string">=</span> <span class="number">1</span></span><br><span class="line"><span class="comment">#net/ipv4/tcp_ipv4.c</span></span><br><span class="line"><span class="comment">#ifdef CONFIG_SYN_COOKIES</span></span><br><span class="line">        <span class="string">if</span> <span class="string">(sysctl_tcp_syncookies)</span> &#123;</span><br><span class="line">                <span class="string">msg</span> <span class="string">=</span> <span class="string">&quot;Sending cookies&quot;</span><span class="string">;</span></span><br><span class="line">                <span class="string">want_cookie</span> <span class="string">=</span> <span class="literal">true</span><span class="string">;</span></span><br><span class="line">                <span class="string">NET_INC_STATS_BH(sock_net(sk)</span>, <span class="string">LINUX_MIB_TCPREQQFULLDOCOOKIES);</span></span><br><span class="line">        &#125; <span class="string">else</span></span><br><span class="line"><span class="comment">#endif</span></span><br><span class="line">                <span class="string">NET_INC_STATS_BH(sock_net(sk),</span> <span class="string">LINUX_MIB_TCPREQQFULLDROP);</span></span><br><span class="line"></span><br><span class="line">        <span class="string">lopt</span> <span class="string">=</span> <span class="string">inet_csk(sk)-&gt;icsk_accept_queue.listen_opt;</span></span><br><span class="line">        <span class="string">if</span> <span class="string">(!lopt-&gt;synflood_warned</span> <span class="string">&amp;&amp;</span> <span class="string">sysctl_tcp_syncookies</span> <span class="type">!=</span> <span class="number">2</span><span class="string">)</span> &#123;</span><br><span class="line">                <span class="string">lopt-&gt;synflood_warned</span> <span class="string">=</span> <span class="number">1</span><span class="string">;</span></span><br><span class="line">                <span class="string">pr_info(&quot;%s:</span> <span class="string">Possible</span> <span class="string">SYN</span> <span class="string">flooding</span> <span class="string">on</span> <span class="string">port</span> <span class="string">%d.</span> <span class="string">%s.</span>  <span class="string">Check</span> <span class="string">SNMP</span> <span class="string">counters.\n&quot;</span>,</span><br><span class="line">                        <span class="string">proto</span>, <span class="string">ntohs(tcp_hdr(skb)-&gt;dest)</span>, <span class="string">msg);</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="string">return</span> <span class="string">want_cookie;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EXPORT_SYMBOL(tcp_syn_flood_action);</span></span><br><span class="line"><span class="string">https://access.redhat.com/solutions/30453</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># RHEL 7 default: 32768 61000</span></span><br><span class="line"><span class="comment"># outgoing port range</span></span><br><span class="line"><span class="string">net.ipv4.ip_local_port_range</span> <span class="string">=</span> <span class="number">2000 </span><span class="number">65535</span></span><br><span class="line"></span><br><span class="line"><span class="string">net.ipv4.netfilter.ip_conntrack_max</span></span><br><span class="line"><span class="string">net.ipv4.tcp_fin_timeout</span></span><br><span class="line"><span class="string">net.ipv4.icmp_ignore_bogus_error_responses</span></span><br><span class="line"><span class="string">net.ipv4.tcp_bic</span></span><br><span class="line"></span><br><span class="line"><span class="string">ip_early_demux</span></span><br><span class="line"><span class="comment">#Optimize input packet processing down to one demux for certain kinds of local sockets. Currently we only do this for established TCP and connected UDP sockets.</span></span><br><span class="line"><span class="string">It</span> <span class="string">may</span> <span class="string">add</span> <span class="string">an</span> <span class="string">additional</span> <span class="string">cost</span> <span class="string">for</span> <span class="string">pure</span> <span class="string">routing</span> <span class="string">workloads</span> <span class="string">that</span> <span class="string">reduces</span> <span class="string">overall</span> <span class="string">throughput,</span> <span class="attr">in such case you should disable it. Default:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="string">net.ipv4.tcp_syn_retries</span></span><br><span class="line"><span class="comment">#Number of times initial SYNs for an active TCP connection attempt will be retransmitted. Should not be higher than 127. Default value</span></span><br><span class="line"><span class="string">is</span> <span class="number">6</span><span class="string">,</span> <span class="string">which</span> <span class="string">corresponds</span> <span class="string">to</span> <span class="number">63</span> <span class="string">seconds</span> <span class="string">till</span> <span class="string">the</span> <span class="string">last</span> <span class="string">retransmission</span> <span class="string">with</span> <span class="string">the</span> <span class="string">current</span> <span class="string">initial</span> <span class="string">RTO</span> <span class="string">of</span> <span class="string">1second.</span> <span class="string">With</span> <span class="string">this</span> <span class="string">the</span> <span class="string">final</span> <span class="string">timeout</span> <span class="string">for</span> <span class="string">an</span> <span class="string">active</span> <span class="string">TCP</span> <span class="string">connection</span> <span class="string">attempt</span> <span class="string">will</span> <span class="string">happen</span> <span class="string">after</span> <span class="number">127</span> <span class="string">seconds.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">eg:</span> </span><br><span class="line"><span class="string">$</span> <span class="string">time</span> <span class="string">telnet</span> <span class="string">$ip</span> <span class="string">$port</span></span><br><span class="line"></span><br><span class="line"><span class="string">Trying</span> <span class="string">$ip...</span></span><br><span class="line"><span class="attr">telnet:</span> <span class="string">connect</span> <span class="string">to</span> <span class="string">address</span> <span class="string">$ip:</span> <span class="string">Connection</span> <span class="string">timed</span> <span class="string">out</span></span><br><span class="line"><span class="string">telnet</span> <span class="string">$ip</span> <span class="string">$port</span>  <span class="number">0.</span><span class="string">00s</span> <span class="string">user</span> <span class="number">0.</span><span class="string">00s</span> <span class="string">system</span> <span class="number">0</span><span class="string">%</span> <span class="string">cpu</span> <span class="number">2</span><span class="string">:07.29</span> <span class="string">total</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">18</span><span class="string">:04:23.765507</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13801993</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:24.768182</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13802996</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:26.772188</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13805000</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:30.780189</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13809008</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:38.796205</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13817024</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:54.828196</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13833056</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"><span class="number">18</span><span class="string">:05:26.860210</span> <span class="string">IP</span> <span class="string">$ip1.$port1</span> <span class="string">&gt;</span> <span class="string">$ip2.$port2:</span> <span class="string">Flags</span> [<span class="string">S</span>]<span class="string">,</span> <span class="string">seq</span> <span class="number">922947731</span><span class="string">,</span> <span class="string">win</span> <span class="number">29200</span><span class="string">,</span> <span class="string">options</span> [<span class="string">mss</span> <span class="number">1460</span>,<span class="string">sackOK</span>,<span class="string">TS</span> <span class="string">val</span> <span class="number">13865088</span> <span class="string">ecr</span> <span class="number">0</span>,<span class="string">nop</span>,<span class="string">wscale</span> <span class="number">7</span>]<span class="string">,</span> <span class="string">length</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="number">18</span><span class="string">:04:23.765507</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:24.768182</span> <span class="string">1s</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:26.772188</span> <span class="string">2s</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:30.780189</span> <span class="string">4s</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:38.796205</span> <span class="string">8s</span></span><br><span class="line"><span class="number">18</span><span class="string">:04:54.828196</span> <span class="string">16s</span></span><br><span class="line"><span class="number">18</span><span class="string">:05:26.860210</span> <span class="string">32s</span></span><br><span class="line"><span class="number">06</span><span class="string">:30.98</span>        <span class="string">64s</span></span><br><span class="line"></span><br><span class="line"><span class="string">defaults</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_syn_retries = 6</span></span><br></pre></td></tr></table></figure>

<h5 id="mtu-setting"><a href="#mtu-setting" class="headerlink" title="mtu setting"></a>mtu setting</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## set NIC</span></span><br><span class="line">$ ifconfig em1 mtu 9000</span><br><span class="line"></span><br><span class="line"><span class="comment">## set gateway</span></span><br><span class="line">$<span class="built_in"> ip route </span><span class="builtin-name">add</span><span class="built_in"> default </span>via 192.168.1.1 mtu 1400 dev em1</span><br><span class="line"></span><br><span class="line">/etc/sysconfig/network-scripting/ifcfg-eth0</span><br><span class="line"><span class="attribute">MTU</span>=9000</span><br></pre></td></tr></table></figure>

<h5 id="ip-fragments-dropped"><a href="#ip-fragments-dropped" class="headerlink" title="ip fragments dropped"></a>ip fragments dropped</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/sys/net/ipv4/ipfrag_time</span><br><span class="line">30  (seconds)</span><br><span class="line"></span><br><span class="line">ipfrag_high_thresh - INTEGER</span><br><span class="line">        Maximum memory used to reassemble IP fragments. When</span><br><span class="line">        ipfrag_high_thresh bytes of memory is allocated <span class="keyword">for</span> this purpose,</span><br><span class="line">        the fragment handler will toss packets until ipfrag_low_thresh</span><br><span class="line">        is reached.</span><br><span class="line"></span><br><span class="line">ipfrag_low_thresh - INTEGER</span><br><span class="line">        See ipfrag_high_thresh</span><br><span class="line"></span><br><span class="line">To see the current settings:</span><br><span class="line">cat /proc/sys/net/ipv4/ipfrag_low_thresh /proc/sys/net/ipv4/ipfrag_high_thresh</span><br><span class="line">3145728 (bytes default)</span><br><span class="line">4194304</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/1498603">the IP fragmentation thresholds</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">packet reassembles failed</span><br><span class="line"></span><br><span class="line">probe kernel.function(<span class="string">&quot;frag_mem_limit&quot;</span>).inline</span><br><span class="line">&#123;</span><br><span class="line">  mem_count = @cast(@cast(<span class="variable">$nf</span>,<span class="string">&quot;netns_frags&quot;</span>,<span class="string">&quot;kernel&lt;net/inet_frag.h&gt;&quot;</span>)-&gt;lru_list-&gt;next,<span class="string">&quot;netns_frags_priv&quot;</span>,<span class="string">&quot;kernel&lt;net/inet_frag.h&gt;&quot;</span>)-&gt;mem-&gt;count</span><br><span class="line">  nqueues = @cast(@cast(<span class="variable">$nf</span>,<span class="string">&quot;netns_frags&quot;</span>,<span class="string">&quot;kernel&lt;net/inet_frag.h&gt;&quot;</span>)-&gt;lru_list-&gt;next,<span class="string">&quot;netns_frags_priv&quot;</span>,<span class="string">&quot;kernel&lt;net/inet_frag.h&gt;&quot;</span>)-&gt;nqueues</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;fragmentation memory use = %d bytes and nqueues = %d\n&quot;</span>,mem_count, nqueues)</span><br><span class="line">  <span class="built_in">exit</span>()</span><br><span class="line">&#125;</span><br><span class="line">For example here we can see that it has exceeded the threshold. IP fragmentation will now fail.</span><br></pre></td></tr></table></figure>

<h5 id="Enable-bbr"><a href="#Enable-bbr" class="headerlink" title="Enable bbr"></a>Enable bbr</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">net.core.default_qdisc=fq</span><br><span class="line">net.ipv4.tcp_congestion_control=bbr <span class="comment">#cubic/reno/htcp/westwood</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#tcp_low_latency will be out of date too..</span></span><br></pre></td></tr></table></figure>

<h4 id="tcp-timestamps"><a href="#tcp-timestamps" class="headerlink" title="tcp_timestamps"></a>tcp_timestamps</h4><p>default enabled<br>add additional 10 bytes to each packet but more accurate timestamp make TCP congestion control algorithms work better and are recommonded for fast networks, The following changes are recommended for improving IPv4 traffic performance, Disable the TCP timestamps option for better CPU utilization    </p>
<h5 id="tcp-window-scaling"><a href="#tcp-window-scaling" class="headerlink" title="tcp_window_scaling"></a>tcp_window_scaling</h5><p>default enabled   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_window_scaling = 1</span><br></pre></td></tr></table></figure>
<p>tcp_window_scaling - support for large TCP Windows (RFC 1323).The options info in SYN or SYN/ACK packages Needs to be set to 1 if the Max TCP Window is over 65535</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_adv_win_scale=1</span><br></pre></td></tr></table></figure>
<p>The following variable is used to tell the kernel how much of the socket buffer space should be used for TCP window size, and how much to save for an application buffer A value of 1 means the socket buffer will be divided evenly between TCP windows size and application</p>
<h5 id="keepalive"><a href="#keepalive" class="headerlink" title="keepalive"></a>keepalive</h5><p>This determines the wait time between isAlive interval probes</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Increase/decrease depends your application, the time default value for connections to keep alive, default values</span></span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 75</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 9</span><br><span class="line">net.ipv4.tcp_keepalive_time = 7200</span><br></pre></td></tr></table></figure>

<h5 id="tcp-sack"><a href="#tcp-sack" class="headerlink" title="tcp_sack"></a>tcp_sack</h5><p>default enabled<br>Enable the TCP selective acks option for better throughput:<br>With selective acknowledgments, the data receiver can inform the sender about all segments that have arrived successfully, so the sender need retransmit only the segments that have actually been lost.    </p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">sysctl</span> -w net.ipv<span class="number">4</span>.tcp_sack=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h5 id="dirty-page"><a href="#dirty-page" class="headerlink" title="dirty page"></a>dirty page</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">vm.dirty_background_ratio = 5</span><br><span class="line">vm.dirty_ratio = 10</span><br><span class="line">vm.dirty_expire_centisecs = 250</span><br><span class="line"></span><br><span class="line"><span class="comment">## default</span></span><br><span class="line">vm.dirty_background_ratio = 10</span><br><span class="line">vm.dirty_ratio = 20</span><br><span class="line">vm.dirty_expire_centisecs = 3000</span><br></pre></td></tr></table></figure>

<h5 id="tcp-frto"><a href="#tcp-frto" class="headerlink" title="tcp_frto"></a>tcp_frto</h5><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">integer; default: 0; since Linux 2.4.21/2.6   </span><br><span class="line"><span class="builtin-name">Enable</span>  F-RTO,  an enhanced recovery algorithm <span class="keyword">for</span> TCP retrans‐mission timeouts (RTOs).   It  is  particularly  beneficial  <span class="keyword">in</span><span class="built_in"> wireless </span> environments  where  packet  loss is typically due <span class="keyword">to</span> random radio interference rather than intermediate router  con‐gestion.  See RFC 4138 <span class="keyword">for</span> more details. </span><br><span class="line">              This file can have one of the following values:</span><br><span class="line">              0  Disabled.</span><br><span class="line">              1  The basic version F-RTO algorithm is enabled.</span><br><span class="line">              2  <span class="builtin-name">Enable</span>  SACK-enhanced  F-RTO  <span class="keyword">if</span>  flow uses SACK.  The basic version can be used also when SACK is <span class="keyword">in</span> use though <span class="keyword">in</span>  that case scenario(s) exists where F-RTO interacts badly with the packet counting of the SACK-enabled TCP flow.</span><br><span class="line">net.ipv4.<span class="attribute">tcp_frto</span>=1</span><br><span class="line"><span class="keyword">or</span></span><br><span class="line">net.ipv4.<span class="attribute">tcp_frto</span>=2 #default value</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enabled default</span></span><br><span class="line"><span class="comment">#net.ipv4.tcp_sack=1</span></span><br></pre></td></tr></table></figure>

<h5 id="tcp-tw-reuse"><a href="#tcp-tw-reuse" class="headerlink" title="tcp_tw_reuse"></a>tcp_tw_reuse</h5><p>This allows reusing sockets in TIME_WAIT state for new connections when it is safe from protocol viewpoint<br>Allow to reuse TIME_WAIT sockets for new connections when it is safe from protocol viewpoint. It should not be changed without advice/request of technical experts    </p>
<p>Note: The tcp_tw_reuse setting is particularly useful in environments where numerous short connections are open and left in TIME_WAIT state, such as web servers. Reusing the sockets can be very effective in reducing server load    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse=1</span><br><span class="line">net.ipv4.tcp_max_tw_buckets = 1440000</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-c00916755">There are warnings saying that net.ipv4.tcp_tw_reuse and</a><br>net.ipv4.tcp_tw_recycle tunables should not be changed without consulting experts first.  What does this mean and what can go wrong if they are enabled.<br>Answer:  Potential problems are not specific to Linux.  Enabling these tunables will not make the host crash or unstable, but it may break TCP/IP functionality if the host is connected to devices such as load-balancers or firewalls.  Some of these devices can reject SYN if it reuses the same connection (i.e. src/dst IP and src/dst ports are the same) too quickly.  RFC 1122 describes when it is acceptable to recycle the connection when SYN arrives for a connection in TIME_WAIT state.</p>
<h5 id="netfilter"><a href="#netfilter" class="headerlink" title="netfilter"></a>netfilter</h5><p>To reduce the number of connections in TIME_WAIT state, we can decrease the number of seconds connections are kept in this state before being dropped:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># reduce TIME_WAIT from the 120s default to 30-60s</span></span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_time_wait=30</span><br><span class="line"><span class="comment"># reduce FIN_WAIT from teh 120s default to 30-60s</span></span><br><span class="line">net.netfilter.nf_conntrack_tcp_timeout_fin_wait=30</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_fin_timeout = 15</span><br><span class="line"><span class="comment">#Decrease the time default value for tcp_fin_timeout connection, FIN-WAIT-2</span></span><br><span class="line"><span class="comment">#tcp_available_congestion_control - shows the available congestion control choices that are registered.</span></span><br><span class="line">````</span><br><span class="line"></span><br><span class="line"><span class="comment">##### Enabling flow limits and tuning flow limit hash table size</span></span><br><span class="line">```bash</span><br><span class="line">$ sysctl -w net.core.flow_limit_table_len=8192</span><br><span class="line">The value is only consulted when a new table is allocated. Modifying it does not update active tables.</span><br><span class="line"></span><br><span class="line">$ cat /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line">00000</span><br><span class="line"></span><br><span class="line"><span class="comment"># set a bitmask</span></span><br><span class="line"><span class="built_in">echo</span> f &gt; /proc/sys/net/core/flow_limit_cpu_bitmap</span><br><span class="line"></span><br><span class="line">Per-flow rate is calculated by hashing each packet into a hashtable bucket and incrementing a per-bucket counter. The <span class="built_in">hash</span> <span class="keyword">function</span> is the same that selects a CPU <span class="keyword">in</span> RPS, but as the number of buckets can be much larger than the number of CPUs, flow <span class="built_in">limit</span> has finer-grained identification of large flows and fewer <span class="literal">false</span> positives. The default table has 4096 buckets. This value can be modified through sysctl</span><br><span class="line"></span><br><span class="line">Flow <span class="built_in">limit</span> is useful on systems with many concurrent connections, <span class="built_in">where</span> a single connection taking up 50% of a CPU indicates a problem. In such environments, <span class="built_in">enable</span> the feature on all CPUs that handle network rx interrupts (as <span class="built_in">set</span> <span class="keyword">in</span> /proc/irq/N/smp_affinity).</span><br><span class="line"></span><br><span class="line">The feature depends on the input packet queue length to exceed the flow <span class="built_in">limit</span> threshold (50%) + the flow <span class="built_in">history</span> length (256). Setting net.core.netdev_max_backlog to either 1000 or 10000 performed well <span class="keyword">in</span> experiments.</span><br></pre></td></tr></table></figure>

<h5 id="ARP-setting"><a href="#ARP-setting" class="headerlink" title="ARP setting"></a>ARP setting</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">static /etc/ethers file with all hostnames and MAC addresses and load this by $ arp -f /etc/ethers</span><br><span class="line"></span><br><span class="line"><span class="comment">#default values</span></span><br><span class="line">net.ipv4.neigh.default.gc_interval = 30</span><br><span class="line">net.ipv4.neigh.default.gc_stale_time = 60</span><br><span class="line"></span><br><span class="line">net.ipv4.neigh.default.gc_thresh1 = 128</span><br><span class="line">net.ipv4.neigh.default.gc_thresh2 = 512</span><br><span class="line">net.ipv4.neigh.default.gc_thresh3 = 1024</span><br><span class="line"></span><br><span class="line"><span class="comment">#gc_thresh3 is the absolute limit for the table size, but gc_thresh2 is also important, jas when the table size exceeds gc_thresh2 the kernel will aggressively prune entries (deleting entries older than 5 seconds) which could lead to large volumes of ARP or ndisc traffic in pathological situations</span></span><br><span class="line"></span><br><span class="line">gc_thresh1 (since Linux 2.2)</span><br><span class="line">The minimum number of entries to keep <span class="keyword">in</span>  the  ARP  cache. The garbage collector will not run <span class="keyword">if</span> there are fewer than this number of entries <span class="keyword">in</span> the cache.  Defaults to 128.</span><br><span class="line"></span><br><span class="line">gc_thresh2 (since Linux 2.2)</span><br><span class="line">The soft maximum number of entries to keep  <span class="keyword">in</span>  the  ARP  cache.The garbage collector will allow the number of entries to exceed this  <span class="keyword">for</span>  5  seconds  before  collection  will  be   performed. Defaults to 512.</span><br><span class="line"></span><br><span class="line">gc_thresh3 (since Linux 2.2)</span><br><span class="line">The  hard  maximum  number  of entries to keep <span class="keyword">in</span> the ARP cache.The garbage collector will always run <span class="keyword">if</span>  there  are  more  than this number of entries <span class="keyword">in</span> the cache.  Defaults to 1024.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Determines how often to check for stale neighbor entries, default 60 secs</span></span><br><span class="line">cat /proc/sys/net/ipv4/neigh/e*/gc_stale_time</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line">60</span><br><span class="line"></span><br><span class="line"><span class="comment">## works best with &lt;= 500 client computers ##</span></span><br><span class="line"><span class="comment"># Force gc to clean-up quickly</span></span><br><span class="line">net.ipv4.neigh.default.gc_interval = 1800</span><br><span class="line"><span class="comment"># Set ARP cache entry timeout</span></span><br><span class="line">net.ipv4.neigh.default.gc_stale_time = 1800</span><br><span class="line"></span><br><span class="line"><span class="comment"># reduce each arp request, 600s</span></span><br><span class="line">net.ipv4.neigh.default.base_reachable_time_ms=6000000</span><br><span class="line">net.ipv4.neigh.bond0.base_reachable_time_ms=6000000</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://people.cs.clemson.edu/~westall/853/notes/arpstate.pdf">The ARP status</a>    </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_INCOMPLETE 0x01</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_REACHABLE 0x02</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_STALE 0x04</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_DELAY 0x08</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_PROBE 0x10</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_FAILED 0x20</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* Dummy states */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_NOARP 0x40</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_PERMANENT 0x80</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_NONE 0x00</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_IN_TIMER (NUD_INCOMPLETE|NUD_DELAY|NUD_PROBE)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_VALID (NUD_PERMANENT|NUD_NOARP|NUD_REACHABLE|</span></span><br><span class="line">PROBE|NUD_STALE|NUD_DELAY)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUD_CONNECTED (NUD_PERMANENT|NUD_NOARP|NUD_REACHABLE)</span></span><br><span class="line"></span><br><span class="line">NUD_NONE: When a <span class="keyword">new</span> route cache element is created, the arp_bind_neighbour() function is called.  If a suitable ARP cache element cannot be found, neigh_alloc() creates a <span class="keyword">new</span> one <span class="keyword">and</span> sets its state to NUD_NONE.</span><br><span class="line">NUD_INCOMPLETE: When the first packet is sent that <span class="keyword">requires</span> the <span class="keyword">new</span> ARP cache element,  neigh_resolve_output() will be called.  This eventually leads to a call to neigh_event_send,  which sends the ARP request <span class="keyword">and</span> makes the transition to NUD_INCOMPLETE.</span><br><span class="line">NUD_REACHABLE: When an ARP response is received, the struct neighbour enters the NUD_REACHABLE state.</span><br><span class="line">NUD_STALE: When neigh_periodic_timer(), finds that the last time the entry was confirmed exceded the reachable time parameter.</span><br><span class="line">NUD_DELAY: When neigh_resolve_output() is eventually called with a struct neighbour in the NUD_STALE state.</span><br><span class="line">NUD_PROBE: When the neigh_timer_handler() function associated with the struct neighbour is called in the NUD_DELAY state,  a transition is made to NUD_PROBE <span class="keyword">and</span> an ARP request is issued.</span><br></pre></td></tr></table></figure>

<h5 id="proc-pagetypeinfo"><a href="#proc-pagetypeinfo" class="headerlink" title="/proc/pagetypeinfo"></a>/proc/pagetypeinfo</h5><ul>
<li>Unmovable   = Pages fixed/locked in memory (mlock()’d) and cannot be moved anywhere else.</li>
<li>Reclaimable = Some of these should be allocatable although a lot of Filesystem metadata may have to be reclaimed to achieve this.</li>
<li>Movable     = All these blocks should be allocatable. We treat these pages as movable so they can be freed if necessary.</li>
<li>Reserve     = They are emergency memory reserve. Used if a memory reserve cannot be fulfilled from the mobility-specific lists (e.g. Movable, Reclaimable).</li>
<li>Isolate     = Pages isolated onto this private free list. This is required in order to move physical pages across NUMA nodes. These pages can be freed back to the allocator because they are now offlined.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/buddyinfo /proc/pagetypeinfo</span><br><span class="line">          Order =            0      1     2      3      4      5      6      7      8      9     10</span><br><span class="line">Node      Zone               1      2     4      8     16     32     64    128    256    512   1024 &lt;=4k pages</span><br><span class="line">Node      Zone               4kB    8kB  16kB   32kB   64kB  128kB  256kB  512kB 1024kB 2048kB 4096kB &lt;=Byte size</span><br><span class="line">-------------------------------------------means--------------------------------------------------</span><br><span class="line">Node 0, zone      DMA      1      0      1      1      1      1      1      0      1      1      3</span><br><span class="line">Node 0, zone    DMA32   5393  10435   2087    968    621    731    725    504    209     29      0</span><br><span class="line">Node 0, zone   Normal  13788     61      5      1      1      0      0      0      0      0      0</span><br><span class="line">Node 1, zone   Normal 233089   1630    523    323     15      3      0      0      0      0      0</span><br><span class="line">Page block order: 9</span><br><span class="line">Pages per block:  512</span><br><span class="line"></span><br><span class="line">Free pages count per migrate <span class="built_in">type</span> at order       0      1      2      3      4      5      6      7      8      9     10</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>    Unmovable      1      0      1      1      1      1      1      0      1      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>  Reclaimable      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Movable      0      0      0      0      0      0      0      0      0      1      3</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone      DMA, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>    Unmovable     45      0      0    212    224    707    724    503    207     29      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>  Reclaimable      1     35     14      2      1      0      1      1      1      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Movable   5347  10400   2073    754    396     24      0      0      1      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone    DMA32, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>    Unmovable  13189      1      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>  Reclaimable     32      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Movable    567     60      5      1      1      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Reserve      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>          CMA      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line">Node    0, zone   Normal, <span class="built_in">type</span>      Isolate      0      0      0      0      0      0      0      0      0      0      0</span><br><span class="line"></span><br><span class="line">Number of blocks <span class="built_in">type</span>     Unmovable  Reclaimable      Movable      Reserve          CMA      Isolate</span><br><span class="line">Node 0, zone      DMA            1            0            7            0            0            0</span><br><span class="line">Node 0, zone    DMA32          553          175          672            0            0            0</span><br><span class="line">Node 0, zone   Normal         8910          466       120160            0            0            0</span><br><span class="line">Page block order: 9</span><br><span class="line">Pages per block:  512</span><br><span class="line"></span><br><span class="line">$ cat /sys/kernel/debug/extfrag/extfrag_index</span><br><span class="line">Node 0, zone      DMA -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000</span><br><span class="line">Node 0, zone    DMA32 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.989</span><br><span class="line">Node 0, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.993 0.997 0.999 0.999</span><br><span class="line">Node 1, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.984 0.992 0.996 0.998 0.999</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="available-congestion-control"><a href="#available-congestion-control" class="headerlink" title="available_congestion_control"></a>available_congestion_control</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl  net.ipv4.tcp_available_congestion_control</span><br><span class="line">net.ipv4.tcp_available_congestion_control = reno cubic bbr</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="if-ping-reply-the-wrong-ip-addr"><a href="#if-ping-reply-the-wrong-ip-addr" class="headerlink" title="if ping reply the wrong ip addr"></a>if ping reply the wrong ip addr</h5><p>—- important —-</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">net.ipv4.conf.default.arp_announce = 2</span><br><span class="line"></span><br><span class="line">arp_announce</span><br><span class="line">        Define different restriction levels <span class="keyword">for</span> announcing the <span class="built_in">local</span></span><br><span class="line">        <span class="built_in">source</span> IP address from IP packets <span class="keyword">in</span> ARP requests sent on</span><br><span class="line">        interface:</span><br><span class="line">        0 - (default) Use any <span class="built_in">local</span> address, configured on any interface</span><br><span class="line">        1 - Try to avoid <span class="built_in">local</span> addresses that are not <span class="keyword">in</span> the target<span class="string">&#x27;s</span></span><br><span class="line"><span class="string">        subnet for this interface. This mode is useful when target</span></span><br><span class="line"><span class="string">        hosts reachable via this interface require the source IP</span></span><br><span class="line"><span class="string">        address in ARP requests to be part of their logical network</span></span><br><span class="line"><span class="string">        configured on the receiving interface. When we generate the</span></span><br><span class="line"><span class="string">        request we will check all our subnets that include the</span></span><br><span class="line"><span class="string">        target IP and will preserve the source address if it is from</span></span><br><span class="line"><span class="string">        such subnet. If there is no such subnet we select source</span></span><br><span class="line"><span class="string">        address according to the rules for level 2.</span></span><br><span class="line"><span class="string">        2 - Always use the best local address for this target.</span></span><br><span class="line"><span class="string">        In this mode we ignore the source address in the IP packet</span></span><br><span class="line"><span class="string">        and try to select local address that we prefer for talks with</span></span><br><span class="line"><span class="string">        the target host. Such local address is selected by looking</span></span><br><span class="line"><span class="string">        for primary IP addresses on all our subnets on the outgoing</span></span><br><span class="line"><span class="string">        interface that include the target IP address. If no suitable</span></span><br><span class="line"><span class="string">        local address is found we select the first local address</span></span><br><span class="line"><span class="string">        we have on the outgoing interface or on all other interfaces,</span></span><br><span class="line"><span class="string">        with the hope we will receive reply for our request and</span></span><br><span class="line"><span class="string">        even sometimes no matter the source IP address we announce.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        The max value from conf/&#123;all,interface&#125;/arp_announce is used.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">arp_ignore</span></span><br><span class="line"><span class="string">        Define different modes for sending replies in response to</span></span><br><span class="line"><span class="string">        received ARP requests that resolve local target IP addresses:</span></span><br><span class="line"><span class="string">        0 - (default): reply for any local target IP address, configured</span></span><br><span class="line"><span class="string">        on any interface</span></span><br><span class="line"><span class="string">        1 - reply only if the target IP address is local address</span></span><br><span class="line"><span class="string">        configured on the incoming interface</span></span><br><span class="line"><span class="string">        2 - reply only if the target IP address is local address</span></span><br><span class="line"><span class="string">        configured on the incoming interface and both with the</span></span><br><span class="line"><span class="string">        sender&#x27;</span>s IP address are part from same subnet on this interface</span><br><span class="line">        3 - <span class="keyword">do</span> not reply <span class="keyword">for</span> <span class="built_in">local</span> addresses configured with scope host,</span><br><span class="line">        only resolutions <span class="keyword">for</span> global and link addresses are replied</span><br><span class="line">        4-7 - reserved</span><br><span class="line">        8 - <span class="keyword">do</span> not reply <span class="keyword">for</span> all <span class="built_in">local</span> addresses</span><br><span class="line"></span><br><span class="line">        The max value from conf/&#123;all,interface&#125;/arp_ignore is used</span><br><span class="line">        when ARP request is received on the &#123;interface&#125;</span><br><span class="line"></span><br><span class="line">Configure all interfaces to allow you to have multiple network interfaces on the same subnet, and have the ARPs <span class="keyword">for</span> each interface be answered based on whether or not the kernel would route a packet from the ARP<span class="string">&#x27;d IP out that interface (this change also requires source-based routing to be deployed and functional):</span></span><br><span class="line"><span class="string">Raw</span></span><br><span class="line"><span class="string">net.ipv4.conf.all.arp_filter = 1</span></span><br><span class="line"><span class="string">net.ipv4.conf.default.arp_filter = 1</span></span><br><span class="line"><span class="string">        Define different restriction levels for announcing the local</span></span><br><span class="line"><span class="string">        source IP address from IP packets in ARP requests sent on</span></span><br><span class="line"><span class="string">        interface:</span></span><br><span class="line"><span class="string">        0 - (default) Use any local address, configured on any interface</span></span><br><span class="line"><span class="string">        1 - Try to avoid local addresses that are not in the target&#x27;</span>s</span><br><span class="line">        subnet <span class="keyword">for</span> this interface. This mode is useful when target</span><br><span class="line">        hosts reachable via this interface require the <span class="built_in">source</span> IP</span><br><span class="line">        address <span class="keyword">in</span> ARP requests to be part of their logical network</span><br><span class="line">        configured on the receiving interface. When we generate the</span><br><span class="line">        request we will check all our subnets that include the</span><br><span class="line">        target IP and will preserve the <span class="built_in">source</span> address <span class="keyword">if</span> it is from</span><br><span class="line">        such subnet. If there is no such subnet we select <span class="built_in">source</span></span><br><span class="line">        address according to the rules <span class="keyword">for</span> level 2.</span><br><span class="line">        2 - Always use the best <span class="built_in">local</span> address <span class="keyword">for</span> this target.</span><br><span class="line">        In this mode we ignore the <span class="built_in">source</span> address <span class="keyword">in</span> the IP packet</span><br><span class="line">        and try to select <span class="built_in">local</span> address that we prefer <span class="keyword">for</span> talks with</span><br><span class="line">        the target host. Such <span class="built_in">local</span> address is selected by looking</span><br><span class="line">        <span class="keyword">for</span> primary IP addresses on all our subnets on the outgoing</span><br><span class="line">        interface that include the target IP address. If no suitable</span><br><span class="line">        <span class="built_in">local</span> address is found we select the first <span class="built_in">local</span> address</span><br><span class="line">        we have on the outgoing interface or on all other interfaces,</span><br><span class="line">        with the hope we will receive reply <span class="keyword">for</span> our request and</span><br><span class="line">        even sometimes no matter the <span class="built_in">source</span> IP address we announce.</span><br><span class="line"></span><br><span class="line">        The max value from conf/&#123;all,interface&#125;/arp_announce is used.</span><br></pre></td></tr></table></figure>

<ul>
<li>QDISCS     <ul>
<li>qdisc is short for ‘queueing discipline’ and it is elementary to understanding traffic control. Whenever the kernel needs to send a packet to an interface, it is enqueued to the qdisc configured for that interface. Immediately afterwards, the kernel tries to get as many packets as possible from the qdisc, for giving  them to the network adaptor driver.    </li>
<li>A simple QDISC is the ‘pfifo’ one, which does no processing at all and is a pure First In, First Out queue. It does however store traffic when the network inter‐face can’t handle it momentarily.     </li>
</ul>
</li>
</ul>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">$ tc -s qdisc ls dev enp2s0f0</span><br><span class="line">qdisc mq <span class="number">0</span>: root </span><br><span class="line"> Sent <span class="number">24539873</span> bytes <span class="number">162857</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">17</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">17</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">8</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">1919555</span> bytes <span class="number">15660</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">3</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">3</span></span><br><span class="line">  maxpacket <span class="number">790</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">2</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">7</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">2191430</span> bytes <span class="number">18333</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">0</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">0</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">6</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">2298405</span> bytes <span class="number">18229</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">1</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">1</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">5</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">3851428</span> bytes <span class="number">27271</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">4</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">4</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">4</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">2456334</span> bytes <span class="number">20238</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">2</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">2</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">3</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">2239987</span> bytes <span class="number">18011</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">2</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">2</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">2</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">8308378</span> bytes <span class="number">38560</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">1</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">1</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br><span class="line">qdisc fq_codel <span class="number">0</span>: parent :<span class="number">1</span> limit <span class="number">10240</span>p flows <span class="number">1024</span> quantum <span class="number">1514</span> target <span class="number">5</span>ms <span class="built_in">int</span>erval <span class="number">100</span>ms memory_limit <span class="number">32</span>Mb ecn drop_batch <span class="number">64</span> </span><br><span class="line"> Sent <span class="number">1274356</span> bytes <span class="number">6555</span> pkt (dropped <span class="number">0</span>, overlimits <span class="number">0</span> requeues <span class="number">4</span>) </span><br><span class="line"> backlog <span class="number">0</span>b <span class="number">0</span>p requeues <span class="number">4</span></span><br><span class="line">  maxpacket <span class="number">0</span> drop_overlimit <span class="number">0</span> new_flow_count <span class="number">0</span> ecn_mark <span class="number">0</span></span><br><span class="line">  new_flows_len <span class="number">0</span> old_flows_len <span class="number">0</span></span><br></pre></td></tr></table></figure>

<h5 id="bonding"><a href="#bonding" class="headerlink" title="bonding"></a><a target="_blank" rel="noopener" href="https://wiki.linuxfoundation.org/networking/bonding">bonding</a></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">BONDING_OPTS=<span class="string">&quot;mode=4 millmon=100 arp_validate=0 updelay=30000 lacp_rate=fast xmit_hash_policy=4&quot;</span></span><br><span class="line"></span><br><span class="line">static const struct bond_opt_value bond_xmit_hashtype_tbl[] = &#123;</span><br><span class="line">	&#123; <span class="string">&quot;layer2&quot;</span>,      BOND_XMIT_POLICY_LAYER2,      BOND_VALFLAG_DEFAULT&#125;,</span><br><span class="line">	&#123; <span class="string">&quot;layer3+4&quot;</span>,    BOND_XMIT_POLICY_LAYER34,     0&#125;,</span><br><span class="line">	&#123; <span class="string">&quot;layer2+3&quot;</span>,    BOND_XMIT_POLICY_LAYER23,     0&#125;,</span><br><span class="line">	&#123; <span class="string">&quot;encap2+3&quot;</span>,    BOND_XMIT_POLICY_ENCAP23,     0&#125;,</span><br><span class="line">	&#123; <span class="string">&quot;encap3+4&quot;</span>,    BOND_XMIT_POLICY_ENCAP34,     0&#125;,</span><br><span class="line">	&#123; <span class="string">&quot;vlan+srcmac&quot;</span>, BOND_XMIT_POLICY_VLAN_SRCMAC, 0&#125;,</span><br><span class="line">	&#123; NULL,          -1,                           0&#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>For more hash policy, the source code in drivers/net/bonding/bond_main.c   </p>
<p><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/bonding.txt">kernel bonding doc</a><br><a target="_blank" rel="noopener" href="https://patchwork.ozlabs.org/project/netdev/patch/20110114190714.GA11655@yandex-team.ru/">bonding patch</a></p>
<ul>
<li><p>802.3ad </p>
<ul>
<li>This mode can be a good choice for this type of network topology. The 802.3ad mode is an IEEE standard, so all peers that implement 802.3ad should interoperate well</li>
<li>The 802.3ad protocol includes automatic configuration of the aggregates, so minimal manual configuration of the switch is needed (typically only to designate that some set of devices is available for 802.3ad). </li>
<li>The 802.3ad standard also mandates that frames be delivered in order (within certain limits), so in general single connections will not see misordering of packets. </li>
<li>The 802.3ad mode does have some drawbacks: the standard mandates that all devices in the aggregate operate at the same speed and duplex. Also, as with all bonding load balance modes other than balance-rr, no single connection will be able to utilize more than a single interface’s worth of bandwidth.</li>
</ul>
</li>
<li><p>The 802.3ad mode requires that the switch have the appropriate ports configured as an 802.3ad aggregation. The precise method used to configure this varies from switch to switch, </p>
<ul>
<li>a Cisco 3550 series switch requires that the appropriate ports first be grouped together in a single etherchannel instance<ul>
<li>then that etherchannel is set to mode “lacp” to enable 802.3ad (instead of standard EtherChannel)    </li>
</ul>
</li>
</ul>
</li>
<li><p>The balance-rr, balance-xor and broadcast modes generally require that the switch have the appropriate ports grouped together</p>
<ul>
<li>The nomenclature for such a group differs between switches, it may be called an “etherchannel” (as in the Cisco example, above), a “trunk group” or some other similar variation. For these modes, each switch will also have its own configuration options for the switch’s transmit policy to the bond. </li>
<li>Typical choices include XOR of either the MAC or IP addresses. The transmit policy of the two peers does not need to match. For these three modes, the bonding mode really selects a transmit policy for an EtherChannel group; all three will interoperate with another EtherChannel group</li>
</ul>
</li>
<li><p>Link Monitoring</p>
<ul>
<li>ARP monitoring can be done with just one target, it can be useful in a High Availability setup to have several targets to monitor</li>
<li>Having an additional target (or several) increases the reliability of the ARP monitoring.<ul>
<li>arp_interval=60 arp_ip_target=192.168.0.1,192.168.0.3,192.168.0.9</li>
</ul>
</li>
</ul>
</li>
<li><p>MII Monitor</p>
<ul>
<li>The MII monitor monitors only the carrier state of the local network interface. It accomplishes this in one of three ways: by depending upon the device driver to maintain its carrier state, by querying the device’s MII registers, or by making an ethtool query to the device.</li>
<li>If the use_carrier module parameter is 1 (the default value), then the MII monitor will rely on the driver for carrier state information (via the netif_carrier subsystem)</li>
<li>If use_carrier is 0, then the MII monitor will first query the device’s (via ioctl) MII registers and check the link state</li>
</ul>
</li>
<li><p>Switch Behavior Issues</p>
<ul>
<li>Some switches exhibit undesirable behavior with regard to the timing of link up and down reporting by the switch.<ul>
<li>Link Establishment and Failover Delays<ul>
<li>First, when a link comes up, some switches may indicate that the link is up (carrier available), but not pass traffic over the interface for some period of time. </li>
</ul>
</li>
<li>Duplicated Incoming Packets<ul>
<li>It is not uncommon to observe a short burst of duplicated traffic when the bonding device is first used, or after it has been idle for some period of time.<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ping -n 10.0.4.2</span></span><br><span class="line">PING 10.0.4.2 (10.0.4.2) from 10.0.3.10 : 56(84) bytes of data.</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=1 ttl=64 time=13.7 ms</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=1 ttl=64 time=13.8 ms (DUP!)</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=1 ttl=64 time=13.8 ms (DUP!)</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=1 ttl=64 time=13.8 ms (DUP!)</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=1 ttl=64 time=13.8 ms (DUP!)</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=2 ttl=64 time=0.216 ms</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=3 ttl=64 time=0.267 ms</span><br><span class="line">64 bytes from 10.0.4.2: icmp_seq=4 ttl=64 time=0.222 ms</span><br></pre></td></tr></table></figure></li>
<li>The duplicated packet behavior is switch dependent, some switches exhibit this, and some do not. On switches that display this behavior, it can be induced by clearing the MAC forwarding table (on most Cisco switches, the privileged command “clear mac address-table dynamic” will accomplish this).</li>
<li>This is not due to an error in the bonding driver, rather, it is a side effect of how many switches update their MAC forwarding tables</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>mode</p>
<ul>
<li>balance-rr or 0 <ul>
<li>Round-robin policy: Transmit packets in sequential order from the first available slave through the last. This mode provides load balancing and fault tolerance</li>
</ul>
</li>
<li>802.3ad or 4<ul>
<li>IEEE 802.3ad Dynamic link aggregation. Creates aggregation groups that share the same speed and duplex settings. Utilizes all slaves in the active aggregator according to the 802.3ad specification </li>
<li>xmit_hash_policy<ul>
<li>layer2<ul>
<li>Uses XOR of hardware MAC addresses to generate the hash</li>
</ul>
</li>
<li>layer3+4 (1)<ul>
<li>This policy uses upper layer protocol information, when available, to generate the hash. This allows for traffic to a particular network peer to span multiple slaves, although a single connection will not span multiple slaves</li>
<li>This policy is intended to mimic the behavior of certain switches, notably Cisco switches with PFC2 as well as some Foundry and IBM products</li>
<li>This algorithm is not fully 802.3ad compliant. A single TCP or UDP conversation containing both fragmented and unfragmented packets will see packets striped across two interfaces<ul>
<li><code>This may result in out of order delivery</code></li>
</ul>
</li>
<li>Most traffic types will not meet this criteria, as TCP rarely fragments traffic, and most UDP traffic is not involved in extended conversations. Other implementations of 802.3ad may or may not tolerate this noncompliance</li>
</ul>
</li>
<li>layer2+3<ul>
<li>This policy uses a combination of layer2 and layer3 protocol information to generate the hash. Uses XOR of hardware MAC addresses and IP addresses to generate the hash.</li>
</ul>
</li>
<li>encap3+4 (4)<ul>
<li>This policy uses the same formula as layer3+4 but it relies on skb_flow_dissect to obtain the header fields which might result in the use of inner headers if an encapsulation protocol is used. For example this will improve the performance for tunnel users because the packets will be distributed according to the encapsulated flows</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>balance-alb or 6 <ul>
<li>Adaptive load balancing: includes balance-tlb plus receive load balancing (rlb) for IPV4 traffic, and does not require any special switch support<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/include/uapi/linux/if_bonding.h</span><br><span class="line"></span><br><span class="line"><span class="comment">/* hashing types */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOND_XMIT_POLICY_LAYER2         0 <span class="comment">/* layer 2 (MAC only), default */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOND_XMIT_POLICY_LAYER34        1 <span class="comment">/* layer 3+4 (IP ^ (TCP || UDP)) */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOND_XMIT_POLICY_LAYER23        2 <span class="comment">/* layer 2+3 (IP ^ MAC) */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOND_XMIT_POLICY_ENCAP23        3 <span class="comment">/* encapsulated layer 2+3 */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BOND_XMIT_POLICY_ENCAP34        4 <span class="comment">/* encapsulated layer 3+4 */</span></span></span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">bonding value &gt; total ethernet frame, bonding will be re-process all frames ???     </span><br><span class="line"></span><br><span class="line">##### Monitor</span><br><span class="line"></span><br><span class="line"> ss    </span><br><span class="line">```bash</span><br><span class="line">$ ss -eipnt | grep -A 1 $ipaddr --color  | grep -B 1 -Ei &#x27;cwnd|ssthresh&#x27;</span><br><span class="line">    * If cwnd and ssthresh and cwnd &#x27;s value up and down frequently that means there is a bad network env(maybe it &#x27;s trigger the tcp slow start algorithm and TCP Congestion avoidance algorithm)</span><br><span class="line"></span><br><span class="line">#Recv-Q is the count of bytes <span class="keyword">not</span> copied by the user program connected to <span class="keyword">this</span> socket.</span><br><span class="line">#Send-Q is the count of bytes <span class="keyword">not</span> acknowledged by the remote host.</span><br><span class="line">#If there are Send-Q values/counts that are persistent:</span><br><span class="line">   Some of these are data the host has already sent but that have <span class="keyword">not</span> yet arrived at the receiver, merely due to geographic distance.</span><br><span class="line">   Likewise, some are <span class="keyword">for</span> sent data <span class="keyword">for</span> which the receiver has emitted acknowledgements, which are still in transit on the <span class="keyword">return</span> path. Some can be due to sent data which has been dropped by the network, <span class="keyword">or</span> the responses <span class="keyword">for</span> those.</span><br><span class="line">   Finally, when the receiver tells the sender to pause sending, <span class="keyword">or</span> the sending application is faster than the network can support, an unsent-data <span class="built_in">queue</span> can build up</span><br><span class="line"></span><br><span class="line">#Similarly a non-zero value in Recv-Q does <span class="keyword">not</span> really indicate a system problem but an application level issue. If the counts in Recv-Q increases it implies that application running on system is <span class="keyword">not</span> picking up the data that the kernel is signalling to them. This may <span class="keyword">or</span> may <span class="keyword">not</span> be a problem. For example <span class="keyword">if</span> the receiving application is writing to a filesystem which is slower than both the sender <span class="keyword">and</span> the network, a receive <span class="built_in">queue</span> would be expected to build up.</span><br><span class="line"></span><br><span class="line">Listen status:</span><br><span class="line">Recv-Q: the ESTABLISHED tcp connections, appliction <span class="keyword">not</span> begin to received   </span><br><span class="line">        </span><br><span class="line">Recv-Q: maximum = Send-Q+<span class="number">1</span> = min(backlog, somaxconn)+<span class="number">1</span>    </span><br><span class="line">Send-Q: Since Kernel <span class="number">2.6</span><span class="number">.18</span> <span class="keyword">this</span> column contains the maximum size of the syn backlog</span><br><span class="line">maxConnections + ( min(acceptCount, somaxconn) + <span class="number">1</span> ) == <span class="number">7</span> + ( min(<span class="number">5</span>, <span class="number">4096</span>) + <span class="number">1</span> ) == <span class="number">7</span>+ ( <span class="number">5</span>+<span class="number">1</span> ) == <span class="number">13</span></span><br><span class="line"></span><br><span class="line">LISTEN Recv-Q: After the three-way handshake listen, that means the total wait the server to accept the connection number</span><br><span class="line">LISTEN Send-Q: the maximum listen backlog number(min(backlog, somaxconn(<span class="keyword">default</span> <span class="number">128</span>))), <span class="number">129</span> tcp ESTABLISHED connections</span><br><span class="line">The others</span><br><span class="line">Recv-Q: the receive <span class="built_in">queue</span> bytes, has received, <span class="keyword">and</span> <span class="keyword">not</span> send to the local application total bytes</span><br><span class="line">Send-Q: the send <span class="built_in">queue</span> bytes, has sent, <span class="keyword">not</span> receive the ACK total bytes</span><br><span class="line"></span><br><span class="line">client: SYN_SENT -----------syn----------&gt; server: SYN_RCVD ----&gt; cache in sync <span class="built_in">queue</span> (net.ipv4.tcp_max_syn_backlog)</span><br><span class="line">                                                     |               |</span><br><span class="line">client: ESTABLISHED&lt;----------syn+ack----------------                | out from sync <span class="built_in">queue</span> to accept <span class="built_in">queue</span> </span><br><span class="line">            |                                                        V</span><br><span class="line">            ---------------------ack------------------&gt; server: ESTABLISHED <span class="built_in">queue</span> (min (backlog, somaxconn))</span><br><span class="line">                                                                 |    |           |</span><br><span class="line">                                                                 |    |           ----------one backlog <span class="built_in">queue</span> per CPU core</span><br><span class="line">client: ESTABLISHED ----------psh+ack-----------------------------    -- out the accept <span class="built_in">queue</span></span><br><span class="line"></span><br><span class="line">somaxconn: An application can always request a larger backlog, but it will only get a backlog as large as <span class="keyword">this</span> maximum.</span><br><span class="line">somaxconn represents the maximal size of ESTABLISHED <span class="built_in">queue</span>. This is another <span class="built_in">queue</span>.</span><br><span class="line">Recall the previously mentioned SYN_RECV queue - your server is waiting for ACK from client. When the ACK arrives the kernel roughly speaking makes the big full-fledged socket from &quot;request socket&quot; and moves it to ESTABLISHED queue. Then you can do accept() on this socket. This queue is also affected by listen()&#x27;s backlog argument and limited by somaxconn in kernel</span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_max_syn_backlog</span><br><span class="line">#This value is adjusted to <span class="number">128</span> <span class="keyword">for</span> low memory machines, <span class="keyword">and</span> it will increase in proportion to the memory of machine. Note : Dont forget somaxconn that may limit backlog too.</span><br><span class="line">inet_listen-&gt;inet_csk_listen_start -&gt; reqsk_queue_alloc</span><br><span class="line">represents the maximal number of connections in SYN_RECV queue. I.e. when your server received SYN, sent SYN-ACK and haven&#x27;t received ACK yet. This is a separate queue of so-called &quot;request sockets&quot; - reqsk in code (i.e. not fully-fledged sockets, &quot;request sockets&quot; occupy less memory. In this state we can save some memory and not yet allocate a full socket because the full connection may not be at all in the future if ACK will not arrive).</span><br><span class="line"></span><br><span class="line">Client                     Server</span><br><span class="line">  |                          |</span><br><span class="line">  |                         bind</span><br><span class="line">  |                          |</span><br><span class="line">  |                        license</span><br><span class="line">connect                      |</span><br><span class="line">  |                          |</span><br><span class="line">  |SYN_SENT                  |</span><br><span class="line">  |     |                    |</span><br><span class="line">  |    SYN-------&gt;-&gt;SYN_RECV========&gt;=&gt;half-open-SYN-<span class="built_in">queue</span> (ipv4.tcp_max_syn_backlog, ss -n state syn-recv sport = :<span class="number">80</span> | wc -l)</span><br><span class="line">  |                    |     |          |       |</span><br><span class="line">  |ESTABLISHED&lt;-&lt;---SYN+ACK  |          |       ----&gt; <span class="keyword">if</span> full, <span class="keyword">default</span> will <span class="keyword">not</span> interrupt, tcp_abort_on_overflow = <span class="number">1</span> will direct <span class="built_in">abort</span></span><br><span class="line">  |     |                    |          |</span><br><span class="line">  |    ACK---&gt;-&gt;ESTABLISHED&lt;=&lt;===========</span><br><span class="line">  |                   |      |</span><br><span class="line">  |                   |      |</span><br><span class="line">                      =================&gt;=&gt;accept-queue (min(backlog, somaxconn(default 128)), netstat -s | grep &#x27;times the listen queue of a socket overflowed&#x27;)</span><br><span class="line">  |                          |             |</span><br><span class="line">  |                          |             |</span><br><span class="line">  |                        Accept&lt;=&lt;=======</span><br><span class="line">write                        |</span><br><span class="line">  |                          |</span><br><span class="line">  |ESTAB--PSH ACK--&gt;ESTABLISH|</span><br><span class="line">  |                          |</span><br><span class="line">  |                         read</span><br></pre></td></tr></table></figure>
<a target="_blank" rel="noopener" href="https://jaseywang.me/2014/07/20/tcp-queue-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/">tcp queues</a></li>
</ul>
</li>
</ul>
<p>sar   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n TCP,ETCP 2</span><br><span class="line">02:47:30 AM  active/s passive/s    iseg/s    oseg/s</span><br><span class="line">02:47:31 AM      0.00      0.00      8.51      6.38</span><br><span class="line"></span><br><span class="line">02:47:30 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">02:47:31 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line"><span class="comment"># active/s: Number of locally-initiated TCP connections per second (e.g., via connect()).</span></span><br><span class="line"><span class="comment"># passive/s: Number of remotely-initiated TCP connections per second (e.g., via accept()).</span></span><br><span class="line"><span class="comment"># retrans/s: Number of TCP retransmits per second.</span></span><br><span class="line"><span class="comment"># The active and passive counts are often useful as a rough measure of server load: number of new accepted connections (passive), and number of downstream connections (active). It might help to think of active as outbound, and passive as inbound, but this isn&#x27;t strictly true (e.g., consider a localhost to localhost connection).</span></span><br><span class="line"><span class="comment"># Retransmits are a sign of a network or server issue; it may be an unreliable network (e.g., the public Internet), or it may be due a server being overloaded and dropping packets. The example above shows just one new TCP connection per-second.</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">$ cat /proc/sys/net/ipv4/tcp_mem</span><br><span class="line">3082008 4109346 6164016 <span class="comment"># here is 4K page, but in sysctl.conf config file was bytes</span></span><br><span class="line"></span><br><span class="line">$ cat /proc/net/sockstat</span><br><span class="line">sockets: used 181                                <span class="comment"># total sockets</span></span><br><span class="line">TCP: inuse 16 orphan 0 tw 0 alloc 27 mem 5       <span class="comment"># inuse = netstat -lnt | grep ^tcp | wc -l; cat /proc/sys/net/ipv4/tcp_max_orphans</span></span><br><span class="line">UDP: inuse 3 mem 0</span><br><span class="line">UDPLITE: inuse 0</span><br><span class="line">RAW: inuse 0</span><br><span class="line">FRAG: inuse 0 memory 0</span><br><span class="line"></span><br><span class="line"><span class="comment"># orphan , /proc/sys/net/ipv4/tcp_max_orphans, Maximal number of TCP sockets not attached to any user file handle held by system.</span></span><br><span class="line"><span class="comment"># tw , netstat -ant | grep TIME_WAIT | wc -l</span></span><br><span class="line"><span class="comment"># alloc, netstat -ant | grep ^tcp | wc -l</span></span><br><span class="line"><span class="comment"># mem,  proc/net/sockstat, specifically the mem field, is where to look. This value is is reported in kernel pages and corresponds directly to /proc/sys/net/ipv4/tcp_mem.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#At the individual socket level, memory is allocated in kernel space only until the user space code reads it, at which time the kernel memory is freed. sk_buff-&gt;truesize is the sum of both the amount of data buffered, as well as the socket structure itself</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#The device drivers allocate a region of memory for the device to perform DMA to incoming packets</span></span><br><span class="line"><span class="comment">#https://unix.stackexchange.com/questions/419518/how-to-tell-how-much-memory-tcp-buffers-are-actually-using/419525</span></span><br><span class="line"></span><br><span class="line">$ cat /proc/net/tcp</span><br><span class="line">  sl  local_address rem_address   st tx_queue rx_queue tr tm-&gt;when retrnsmt   uid  timeout inode</span><br><span class="line"></span><br><span class="line">$ cat /proc/net/dev</span><br><span class="line">Inter-   |   Receive                                                |  Transmit</span><br><span class="line"> face    |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed</span><br><span class="line">enp1s0f0:  8681      58    0    0    0     0          0        18    10054      48    0    0    0     0       0          0</span><br><span class="line">enp1s0f1:  3200      30    0    0    0     0          0        17     1110      15    0    0    0     0       0          0</span><br><span class="line">  eno1:     180       3    0    0    0     0          0        72        0       0    0    0    0     0       0          0</span><br><span class="line"> bond0:   11881      88    0    0    0     0          0        35    11164      63    0    0    0     0       0          0</span><br><span class="line">  eth0:       0       0    0    0    0     0          0         0        0       0    0    0    0     0       0          0</span><br><span class="line">    lo:    1120      13    0    0    0     0          0         0     1120      13    0    0    0     0       0          0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ ss -itmpn dst <span class="string">&quot;<span class="variable">$des_ipaddr</span>&quot;</span></span><br><span class="line">skmem:(r0,rb235392,t0,tb332800,f0,w0,o0,bl0,d0) cubic wscale:7,7 rto:205 rtt:4.361/8.67 ato:40 mss:8948 rcvmss:536 advmss:8948 cwnd:10 bytes_acked:4 bytes_received:126 segs_out:6 segs_in:8 send 164.1Mbps lastsnd:10357 lastrcv:10396 lastack:10357 pacing_rate 328.3Mbps rcv_space:26844</span><br><span class="line">...</span><br><span class="line">skmem:(r0,rb235104,t317420,tb2595840,f488596,w2169708,o0,bl0,d0) cubic wscale:7,7 rto:204 rtt:3.571/0.166 mss:8948 rcvmss:536 advmss:8948 cwnd:78 ssthresh:16 bytes_acked:2234190366 segs_out:249732 segs_in:80343 send 1563.6Mbps lastsnd:1 lastrcv:3629700830 pacing_rate 3126.6Mbps unacked:43 rcv_space:26880</span><br><span class="line"></span><br><span class="line">$ ss -m</span><br><span class="line">skmem:(r0,rb134217728,t0,tb134217728,f4096,w0,o0,bl0,d0)</span><br><span class="line">   <span class="built_in">printf</span>(<span class="string">&quot; skmem:(r%u,rb%u,t%u,tb%u,f%u,w%u,o%u&quot;</span>,</span><br><span class="line">               skmeminfo[SK_MEMINFO_RMEM_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_RCVBUF],</span><br><span class="line">               skmeminfo[SK_MEMINFO_WMEM_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_SNDBUF],</span><br><span class="line">               skmeminfo[SK_MEMINFO_FWD_ALLOC],</span><br><span class="line">               skmeminfo[SK_MEMINFO_WMEM_QUEUED],</span><br><span class="line">               skmeminfo[SK_MEMINFO_OPTMEM]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (RTA_PAYLOAD(tb[attrtype]) &gt;=</span><br><span class="line">                (SK_MEMINFO_BACKLOG + 1) * sizeof(__u32))</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;,bl%u&quot;</span>, skmeminfo[SK_MEMINFO_BACKLOG]);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (RTA_PAYLOAD(tb[attrtype]) &gt;=</span><br><span class="line">                (SK_MEMINFO_DROPS + 1) * sizeof(__u32))</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;,d%u&quot;</span>, skmeminfo[SK_MEMINFO_DROPS]);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;)&quot;</span>);</span><br><span class="line"></span><br><span class="line">       -m, --memory</span><br><span class="line">              Show socket memory usage. The output format is:</span><br><span class="line"></span><br><span class="line">              skmem:(r&lt;rmem_alloc&gt;,rb&lt;rcv_buf&gt;,t&lt;wmem_alloc&gt;,tb&lt;snd_buf&gt;,</span><br><span class="line">                            f&lt;fwd_alloc&gt;,w&lt;wmem_queued&gt;,o&lt;opt_mem&gt;,</span><br><span class="line">                            bl&lt;back_log&gt;,d&lt;sock_drop&gt;)</span><br><span class="line">              &lt;rmem_alloc&gt;</span><br><span class="line">                     the memory allocated <span class="keyword">for</span> receiving packet</span><br><span class="line">              &lt;rcv_buf&gt;</span><br><span class="line">                     the total memory can be allocated <span class="keyword">for</span> receiving packet</span><br><span class="line">              &lt;wmem_alloc&gt;</span><br><span class="line">                     the memory used <span class="keyword">for</span> sending packet (<span class="built_in">which</span> has been sent to layer 3)</span><br><span class="line">              &lt;snd_buf&gt;</span><br><span class="line">                     the total memory can be allocated <span class="keyword">for</span> sending packet</span><br><span class="line">              &lt;fwd_alloc&gt;</span><br><span class="line">                     the  memory  allocated  by the socket as cache, but not used <span class="keyword">for</span> receiving/sending packet yet. If need memory to send/receive packet, the memory <span class="keyword">in</span></span><br><span class="line">                     this cache will be used before allocate additional memory.</span><br><span class="line">              &lt;wmem_queued&gt;</span><br><span class="line">                     The memory allocated <span class="keyword">for</span> sending packet (<span class="built_in">which</span> has not been sent to layer 3)</span><br><span class="line">              &lt;ropt_mem&gt;</span><br><span class="line">                     The memory used <span class="keyword">for</span> storing socket option, e.g., the key <span class="keyword">for</span> TCP MD5 signature</span><br><span class="line">              &lt;back_log&gt;</span><br><span class="line">                     The memory used <span class="keyword">for</span> the sk backlog queue. On a process context, <span class="keyword">if</span> the process is receiving packet, and a new packet is received, it  will  be  put</span><br><span class="line">                     into the sk backlog queue, so it can be received by the process immediately</span><br><span class="line">              &lt;sock_drop&gt;</span><br><span class="line">                     the number of packets dropped before they are de-multiplexed into the socket</span><br><span class="line"></span><br><span class="line">$ ip tcp_metrics show  | grep <span class="variable">$des_ipaddr</span></span><br><span class="line"><span class="variable">$des_ipaddr</span> age 297.526sec ssthresh 34 cwnd 56 rtt 3986us rttvar 7475us <span class="built_in">source</span> <span class="variable">$source_ip</span></span><br><span class="line"></span><br><span class="line">$ ip tcp_metrics flush all</span><br><span class="line"></span><br><span class="line"><span class="comment"># disable tcp_metrics</span></span><br><span class="line"><span class="comment"># tcp_metrics will cache the tcp connection status in cache, disable cache tcp status </span></span><br><span class="line">net.ipv4.tcp_no_metrics_save = 1</span><br><span class="line">``` </span><br><span class="line">dup ack cause the ssthresh = cwnd/2 ???    </span><br><span class="line"></span><br><span class="line">high rrt impact the window size, the low rrt will recovery quickly     </span><br><span class="line">window update -&gt;     </span><br><span class="line">tcp zero window -&gt;    </span><br><span class="line">tcp zero window -&gt;     </span><br><span class="line">&lt;- tcp window full      </span><br><span class="line"></span><br><span class="line"> driver</span><br><span class="line">```bash</span><br><span class="line">$ ls /sys/class/net/em2/statistics</span><br><span class="line">collisions  rx_compressed  rx_errors        rx_length_errors  rx_over_errors     tx_bytes           tx_dropped      tx_heartbeat_errors</span><br><span class="line">multicast   rx_crc_errors  rx_fifo_errors   rx_missed_errors  rx_packets         tx_carrier_errors  tx_errors       tx_packets</span><br><span class="line">rx_bytes    rx_dropped     rx_frame_errors  rx_nohandler      tx_aborted_errors  tx_compressed      tx_fifo_errors  tx_window_errors</span><br><span class="line"></span><br><span class="line">$ ethtool -S eno1 | grep -Ei <span class="string">&#x27;fail|crc|dis|drop|miss|err|over|timeout|jabb|full|retrans|out.*of|restar|collis&#x27;</span></span><br><span class="line"></span><br><span class="line">./include/uapi/linux/if_link.h</span><br><span class="line">dropped =  stats-&gt;rx_dropped + stats-&gt;rx_missed_errors(no space <span class="keyword">in</span> linux buffers/no space available + bad packets received/packet transmit problems)  </span><br><span class="line">overruns = stats-&gt;rx_fifo_errors (fifo overrun) Receiver overruns usually occur when packets come <span class="keyword">in</span> faster than the kernel can service the last interrupt   </span><br><span class="line"></span><br><span class="line">struct rtnl_link_stats &#123;</span><br><span class="line">        __u32   rx_packets;             /* total packets received       */</span><br><span class="line">        __u32   tx_packets;             /* total packets transmitted    */</span><br><span class="line">        __u32   rx_bytes;               /* total bytes received         */</span><br><span class="line">        __u32   tx_bytes;               /* total bytes transmitted      */</span><br><span class="line">        __u32   rx_errors;              /* bad packets received         */</span><br><span class="line">        __u32   tx_errors;              /* packet transmit problems     */</span><br><span class="line">        __u32   rx_dropped;             /* no space <span class="keyword">in</span> linux buffers    */</span><br><span class="line">        __u32   tx_dropped;             /* no space available <span class="keyword">in</span> linux  */</span><br><span class="line">        __u32   multicast;              /* multicast packets received   */</span><br><span class="line">        __u32   collisions;</span><br><span class="line"></span><br><span class="line">        /* detailed rx_errors: */</span><br><span class="line">        __u32   rx_length_errors;</span><br><span class="line">        __u32   rx_over_errors;         /* receiver ring buff overflow  */</span><br><span class="line">        __u32   rx_crc_errors;          /* recved pkt with crc error    */</span><br><span class="line">        __u32   rx_frame_errors;        /* recv<span class="string">&#x27;d frame alignment error */</span></span><br><span class="line"><span class="string">        __u32   rx_fifo_errors;         /* recv&#x27;</span>r fifo overrun          */</span><br><span class="line">        __u32   rx_missed_errors;       /* receiver missed packet       */</span><br><span class="line"></span><br><span class="line">        /* detailed tx_errors */</span><br><span class="line">        __u32   tx_aborted_errors;</span><br><span class="line">        __u32   tx_carrier_errors;</span><br><span class="line">        __u32   tx_fifo_errors;</span><br><span class="line">        __u32   tx_heartbeat_errors;</span><br><span class="line">        __u32   tx_window_errors;</span><br><span class="line"></span><br><span class="line">        /* <span class="keyword">for</span> cslip etc */</span><br><span class="line">        __u32   rx_compressed;</span><br><span class="line">        __u32   tx_compressed;</span><br><span class="line"></span><br><span class="line"><span class="comment">#ifndef __GENKSYMS__</span></span><br><span class="line">        __u32   rx_nohandler;           /* dropped, no handler found    */</span><br><span class="line"><span class="comment">#endif</span></span><br></pre></td></tr></table></figure>

<h3 id="cases"><a href="#cases" class="headerlink" title="cases"></a>cases</h3><h4 id="bonding-tcp-retrans"><a href="#bonding-tcp-retrans" class="headerlink" title="[bonding tcp retrans]"></a>[bonding tcp retrans]</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">not down enp77s0</span><br><span class="line">Average:         eno1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno4      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:      enp77s0      4.20 141207.77      0.33 849857.72      0.00      0.00      1.53</span><br><span class="line">Average:        bond0 186607.26 191349.97 1214098.43 1216441.18      0.00      0.00      2.55</span><br><span class="line">Average:    enp77s0d1 186602.99  50142.20 1214097.54 366583.46      0.00      0.00      1.02</span><br><span class="line">Average:           lo      0.38      0.38      0.02      0.02      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Average:     atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">Average:         0.00      0.00    152.13      0.00      0.00</span><br><span class="line"></span><br><span class="line">ifdown enp77s0</span><br><span class="line">Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">Average:         eno1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno4      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:      enp77s0      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:        bond0 176756.83 194034.47 1214647.67 1215462.75      0.00      0.00      1.61</span><br><span class="line">Average:    enp77s0d1 176756.83 194034.47 1214647.67 1215462.75      0.00      0.00      1.61</span><br><span class="line">Average:           lo      0.24      0.24      0.01      0.01      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Average:     atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">Average:         0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Here is sender, no any retrans</span><br><span class="line">Average:        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">Average:         eno1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno2      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno3      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:         eno4      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:        bond0 190024.36 190577.24 1211587.94 1213956.38      0.00      0.00      1.54</span><br><span class="line">Average:           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line">Average:      enp65s0 190024.42 190577.24 1211588.22 1213956.38      0.00      0.00      1.54</span><br><span class="line">Average:    enp65s0d1      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">Average:     atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">Average:         0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure>

<h4 id="Finally-verify-if-cores-were-successfully-isolated-by-checking-how-many-thread-context-switches-are-occurring-per-core"><a href="#Finally-verify-if-cores-were-successfully-isolated-by-checking-how-many-thread-context-switches-are-occurring-per-core" class="headerlink" title="Finally verify if cores were successfully isolated by checking how many thread context switches are occurring per core"></a><a target="_blank" rel="noopener" href="https://rigtorp.se/low-latency-guide/">Finally verify if cores were successfully isolated by checking how many thread context switches are occurring per core</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ tuna --cpus=1-7 --isolate</span><br><span class="line"><span class="comment">## 1 means cpu0, Additionally kernel workqueues needs to be moved away from isolated cores. To move all work queues to core 0</span></span><br><span class="line"></span><br><span class="line">$ find /sys/devices/virtual/workqueue -name cpumask  -<span class="built_in">exec</span> sh -c <span class="string">&#x27;echo 1 &gt; &#123;&#125;&#x27;</span> <span class="string">&#x27;;&#x27;</span></span><br><span class="line">$ find /sys/devices/virtual/workqueue -name cpumask -<span class="built_in">print</span> -<span class="built_in">exec</span> cat <span class="string">&#x27;&#123;&#125;&#x27;</span> <span class="string">&#x27;;&#x27;</span></span><br><span class="line"></span><br><span class="line">$ perf <span class="built_in">stat</span> -e <span class="string">&#x27;sched:sched_switch&#x27;</span> -a -A --timeout 10000</span><br><span class="line"></span><br><span class="line">The kernel<span class="string">&#x27;s dirty page writeback mechanism (seen in the process table as &#x27;</span>flush:NNN<span class="string">&#x27;) uses a per-block device flusher thread model. These flush threads come and go on demand, as defined by vm.* sysctl settings and application behavior. The challenge in dealing with these threads has been that they are scheduled like any other thread, and have no default affinity. This means they can be scheduled on any core. Further, depending on factors such as the amount of dirty pages that need to be flushed and speed of storage, the amount of time they execute is unbounded, which might introduce jitter. The workqueue affinity tuning capability allows for a further level of CPU isolation from dirty page writeback</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string">$ echo 1 &gt; /sys/bus/workqueue/devices/writeback/cpumask</span></span><br><span class="line"><span class="string">or</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">tuned.conf</span></span><br><span class="line"><span class="string">[sysfs]</span></span><br><span class="line"><span class="string">/sys/bus/workqueue/devices/writeback/cpumask = 1</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/etc/cgconfig.conf</span></span><br><span class="line"><span class="string">group node0 &#123;</span></span><br><span class="line"><span class="string"> cpuset &#123;</span></span><br><span class="line"><span class="string"> cpuset.cpus = 0-7;</span></span><br><span class="line"><span class="string">cpuset.cpu_exclusive = 1;</span></span><br><span class="line"><span class="string"> cpuset.mems = 0;</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">group node1 &#123;</span></span><br><span class="line"><span class="string"> cpuset &#123;</span></span><br><span class="line"><span class="string"> cpuset.cpus = 8-15;</span></span><br><span class="line"><span class="string">cpuset.cpu_exclusive = 1;</span></span><br><span class="line"><span class="string"> cpuset.mems = 1;</span></span><br><span class="line"><span class="string"> &#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">$ cgexec -g cpuset:node1 ./YOURPROC</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/proc/sys/kernel/sched_min_granularity_ns</span></span><br><span class="line"><span class="string">Set this value lower for latency-sensitive tasks (or huge thread-count), higher for computebound/throughput oriented workloads. Adjust by factor of 2-10x</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">/proc/sys/kernel/sched_migration_cost_ns</span></span><br><span class="line"><span class="string">Specifies the amount of time after the last execution that a task is considered to be “cache hot” in migration decisions. Increasing this variable reduces task migrations. Adjust by factor of 2-10x. Task migrations may be irrelevant depending on any configured task affinity settings</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This is due to the NMI watchdog using the perf infrastructure. To workaround this issue, disable the kernel nmi_watchdog via sysctl, or in a tuned profile</span></span><br><span class="line"><span class="string">[sysfs]</span></span><br><span class="line"><span class="string">/proc/sys/kernel/nmi_watchdog = 0</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## The virtual memory subsystem runs a per core statistics update task every 1 second by default. You can reduce this interval by setting vm.stat_interval to a higher value, for example 120 seconds   </span></span><br><span class="line"><span class="string">The kernel&#x27;</span>s virtual memory management subsystem tabulates statistics every second by default. Calculating these statistics occurs within a kernel timer tick and is unbounded. Reduce the frequency by <span class="built_in">which</span> the kernel updates virtual memory statistics by setting the vm.stat_interval sysctl to a higher value.</span><br><span class="line">$ sysctl vm.stat_interval=120</span><br><span class="line"></span><br><span class="line">Finally you can verify that the timer interrupt frequency is reduced by inspecting /proc/interrupts or using perf to monitor timer interrupts:</span><br><span class="line">$ perf <span class="built_in">stat</span> -e <span class="string">&#x27;irq_vectors:local_timer_entry&#x27;</span> -a -A --timeout 30000</span><br></pre></td></tr></table></figure>

<ul>
<li><p>reduced timer interrupt frequency. Expect isolcpus + nohz_full cores to show a timer interrupt every other second or so. Unfortunately the timer tick cannot be completely eliminated</p>
</li>
<li><p>Huge pages reduces TLB pressure, but THP support introduces latency spikes when pages are promoted into huge pages and when memory compaction is triggered</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">transparent_hugepage=never or running the following <span class="built_in">command</span>:</span><br><span class="line"><span class="built_in">echo</span> never &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line">or</span><br><span class="line">[sysctl]</span><br><span class="line">vm.nr_hugepages = 4096</span><br><span class="line"></span><br><span class="line">If your application tries to access a memory page that is missing <span class="keyword">in</span> the TLB, it causes a TLB miss requiring the MMU to walk the page table. The default page size is 4096 bytes, by using huge pages of 2 MB or 1 GB you can reduce the amount of TLB misses <span class="keyword">for</span> the same amount of actively used RAM.</span><br><span class="line"></span><br><span class="line">$ perf <span class="built_in">stat</span> -e <span class="string">&#x27;dTLB-loads,dTLB-load-misses,iTLB-loads,iTLB-load-misses&#x27;</span> -a --timeout 10000</span><br><span class="line">$ <span class="built_in">echo</span> always &gt; /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>
<p>Each process has a page table mapping virtual address to physical address. When the page table changes such that memory is unmapped (munmap) or access to memory is restricted (mmap changing PROT_* flags) the TLB needs to be flushed on all cores currently running the application process. This is called a TLB shootdown and is implemented as a inter-processor interrupt (IPI) that will introduce jitter to your running application.      </p>
</li>
</ul>
<p>view the number of TLB shootdowns per CPU core   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ egrep <span class="string">&#x27;TLB|CPU&#x27;</span> /proc/interrupts</span><br></pre></td></tr></table></figure>

<p>For lowest latency applications I avoid using real-time priorities SCHED_FIFO / SCHED_RR. Instead it’s better to run a single thread in SCHED_OTHER per core and using busy waiting / polling in order to never enter kernel mode. If you do so with real-time priority you can prevent the kernel from running tasks such as vmstat leading to kernel lockup issues.<br>If you are using real-time tasks you might want to adjust the real-time throttling configuration.</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#disable ksm</span></span><br><span class="line">$ echo <span class="number">0</span> &gt; <span class="regexp">/sys/</span>kernel<span class="regexp">/mm/</span>ksm/run</span><br><span class="line"></span><br><span class="line"><span class="comment">#Disable mitigations for CPU vulnerabilities</span></span><br><span class="line"> mitigations=off to increase performance</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">If your processor supports cache partitioning (Intel Cache Allocation Technology) consider using it to allocate most of the last-level cache (LLC) to your application.</span><br><span class="line">https:<span class="regexp">//</span>www.kernel.org<span class="regexp">/doc/</span>Documentation/kernel-per-CPU-kthreads.txt</span><br></pre></td></tr></table></figure>

<h5 id="RFC2544-stipulates-that-the-latency-test"><a href="#RFC2544-stipulates-that-the-latency-test" class="headerlink" title="RFC2544 stipulates that the latency test"></a>RFC2544 stipulates that the latency test</h5><ul>
<li>Should be at least 120 seconds in duration</li>
<li>Frame sizes to be used on Ethernet 64, 128, 256, 512, 1024, 1280, and 1518</li>
<li>Should include an identifying tag in one frame after 60 seconds with the type of tag being implementation dependent</li>
<li>Records the time at which the frame is fully transmitted (timestamp A)</li>
<li>The receiver logic in the test equipment must recognize the tag information in the frame stream and record the time at which the tagged frame was received (timestamp B)</li>
<li>This test should be performed with the test frame addressed to the same destination as the rest of the data stream, and also with each of the test frames addressed to a new destination network</li>
<li>The test must be repeated at least 20 times with the reported value being the average of the recorded values</li>
<li>The latency is timestamp B minus timestamp A, as per the relevant definition from RFC</li>
</ul>
<h5 id="The-network-latency"><a href="#The-network-latency" class="headerlink" title="The network latency"></a><a target="_blank" rel="noopener" href="https://www.marvell.com/documents/rjx203ukari4r93gntem/">The network latency</a></h5><p>There are new technologies that are pushing latencies into the singledigit microsecond range when measured back-to-back in benchmark<br>repeat 20 times and get the average result</p>
<p>50 - 125μs   1Gb Ethernet (TCP/IP)</p>
<ul>
<li>Multi-tasking: multiple highbandwidth applications running<br>simultaneously</li>
<li>Bulk data transfer</li>
<li>Transactional database backup and<br>applications</li>
<li>Web (front-end for data centers)</li>
</ul>
<p>5 - 50μs 10Gb Ethernet<br>(TCP/IP)</p>
<ul>
<li>Bulk data transfer</li>
<li>Real-time video streaming</li>
<li>Database backup and applications</li>
</ul>
<p>3 - 5μs RDMA, RoCEE, and<br>iWARP</p>
<ul>
<li>High Performance Computing</li>
<li>High-Frequency Trading (HFT)</li>
<li>Inter-process communication (IPC)<br>cluster</li>
<li>Low-latency applications</li>
</ul>
<p>Sub-3μs(less than 3μs) InfiniBand (QDR)<br>and proprietary</p>
<ul>
<li>High Performance Computing</li>
<li>High Frequency Trading (HFT)</li>
<li>Ultra-low latency applications</li>
</ul>
<h5 id="Troubleshooting-a-Zero-Window-https-wiki-wireshark-org-TCP-20ZeroWindow-For-one-reason-or-another-the-machine-alerting-the-Zero-Window-will-not-receive-any-more-data-from-the-host-It-could-be-that-the-machine-is-running-too-many-processes-at-that-moment-and-its-processor-is-maxed-Or-it-could-be-that-there-is-an-error-in-the-TCP-receiver-like-a-Windows-registry-misconfiguration-Try-to-determine-what-the-client-was-doing-when-the-TCP-Zero-Window-happened"><a href="#Troubleshooting-a-Zero-Window-https-wiki-wireshark-org-TCP-20ZeroWindow-For-one-reason-or-another-the-machine-alerting-the-Zero-Window-will-not-receive-any-more-data-from-the-host-It-could-be-that-the-machine-is-running-too-many-processes-at-that-moment-and-its-processor-is-maxed-Or-it-could-be-that-there-is-an-error-in-the-TCP-receiver-like-a-Windows-registry-misconfiguration-Try-to-determine-what-the-client-was-doing-when-the-TCP-Zero-Window-happened" class="headerlink" title="Troubleshooting a Zero Window](https://wiki.wireshark.org/TCP%20ZeroWindow) For one reason or another, the machine alerting the Zero Window will not receive any more data from the host. It could be that the machine is running too many processes at that moment, and its processor is maxed. Or it could be that there is an error in the TCP receiver, like a Windows registry misconfiguration. Try to determine what the client was doing when the TCP Zero Window happened."></a>Troubleshooting a Zero Window](<a target="_blank" rel="noopener" href="https://wiki.wireshark.org/TCP%20ZeroWindow">https://wiki.wireshark.org/TCP%20ZeroWindow</a>) For one reason or another, the machine alerting the Zero Window will not receive any more data from the host. It could be that the machine is running too many processes at that moment, and its processor is maxed. Or it could be that there is an error in the TCP receiver, like a Windows registry misconfiguration. Try to determine what the client was doing when the TCP Zero Window happened.</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ tcpkill -i eth0 port 21</span><br><span class="line">$ tcpkill host 192.168.1.2</span><br><span class="line">$ tcpkill ip host 192.168.1.2 and not 192.168.1.111</span><br></pre></td></tr></table></figure>

<h5 id="kernel-improved"><a href="#kernel-improved" class="headerlink" title="kernel improved"></a>kernel improved</h5><p>linux 4.4 lockless listener<br>&lt; linux 4.4, each listener has a request queue. after insert a new request the each sync package will lock listener</p>
<blockquote>
<p>= linux 4.4 create an new tcp ehash table for reduece the lock compete</p>
</blockquote>
<h5 id="tcp-probe"><a href="#tcp-probe" class="headerlink" title="tcp_probe"></a>tcp_probe</h5><p>tcp_probe<br>That function is now replaced by tcp/tcp_probe trace-event. You can use it via ftrace or perftools</p>
<h5 id="backlog-test"><a href="#backlog-test" class="headerlink" title="backlog test"></a><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000019252960">backlog test</a></h5><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">client.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;arpa/inet.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> sockfd;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">servaddr</span>;</span></span><br><span class="line"></span><br><span class="line">    sockfd = socket(PF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    bzero(&amp;servaddr, <span class="keyword">sizeof</span>(servaddr));</span><br><span class="line">    servaddr.sin_family = AF_INET;</span><br><span class="line">    servaddr.sin_port = htons(<span class="number">50001</span>);</span><br><span class="line">    servaddr.sin_addr.s_addr = inet_addr(<span class="string">&quot;127.0.0.1&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> != connect(sockfd, (struct sockaddr *)&amp;servaddr, <span class="keyword">sizeof</span>(servaddr)))</span><br><span class="line">    &#123;</span><br><span class="line">         <span class="built_in">printf</span>(<span class="string">&quot;connect failed!\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">         <span class="built_in">printf</span>(<span class="string">&quot;connect succeed!\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    sleep(<span class="number">30</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">server.c</span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BACKLOG 4</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> listenfd;</span><br><span class="line">    <span class="keyword">int</span> connfd;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">servaddr</span>;</span></span><br><span class="line"></span><br><span class="line">    listenfd = socket(PF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    bzero(&amp;servaddr, <span class="keyword">sizeof</span>(servaddr));</span><br><span class="line">    servaddr.sin_family = AF_INET;</span><br><span class="line">    servaddr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class="line">    servaddr.sin_port = htons(<span class="number">50001</span>);</span><br><span class="line"></span><br><span class="line">    bind(listenfd, (struct sockaddr *)&amp;servaddr, <span class="keyword">sizeof</span>(servaddr));</span><br><span class="line"></span><br><span class="line">    listen(listenfd, BACKLOG);</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        sleep(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#<span class="meta"># disable syncookies</span></span><br><span class="line">echo <span class="number">0</span> &gt; /proc/sys/net/ipv4/tcp_syncookies</span><br><span class="line"></span><br><span class="line">netstat -t check the status</span><br><span class="line"><span class="meta"># only 5x established <span class="meta-string">&lt;-&gt; established, 4x syn_recv &lt;-&gt; established = 9x connections</span></span></span><br></pre></td></tr></table></figure>

<h5 id="Driver-error"><a href="#Driver-error" class="headerlink" title="Driver error"></a>Driver error</h5><p><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/counters-troubleshooting-for-linux-driver">Counters Troubleshooting for Linux Driver</a><br><a target="_blank" rel="noopener" href="https://community.mellanox.com/s/article/understanding-mlx5-ethtool-counters">ethtool mlx5 counters</a>     </p>
<ul>
<li>ifconfig<ul>
<li>error<ul>
<li>counts CRC errors, too-short/too-long frames.</li>
</ul>
</li>
<li>dropped<ul>
<li><a target="_blank" rel="noopener" href="https://git.kernel.org/cgit/linux/kernel/git/stable/linux-stable.git/commit/?id=caf586e6">RHEL 7 differentiates drop counter from older OS -&gt; RHEL 6 and RHEL 5</a><ul>
<li>unrecognised protocol</li>
<li>unknown VLAN</li>
<li>unregistered multicast address</li>
<li>Incremented for certain packets received by an inactive bond or team member</li>
<li>softnet backlog full (accounted in /proc/net/softnet_stat)</li>
<li><ul>
<li>We can handle a per-device counter of such dropped frames at core level, and automatically adds it to the device provided stats (rx_dropped), so that standard tools can be used (ifconfig, ip link, cat /proc/net/dev)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>overrun<ul>
<li>counts that times when there is FIFO overruns, caused by the rate at which the buffer gets full and the kernel isn’t able to empty it.</li>
</ul>
</li>
<li>frame<ul>
<li>counts only misaligned frames, it means frames with a length not divisible by 8. Because of that length is not a valid frame and it is simply discarded</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/4547571">rx_cache_full</a><ul>
<li>The number of events of full internal page cache where driver can’t put a page back to the cache for recycling (page will be freed)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="number">129</span> <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mlx5e_grp_sw_update_stats</span><span class="params">(struct mlx5e_priv *priv)</span></span></span><br><span class="line">...</span><br><span class="line"> <span class="number">170</span>                 s-&gt;rx_cache_full  += rq_stats-&gt;cache_full;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">bool</span> <span class="title">mlx5e_rx_cache_put</span><span class="params">(struct mlx5e_rq *rq,</span></span></span><br><span class="line"><span class="function"><span class="params">                                      struct mlx5e_dma_info *dma_info)</span></span></span><br><span class="line"><span class="function">       struct mlx5e_page_cache *cache </span>= &amp;rq-&gt;page_cache;</span><br><span class="line">       u32 tail_next = (cache-&gt;tail + <span class="number">1</span>) &amp; (MLX5E_CACHE_SIZE - <span class="number">1</span>);</span><br><span class="line">       <span class="class"><span class="keyword">struct</span> <span class="title">mlx5e_rq_stats</span> *<span class="title">stats</span> = <span class="title">rq</span>-&gt;<span class="title">stats</span>;</span></span><br><span class="line"></span><br><span class="line">mlx5e_page_release(struct mlx5e_rq *rq, struct mlx5e_dma_info *dma_info,</span><br><span class="line"> <span class="number">249</span>                         <span class="keyword">bool</span> recycle)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>rx_no_buffer_count,there was nowhere to DMA the packet<ul>
<li>DMA skb-data to rx-buffer-info(linux RAM, soft-interrupt).</li>
<li>RNBC is a warning sign of a slow drain from the MAC and can be treated by adding more buffers.</li>
<li>There will be times when the RNBC will go up, but it will look like the stack and driver have a ton of buffers but work is not being done.  If you have a task that is eating up the CPU, the ISR or polling routines won’t refill the buffers fast enough and RNBC will happen.</li>
<li>Imagine we have a slow CPU, but a wicked fastbus.  The software is very slow to process the descriptors and return them, but once the descriptors are given to the hardware, it empties the backlog (read the FIFO) faster than the incoming frames are filling the FIFO.  Returning to our kitchen sink analogy, the water is coming in at a fairly constant rate.  But imagine the stopper is down, making the sink fill up.  Just before it over flows, the drain is opened and down it goes.  Once the water doesn’t go down the drain would be the same moment our RNBC would be incremented.  The kitchen sink itself becomes our FIFO and if the FIFO is big enough, it can save frame for quiet some time.  This is 1 Gigabit (or faster) that we’re talking about, so with a good sized FIFO (24K RX for example) that’s only 375 frames at 64 bytes, or 267microseconds of data.  That’s not very much time.  But in a world full of 2 and 3 Gigahertz CPUs that’s long enough.</li>
</ul>
</li>
<li><code>fifo queues full will cause the error too, and the package not go to NIC reveive ring buffer(local CPU RAM), if you have no any CPU or memory resource, you will got the same result, NIC/CPU/MEM resource not enough will cause the same issue</code></li>
<li>rx_errors: Number of received packets that were dropped due to PHY layer related errors. For example:<ul>
<li>symbol error, or an invalid block.</li>
<li>Length related errors (greater than MTU octets, length less than 64 octets, error in length)</li>
<li>Bad CRC that are not runts, jabbers, or alignment errors.</li>
<li>This counter is increased at point (1) in the figure above.</li>
</ul>
</li>
<li>rx_fifo_errors/rx_discards_phy/rx_missed_errors/rx_no_buffer_count/(rx_brb_discard&gt;0 (Big Receive Buffer) and rx_discard=0) (mlx5_core, igb, ixgbe, bnx2x)<ul>
<li>Network hardware buffers to fill and overflow</li>
<li>MPC is a failure condition leading to dropped packets and can be treated with more buffers and faster interconnect buses</li>
<li>The number of received packets dropped due to lack of buffers on a physical port. If this counter is increasing, it implies that the adapter is congested and cannot absorb the traffic coming from the network</li>
<li>Slow CPU to DMA ring buffer frames cause the package loss, and the ring buff full too</li>
<li>buff error</li>
<li>igb show the ifconfig overruns el7<ul>
<li>stats-&gt;rx_fifo_errors (fifo overrun) Receiver overruns usually occur when packets come in faster than the kernel can service the last interrupt</li>
<li>driver speed &lt; NIC ring buff speed (buff full cause package loss, could not write to tcp_mem, socket buff)</li>
</ul>
</li>
</ul>
</li>
<li>rx_dropped (in the compute node, too many in i40e, i40e no rx_fifo_errors and rx_missed_errors) same with rx_discard<ul>
<li>Number of received packets which were chosen to be discarded even though no errors had been detected to prevent them from passing to the upper layer<ul>
<li>For example, drop due to buffer overflow</li>
</ul>
</li>
</ul>
</li>
<li>port.rx_dropped/rx_discards (ixgbe/i40e)<ul>
<li>Discards can happen for many different reason such as:</li>
<li>Excessive traffic on one cpu</li>
<li>Excessive traffic on one network card</li>
<li>Network card accessing memory area that is no longer assigned</li>
<li> Ring Buffer overflowing</li>
<li>drivers/net/ethernet/intel/i40e/i40e_ethtool.c:311<ul>
<li>I40E_PF_STAT(“port.rx_dropped”, stat.eth.rx_discards)</li>
</ul>
</li>
</ul>
</li>
<li>buff_alloc_err(mlx5_core)<ul>
<li>Failed to allocate a buffer to received packet (or SKB) on port (or per ring)</li>
<li>buff error</li>
</ul>
</li>
<li>rx_queue_[0-9]_drops (igb)<ul>
<li>the RX interrupts aren’t allocating buffers fast enough, resulting in the adapter dropping packets</li>
<li>buff error</li>
</ul>
</li>
<li>rx_out_of_buffer (mlx5_core)<ul>
<li>Number of times receive queue had no software buffers allocated for the adapter’s incoming traffic</li>
<li>buff error</li>
</ul>
</li>
<li>tx_restart_queue (ixgbe,igb)<ul>
<li>an informational stats about normal operation which shows the number of times the queue has stopped and started, not a error<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">e1000_adapter</span> &#123;</span></span><br><span class="line">       <span class="keyword">unsigned</span> <span class="keyword">int</span> restart_queue;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>rx_steer_missed_packets mlx5_core (too many in storage node)<ul>
<li>Number of packets that was received by the NIC, however was discarded because it did not match any flow in the NIC flow table</li>
</ul>
</li>
<li>rx_oversize_pkts_phy (mlx5_core)<ul>
<li>The number of dropped received packets due to length which exceed MTU size on a physical port, If this counter is increasing, it implies that the peer connected to the adapter has a larger MTU configured. Using same MTU configuration shall resolve this issue</li>
<li>MTU</li>
</ul>
</li>
<li>rx_err_lane_0_phy (mlx5_core)<ul>
<li>“rx_err_lane_0_phy”, PPORT_PHY_STATISTICAL_OFF(phy_corrected_bits_lane0)</li>
<li>hardware,  the compatibility between fiber optic (NIC/switch), fibre cable</li>
</ul>
</li>
<li>rx_pcs_symbol_err_phy (mlx5_core)<ul>
<li>This counter counts the number of symbol errors that wasn’t corrected by FEC correction algorithm or that FEC algorithm was not active on this interface. If this counter is increasing, it implies that the link between the NIC and the network is suffering from high BER, and that traffic is lost. You may need to replace the cable/transceiver. The error rate is the number of rx_pcs_symbol_err_phy divided by the number of rx_phy_bits on a specific time frame</li>
<li>hardware,  the compatibility between fiber optic (NIC/switch), fibre cable</li>
</ul>
</li>
<li>rx_crc_errors/rx_crc_errors_phy (mlx5_core/ixgbe/igb/mlx4_en)<ul>
<li>Number of received frames with a bad CRC that are not runts, jabbers, or alignment errors</li>
<li>The number of dropped received packets due to FCS (Frame Check Sequence) error on the physical port. If this counter is increased in high rate, check the link quality using rx_symbol_error_phy and rx_corrected_bits_phy counters below</li>
<li>hardware,  the compatibility between fiber optic (NIC/switch), fibre cable</li>
</ul>
</li>
<li>rx_symbol_err_phy (mlx5_core)<ul>
<li>The number of received packets dropped due to physical coding errors (symbol errors) on a physical port</li>
<li>hardware,  the compatibility between fiber optic (NIC/switch), fibre cable</li>
</ul>
</li>
<li>tx_discards_phy mlx5_core  link in down state<ul>
<li>The number of packets which were discarded on transmission, even no errors were detected. the drop might occur due to link in down state, head of line drop, pause from the network</li>
<li>hardware,  the compatibility between fiber optic (NIC/switch), fibre cable</li>
</ul>
</li>
<li>rx_skb_alloc_discard  bnx2x<ul>
<li>rx_skb_alloc_failed, alloc buff timeout</li>
<li>no resource</li>
</ul>
</li>
<li>rx_jabbers/rx_jabbers_phy mlx5_core<ul>
<li>Number of received frames with a length greater than MTU octets and a bad CRC.</li>
<li>The number of received packets d due to a length which is longer than 64 bytes and had FCS error on a physical port</li>
<li>hardware</li>
</ul>
</li>
<li>rx_drops_no_frags<ul>
<li>If the MTU is 9000, or greater than 2048, then increase the driver tunable setting rx_frag_size to the max size of 8192</li>
<li>echo “options be2net rx_frag_size=8192” &gt;&gt; /etc/modprobe.d/be2net.conf</li>
</ul>
</li>
<li>rx_over_errors<ul>
<li>Number of received frames that were dropped due to on hardware port receive buffer overflow.</li>
<li>no resource</li>
</ul>
</li>
<li>tx_errors<ul>
<li>Number of frames that failed to transmit. Include frame dropped due to error in the length field</li>
</ul>
</li>
<li>tx_dropped<ul>
<li>Number of transmitted frames that were dropped.</li>
</ul>
</li>
<li>vport_rx_dropped<ul>
<li>Received packets discarded due to luck of software receive buffers (WQEs).</li>
<li>Important indication to weather RX completion routines are keeping up with HW ingress packet rate.</li>
</ul>
</li>
<li>mac_filter_discards</li>
<li>rx_drops_no_pbuf</li>
<li>rx_brb_discard</li>
<li>no_buff_discards</li>
<li>tx_timeout_count</li>
<li>tx_dropped</li>
<li>rx_long_length_errors</li>
<li>rx_input_fifo_overflow_drop</li>
<li>rx_drops_no_tpre_descr</li>
<li>rx_csum_offload_errors</li>
<li>vport_rx_filtered: Received packets dropped due to packet check that was failed. For example:<ul>
<li>Incorrect VLAN</li>
<li>Incorrect Ethertype</li>
<li>unavailable queue/QP</li>
<li>Loopback prevention</li>
<li>This counter is increased at point (2) in the figure above<ul>
<li>Note: In high performance scenarios vport_rx_filters may increment due to rx_over_errors. </li>
<li>In addition,In SRIOV configurations vport_rx_filters increments can be seen and it is a normal condition (expected)</li>
</ul>
</li>
</ul>
</li>
<li>vport_tx_errors<ul>
<li>Packets dropped due to transmit errors</li>
</ul>
</li>
<li>rx_lro_aggregated<ul>
<li>The number of packets processed by the LRO (Large Receive Offload) mechanism (good for IPv4 TCP), and should be equal to rx_packets in good/normal condition.</li>
</ul>
</li>
<li>rx_lro_flushed<ul>
<li>The number of offloaded packets the LRO mechanism passed to kernel. Ideally the packet size is 64KB (depends on kernel). 64KB is the maximum packet size.</li>
</ul>
</li>
<li>rx_lro_no_desc<ul>
<li>This is abnormal condition, and mostly will not happen. The LRO mechanism has no room to receive packets from the adapter. </li>
<li>In normal condition, it should not increase, mostly when using 64 packets budget and flush LRO descriptors every NAPI cycle</li>
<li>In addition, LRO has a lot of space (much more than 64).</li>
</ul>
</li>
<li>tx_tso_packets<ul>
<li>When using TCO (TCP Segmentation Offload), it offloads tasks from the CPU and improve CPU utilization</li>
<li>This counter shows the number of offloaded TSO packets received by the driver from the TCP layer </li>
<li>The rate of TSO This counter is correlated strongly with the TX performance and CPU utilization</li>
<li>TSO is crucial for wire speed performance, and the kernel will enable it only when the CPU is not on heavy load</li>
</ul>
</li>
<li>tx_queue_stopped<ul>
<li>The number of times the kernel didn’t manage to send packets as the queue was full</li>
<li>the tx_queue_stopped and tx_wake_queue are usually equal (TX queue is stopped and later gets wake up call). </li>
<li>This is an important indication to whether TX completion routines are keeping up with the transmit routines</li>
<li>If the application is sending in an higher rate than driver is evicting CQEs from the buffer this will start to go up.</li>
</ul>
</li>
<li>tx_wake_queue<ul>
<li>The number of time the kernel got message from the adapters that there is a queue to run (tx_queue_stopped is released)</li>
<li>his is an important indication to whether TX completion routines are keeping up with the transmit routines</li>
<li>If the application is sending in an higher rate than driver is evicting CQEs from the buffer this will start to go up.</li>
</ul>
</li>
<li>tx_timeout<ul>
<li>This a rare event, that usually indicate on a severe issue. </li>
<li>It means around 15 sec timeframe that passed since a packet was sent without a CQE generated. Usually a lost interrupt or a bad cable.</li>
</ul>
</li>
<li>rx_csum_good<ul>
<li>The number of packets received with good checksum (in L4).</li>
</ul>
</li>
<li>rx_csum_none<ul>
<li>The number of packets received with no checksum (in L4).</li>
</ul>
</li>
<li>tx_cksum_offload<ul>
<li>The number of packets sent with hardware checksum.</li>
</ul>
</li>
</ul>
<h5 id="netstat-info"><a href="#netstat-info" class="headerlink" title="netstat info"></a><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/html/latest/networking/snmp_counter.html">netstat info</a></h5><ul>
<li>TCP retrans<ul>
<li>TcpExtTCPSlowStartRetrans<ul>
<li>retransmits in slow start</li>
<li>The TCP stack wants to retransmit a packet and the congestion control state is ‘Loss’</li>
</ul>
</li>
<li>TcpExtTCPFastRetrans<ul>
<li>fast retransmits</li>
<li>The TCP stack wants to retransmit a packet and the congestion control state is not ‘Loss’</li>
</ul>
</li>
<li>TcpExtTCPLostRetransmit<ul>
<li>retransmits lost</li>
<li>A SACK points out that a retransmission packet is lost again</li>
</ul>
</li>
<li>TcpExtTCPRetransFail<ul>
<li>The TCP stack tries to deliver a retransmission packet to lower layers but the lower layers return an error</li>
</ul>
</li>
<li>TcpExtTCPSynRetrans<ul>
<li>The TCP stack retransmits a SYN packet</li>
</ul>
</li>
<li>TcpRetransSegs<ul>
<li>(retrans/s) in the sar</li>
</ul>
</li>
<li>TCPDSACKUndo<ul>
<li>We detected some erroneous retransmits, a D-SACK arrived and ACK’ed all the retransmitted data, so we undid our CWND reduction<ul>
<li>times of undo_retrans == 0 in Disorder status<ul>
<li>tcp_ack() -&gt; tcp_fastretrans_alert() -&gt; tcp_try_undo_dsack()</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPPartialUndo<ul>
<li>We detected some erroneous retransmits, a partial ACK arrived while we were fast retransmitting, so we were able to partially undo some of our CWND reduction<ul>
<li>tcp_ack() -&gt; tcp_fastretrans_alert() -&gt; tcp_undo_partial()</li>
</ul>
</li>
</ul>
</li>
<li>TCPFullUndo<ul>
<li>We detected some erroneous retransmits and undid our CWND reduction<ul>
<li>tcp_ack() -&gt; tcp_fastretrans_alert() -&gt; tcp_try_undo_recovery()</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Out of order<ul>
<li>TcpExtTCPOFOQueue<ul>
<li>The TCP layer receives an out of order packet and has enough memory to queue it.</li>
</ul>
</li>
<li>TcpExtTCPOFOMerge<ul>
<li>The received out of order packet has an overlay with the previous packet. the overlay part will be dropped. <ul>
<li>All of TcpExtTCPOFOMerge packets will also be counted into TcpExtTCPOFOQueue</li>
</ul>
</li>
</ul>
</li>
<li>EstabResets , only in many clients and high value, no-one in server (out of order/retrans/high lat)<ul>
<li>connection resets received</li>
<li>connections RST count<ul>
<li>ESTABLISHED =&gt; CLOSED count</li>
<li>CLOSE-WAIT =&gt; CLOSED count<ul>
<li>tcp_set_state</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPDSACKOfoRecv<ul>
<li>DSACKs for out of order packets received</li>
</ul>
</li>
<li>TCPDSACKRecv<ul>
<li>DSACKs received, dscak number &lt; ACK number</li>
</ul>
</li>
<li>TCPDSACKOfoSent<ul>
<li>DSACKs sent for out of order packets</li>
</ul>
</li>
<li>TCPDSACKOldSent<ul>
<li>SACKs sent for old packets</li>
<li>DSACKs for out of order packets received</li>
<li>Duplicate package seq number &lt; rcv_nxt (next want to receive number), is the oldsent</li>
</ul>
</li>
<li>TCPFACKReorder<ul>
<li>Detected reordering %llu times using FACK</li>
<li>We detected re-ordering using FACK Forward ACK, the highest sequence number known to have been received by the peer when using SACK. <ul>
<li>FACK is used during congestion control</li>
</ul>
</li>
</ul>
</li>
<li>TCPSACKReorder<ul>
<li>Detected reordering %llu times using SACK</li>
<li>We detected re-ordering using SACK</li>
</ul>
</li>
<li>TCPRenoReorder<ul>
<li>not support SACK</li>
<li>Detected reordering %llu times using reno fast retransmit</li>
<li>We detected re-ordering using fast retransmit</li>
</ul>
</li>
<li>TCPTSReorder<ul>
<li>Detected reordering %llu times using time stamp</li>
<li>We detected re-ordering using the timestamp option</li>
</ul>
</li>
</ul>
</li>
<li>invalid SACK and DSACK<ul>
<li>TcpExtTCPSACKDiscard<ul>
<li>SACK block and discarded it</li>
<li>This counter indicates how many SACK blocks are invalid. <ul>
<li>If the invalid SACK block is caused by ACK recording(reordering ?), the TCP stack will only ignore it and won’t update this counter.</li>
</ul>
</li>
<li>tcp_clean_rtx_queue</li>
</ul>
</li>
<li>TcpExtTCPDSACKIgnoredOld(DSACKs sent for old packets) and TcpExtTCPDSACKIgnoredNoUndo(We got a duplicate SACK and discarded it)<ul>
<li>When a DSACK block is invalid, one of these two counters would be updated. </li>
<li>Which counter will be updated depends on the undo_marker flag of the TCP socket. <ul>
<li>If the undo_marker is not set, the TCP stack isn’t likely to re-transmit any packets, and we still receive an invalid DSACK block, <ul>
<li>the reason might be that the packet is duplicated in the middle of the network. </li>
</ul>
</li>
<li>In such scenario, TcpExtTCPDSACKIgnoredNoUndo will be updated. <ul>
<li>If the undo_marker is set, TcpExtTCPDSACKIgnoredOld will be updated. As implied in its name, it might be an old packet.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPPureAcks<ul>
<li>acknowledgments not containing data payload received<ul>
<li>pure ack from tcp slow path<ul>
<li>tcp_ack</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>SACK shift<ul>
<li>TcpExtTCPSackShiftFallback<ul>
<li>A skb should be shifted or merged, but the TCP stack doesn’t do it for some reasons.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCP PAWS (Protection Against Wrapped Sequence numbers)<ul>
<li>tcp_delack_timer<ul>
<li>RHEL7 40~200ms</li>
</ul>
</li>
<li>PAWSPassive<ul>
<li>number of passive connections rejected because of timestamp</li>
<li>Remove tcp_tw_recycle, since it is not functional. Also, remove the PAWSPassive SNMP counter since it is only used for tcp_tw_recycle<ul>
<li>In the tcp handshake, the last ack PAWS failed count</li>
<li>tcp_v4_conn_request</li>
</ul>
</li>
</ul>
</li>
<li>TcpExtPAWSActive<ul>
<li>number of active connections rejected because of timestamp<ul>
<li>Packets are dropped by PAWS in Syn-Sent status.</li>
</ul>
</li>
</ul>
</li>
<li>TcpExtPAWSEstab<ul>
<li>packets rejects in established connections because of timestamp</li>
<li>Packets are dropped by PAWS in any status other than Syn-Sent.</li>
</ul>
</li>
</ul>
</li>
<li>TCP receive window<ul>
<li>Depending on current memory usage, the TCP stack tries to set receive window to zero. <ul>
<li>But the receive window might still be a no-zero value. <ul>
<li>For example, if the previous window size is 10, and the TCP stack receives 3 bytes, </li>
<li>the current window size would be 7 even if the window size calculated by the memory usage is zero.</li>
</ul>
</li>
</ul>
</li>
<li>TcpExtTCPToZeroWindowAdv<ul>
<li>The TCP receive window is set to zero from a no-zero value.</li>
</ul>
</li>
</ul>
</li>
<li>TCP Fast Open description<ul>
<li>TcpExtTCPFastOpenActiveFail<ul>
<li>This counter indicates that the TCP stack initiated a TCP Fast Open, but it failed. This counter would be updated in three scenarios: (1) the other side doesn’t acknowledge the data in the SYN packet. (2) The SYN packet which has the TFO cookie is timeout at least once. (3) after the 3-way handshake, the retransmission timeout happens net.ipv4.tcp_retries1 times, because some middle-boxes may black-hole fast open after the handshake.</li>
</ul>
</li>
<li>TcpExtTCPFastOpenPassiveFail<ul>
<li>This counter indicates how many times the TCP stack rejects the fast open request. It is caused by either the TFO cookie is invalid or the TCP stack finds an error during the socket creating process.</li>
</ul>
</li>
<li>TcpExtTCPFastOpenListenOverflow<ul>
<li>When the pending fast open request number is larger than fastopenq-&gt;max_qlen, the TCP stack will reject the fast open request and update this counter</li>
</ul>
</li>
</ul>
</li>
<li>Backlog<ul>
<li>TCPBacklogDrop<ul>
<li>We received something but had to drop it because the socket’s receive queue was full<ul>
<li>user lock the scoket buf add the package to sk_backlog_queue, no enough sk_rcv_buf cause dropped<ul>
<li>tcp_v4_rcv , ./net/ipv4/tcp_ipv4.c:1745:              NET_INC_STATS_BH(net, LINUX_MIB_TCPBACKLOGDROP);<ul>
<li>goto discard_and_relse</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Accept queue overflow , min(acceptcount,somaxconn)<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (unlikely(sk_add_backlog(sk, skb,</span><br><span class="line">                                           sk-&gt;sk_rcvbuf + sk-&gt;sk_sndbuf))) &#123; \\sk_add_backlog failed</span><br><span class="line">                bh_unlock_sock(sk);</span><br><span class="line">                NET_INC_STATS_BH(net, LINUX_MIB_TCPBACKLOGDROP);</span><br><span class="line">                <span class="keyword">goto</span> discard_and_relse;</span><br><span class="line"></span><br><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/include/net/sock.h</span><br><span class="line"><span class="comment">/* The per-socket spinlock must be held here. */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> __must_check <span class="keyword">int</span> <span class="title">sk_add_backlog</span><span class="params">(struct sock *sk, struct sk_buff *skb,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="keyword">unsigned</span> <span class="keyword">int</span> limit)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (sk_rcvqueues_full(sk, skb, limit))</span><br><span class="line">                <span class="keyword">return</span> -ENOBUFS;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * If the skb was allocated from pfmemalloc reserves, only</span></span><br><span class="line"><span class="comment">         * allow SOCK_MEMALLOC sockets to use it as this socket is</span></span><br><span class="line"><span class="comment">         * helping free memory</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (skb_pfmemalloc(skb) &amp;&amp; !sock_flag(sk, SOCK_MEMALLOC))</span><br><span class="line">                <span class="keyword">return</span> -ENOMEM;</span><br><span class="line"></span><br><span class="line">        __sk_add_backlog(sk, skb);</span><br><span class="line">        sk-&gt;sk_backlog.len += skb-&gt;truesize;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>TCPDeferAcceptDrop<ul>
<li>tcp_check_req</li>
<li>When the socket in SYN_RECV state is trying to complete the 3 way handshake, it receives a final ACK before the connection goes to established state.<ul>
<li>This counter will be seen if an application has set TCP_DEFER_ACCEPT on its listening socket</li>
<li>If the socket has had TCP_DEFER_ACCEPT set, and the ACK carries no data, then the ACK packet is dropped and the TCPDeferAcceptDrop counter is incremented</li>
<li>The socket remains in SYN_RECV state until data arrives. It is not uncommon for at least one such pure ACK to be received.</li>
</ul>
</li>
</ul>
</li>
<li>SYN cookies, SYN cookies are used to mitigate SYN flood</li>
<li>TCPReqQFullDoCookies<ul>
<li>syn table overloading, SYN cookie count, tcp_syncookies</li>
<li>tcp_rcv_state_process() -&gt; tcp_v4_conn_request() -&gt; tcp_syn_flood_action()</li>
</ul>
</li>
<li>TCPReqQFullDrop<ul>
<li>syn_table overloading, discard SYN counts</li>
<li>tcp_rcv_state_process() -&gt; tcp_v4_conn_request() -&gt; tcp_syn_flood_action()</li>
</ul>
</li>
<li>ListenDrops<ul>
<li>of SYNs to LISTEN sockets dropped<ul>
<li>tcp_v4_syn_recv_sock()<ul>
<li>we had no route to the destination</li>
<li>we failed to allocate a socket</li>
<li>we failed to allocate a new local port bind bucket</li>
<li>somaxconn</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>ListenOverflows<ul>
<li>times the listen queue of a socket overflowed<ul>
<li>TCP handshakes cancelled by an ICMP error message</li>
<li>SYN packets received on broadcast or multicast addresses </li>
<li>a full accept queue  with TcpExtListenOverflows count increased</li>
<li>a full SYN queue and fallback to SYN cookies disabled and increases TcpExtTCPReqQFullDrop counter</li>
<li>We completed a 3WHS but couldn’t put the socket on the accept queue, so we had to discard the connection<ul>
<li>tcp_v4_syn_recv_sock() and tcp_v4_conn_request()</li>
<li>linux-3.10.0-1127.el7/net/ipv4/tcp.c:2704</li>
<li>listen backlog full, somaxconn , Limit of socket listen() backlog, known in userspace as SOMAXCONN.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>OfoPruned (critical)<ul>
<li>packets dropped from out-of-order queue because of socket buffer overrun</li>
<li>When a socket is using too much memory (rmem), the kernel will first discard any out-of-order packet that has been queued (with SACK)<ul>
<li>In the tcp slow path could not copy data to user space, add it to sk_receive_queue, <ul>
<li>if no enough rcv_buf, prune out of order queue count, add 1, like to trigger the GC</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>locked by user <ul>
<li>DelayedACKLocked, too many clients(The TCP Delayed ACK is a technique which is used for reducing the packet count in the network)<ul>
<li>number of packets rejects in ESTABLISHED connections because of timestamp</li>
<li>We wanted to send a delayed ACK but failed because the socket was locked. So the timer was reset.</li>
<li>The TCP stack will send a pure ACK later (after the userspace program unlock the socket).</li>
<li>When the TCP stack sends the pure ACK later, the TCP stack will also update TcpExtDelayedACKs and exit the delayed ACK mode.</li>
</ul>
</li>
<li>DelayedACKLost , too many clients<ul>
<li>Quick ack mode was activated <num> times</li>
<li>We sent a delayed and duplicated ACK because the remote peer retransmitted a packet, thinking that it didn’t get to us.<ul>
<li>the package not in the window or PAWS failed add1<ul>
<li>tcp_validate_incoming()-&gt;tcp_send_dupack()</li>
</ul>
</li>
</ul>
</li>
<li>the end sequence number of the package &lt; RCV_NXT<ul>
<li>tcp_data_queue</li>
</ul>
</li>
<li>It will be updated when the TCP stack receives a packet which has been ACKed. <ul>
<li>A Delayed ACK loss might cause this issue, but it would also be triggered by other reasons, such as a packet is duplicated in the network.</li>
</ul>
</li>
</ul>
</li>
<li>LockDroppedIcmps<ul>
<li>number of ICMP packets dropped because socket was locked<ul>
<li>socket buff lock by usespace app<ul>
<li>tcp_v4_err ??</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPAbortOnClose ,in many clients, no-one in server<ul>
<li>connections reset due to early user close</li>
<li>We received data but the user has closed the socket, so we have no wait of handing it to them, so we RST’ed.</li>
<li>tcp_close the socket, recv buff has the data, send a RST to the another side activly</li>
</ul>
</li>
<li>TCPSchedulerFailed (the user app) , some of clients, low value<ul>
<li>times receiver scheduled too late for direct processing</li>
<li>In the delay ACK, add to the prequeue for tcp_recvmsg to process, but add prequeue timeout or no enough buff cause failed, maybe it the user app too bad<ul>
<li>tcp_delack_timer</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>AttemptFails<ul>
<li>failed connection attempts<ul>
<li>SYN-SENT =&gt; CLOSED failed count + SYN-RECV =&gt; CLOSED failed count + SYN-RECV =&gt; LISTEN failed count</li>
</ul>
</li>
</ul>
</li>
<li>ArpFilter<ul>
<li>route mapping (sip,tip), if route device diff with input device, add 1</li>
<li>ArpFilter arp_rcv() -&gt; NETFILTER(ARP_IN) -&gt; arp_process()<ul>
<li>CLOSED in tcp_done()</li>
<li>LISTEN in tcp_check_req()</li>
</ul>
</li>
</ul>
</li>
<li>TCPLossUndo<ul>
<li>congestion windows recovered without slow start after partial ack<ul>
<li>We detected some erroneous retransmits, a partial ACK arrived, so we undid our CWND reduction<ul>
<li>tcp_ack() -&gt; tcp_fastretrans_alert() -&gt; tcp_try_undo_loss()</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>OutOfWindowIcmps<ul>
<li>number of ICMP packets dropped because they were out-of-window<ul>
<li>ICMP seq number not in the receive window ??<ul>
<li>tcp_v4_err</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPMD5NotFound</li>
<li>TCPMD5Unexpected</li>
<li>RTO (critical) The heavy impact the performance becasue RTO, TLP reduce the TCPTimeouts because fast retrans<ul>
<li>TCPTimeouts<ul>
<li>other TCP timeouts</li>
<li>RTO timer, The CWR/Open status first timeout count</li>
<li>SYN,ACK time count</li>
</ul>
</li>
<li>TCPSpuriousRTOs</li>
<li>TCPLossProbes<ul>
<li>net.ipv4.tcp_early_retrans=3(default)<ul>
<li>Tail loss probe (TLP) converts RTOs occurring due to tail losses into fast recovery (draft-ietf-tcpm-rack). </li>
<li>Note that TLP requires RACK to function properly (see tcp_recovery below) Possible values: 0 disables TLP 3 or 4 enables TLP Default: 3<ul>
<li><a target="_blank" rel="noopener" href="http://perthcharles.github.io/2015/10/31/wiki-network-tcp-tlp/">http://perthcharles.github.io/2015/10/31/wiki-network-tcp-tlp/</a></li>
</ul>
</li>
</ul>
</li>
<li>Probe Timeout(PTO) casue Tail Loss Probe (TLP) count<ul>
<li>TLP算法会在TCP还是Open状态的时候，设置一个Probe TimeOut (PTO)。 当链路中有未被确认的数据包，同时在PTO时间内未收到任何ACK，则会触发PTO. </li>
<li>TLP会选择传输序号最大的一个数据&gt;包作为tail loss probe包，这个序号最大的包可能是一个可以发送的新的数据包，也可能是一个重传包。</li>
<li>TLP通过这样一个tail loss probe包，如果能够收到相应的ACK，则会触发FR机制，而不是RTO机制。</li>
<li>Tail loss probe (TLP)利用RACK减少RTO的发生，TLP触发快速恢复以修复末端丢包，否则只能由之后的RTO来修复。</li>
<li>在原始报文发送之后，TLP将在1到2倍的RTT时间内发送探测数据报文，探测报文可以是新的、之前非发送过的报文，或者重传SND.NXT序号之前已经发送过的报文。</li>
<li>探测报文的发送旨在激起对端的反馈，例如ACK报文，这样RACK就可以发起快速重传，而不用等待RTO超时。</li>
</ul>
</li>
</ul>
</li>
<li>TCPLossProbeRecovery , many clients and many servers<ul>
<li>TLP probe recovery times</li>
</ul>
</li>
<li>TCPRenoRecoveryFail<ul>
<li>classic Reno fast retransmits failed</li>
<li>In the recovery status, RTO count, the other side not support SACK</li>
</ul>
</li>
<li>TCPSACKRecoveryFail , many clients and many servers<ul>
<li>SACK retransmits failed</li>
<li>In the recovery status, RTO count, the other side support SACK</li>
</ul>
</li>
<li>TCPRenoFailures<ul>
<li>timeouts after reno fast retransmit</li>
<li>In the TCP_CA_Disorder status, RTO count, another side not support SACK</li>
</ul>
</li>
<li>TCPSackFailures<ul>
<li>timeouts after SACK recovery</li>
<li>In the TCP_CA_Disorder status, RTO count, another side support SACK</li>
</ul>
</li>
<li>TCPLossFailures<ul>
<li>timeouts in loss state</li>
<li>In the TCP TCP_CA_Loss status, RTO count</li>
</ul>
</li>
</ul>
</li>
<li>Memory<ul>
<li>TcpExtTCPOFODrop<ul>
<li>The TCP layer receives an out of order packet but doesn’t have enough memory, so drops it. Such packets won’t be counted into TcpExtTCPOFOQueue.</li>
</ul>
</li>
<li>TCPMemoryPressures<ul>
<li>TCP ran low on memory %llu times</li>
<li>Number of times a socket was put in “memory pressure” due to a non fatal memory allocation failure</li>
<li>tcp_enter_memory_pressure high stress add 1<ul>
<li>tcp_sendmsg</li>
<li>tcp_sendpage</li>
<li>tcp_fragment</li>
<li>tso_fragment</li>
<li>tcp_mtu_probe</li>
<li>tcp_data_queue</li>
</ul>
</li>
</ul>
</li>
<li>RcvPruned (critical), too many client, not in server with old parameters(modified recv buff)<ul>
<li>packets pruned from receive queue</li>
<li>Number of packets pruned from receive queue because of socket buffer overrun</li>
<li>If the kernel is really really desperate and cannot give more memory to this socket even after dropping the ofo queue, <ul>
<li>it will simply discard the packet it received. This is Really Bad</li>
</ul>
</li>
</ul>
</li>
<li>PruneCalled (critical) too many in client, not too high value,little in 5 server(modified)<ul>
<li>packets pruned from receive queue because of socket buffer overrun<ul>
<li>In the tcp slow path could not copy data to user space, add it to sk_receive_queue, if no enough rcv_buf go to prune queue. like to trigger the GC</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Abort is the bad status<ul>
<li>TCPAbortFailed (critical) little client<ul>
<li>times unable to send RST due to no memory</li>
<li>We tried to send a RST, probably during one of the TCPABort* situations above, but we failed e.g. because we couldn’t allocate enough memory (very bad).</li>
</ul>
</li>
<li>TCPAbortOnLinger<ul>
<li>connections aborted after user close in linger timeout</li>
<li>We killed a socket that was closed by the application and lingered around for long enough.</li>
<li>tcp_close() tp-&gt;linger2 set &lt; 0 cause FIN_WAIT2 switch to CLOSED count</li>
</ul>
</li>
<li>TCPAbortOnTimeout , in many clients and low value, no-one in server<ul>
<li>connections aborted due to timeout</li>
<li>The connection timed out really hard<ul>
<li>reach the RTO/PTO/keepalive upper limit, close the connection, add 1</li>
</ul>
</li>
</ul>
</li>
<li>TCPAbortOnMemory(critical) , in many clients and low to high value, no-one in server<ul>
<li>connections aborted due to timeout</li>
<li>This is Really Bad. It happens when there are too many orphaned sockets (not attached a FD) and the kernel has to drop a connection. Sometimes it will send a RST to the peer, sometimes it wont.</li>
<li>orphan socket or tcp_memory_allocated upper the limit, add 1</li>
</ul>
</li>
<li>TCPAbortOnData , in many clients and and high value, no-one in server<ul>
<li>connections reset due to unexpected data</li>
<li>We were in FIN_WAIT_1 yet we received a data packet with a sequence number that’s beyond the last one for this connection, so we RST’ed.<ul>
<li>Keep receive the data in the FIN_WAIT1/FIN_WAIT2/TCP_LINGER2&lt;0, send the RST to another side</li>
</ul>
</li>
</ul>
</li>
<li>TCPAbortOnSyn<ul>
<li>connections reset due to unexpected SYN</li>
<li>We received an unexpected SYN so we sent a RST to the peer</li>
<li>received the unexpect SYN package, send the RST direct<ul>
<li>timestamps issue, pass the multiple NAT, these clients use the same public ipaddr</li>
</ul>
</li>
</ul>
</li>
<li>TCPTimeWaitOverflow<ul>
<li>the kernel could not malloc the new tcp_timewait_socket or tw_count(scheduled timewait sockets) &gt; tcp_max_tw_buckets, add 1</li>
</ul>
</li>
</ul>
</li>
<li>Syncookies<ul>
<li>SyncookiesSent (critical)<ul>
<li>SYN cookies sent (syncookie transmit syncookie value SYN/ACK count)</li>
<li>An application wasn’t able to accept a connection fast enough, so the kernel couldn’t store an entry in the queue for this connection. Instead of dropping it, it sent a cookie to the client</li>
<li>ipv4/syncookies.c-&gt;EXPORT_SYMBOL_GPL-&gt;tcp_synq_overflow(sk);NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_SYNCOOKIESSENT);</li>
</ul>
</li>
<li>SyncookiesRecv (critical) , 1 x client (maybe critical, syn_backlog full,eg: SYN flood attack)<ul>
<li>SYN cookies received</li>
<li>After sending a cookie, it came back to us and passed the check.</li>
<li>received worked syncookies packages count</li>
</ul>
</li>
<li>SyncookiesFailed , too many clients<ul>
<li>The MSS decoded from the SYN cookie is invalid</li>
<li>但是 SyncookiesFailed 值即使SYN Cookies 机制没有被触发，也很可能不为0。</li>
<li>这是因为一个处于 LISTEN 状态的 socket 收到一个不带 SYN 标记的数据包时，就会调 用 cookie_v4_check() 尝试验证 cookie 信息。 而如果验证失败，SyncookiesFailed 次数就加1。</li>
<li><num> invalid SYN cookies received</li>
<li>After sending a cookie, it came back to us but looked invalid<ul>
<li>invalid syncookies packages count</li>
<li>cookie_v4_check net/ipv4/syncookies.c<figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">             -----------------Does recent overflow requiring SYN cookies within the time range(<span class="number">2</span> mins ? ) ?, goto complete handshake</span><br><span class="line">             <span class="pattern-match">|                                --------<span class="constructor">The</span> cookie fails <span class="keyword">to</span> checks out <span class="keyword">as</span> a valid regular <span class="constructor">SYN</span> packet <span class="keyword">or</span> <span class="constructor">SYN</span> cookie</span></span><br><span class="line"><span class="pattern-match">             |                                |</span></span><br><span class="line"><span class="pattern-match"><span class="keyword">if</span> (tcp<span class="constructor">_synq_no_recent_overflow(<span class="params">sk</span>)</span> <span class="operator">||</span>        |</span></span><br><span class="line"><span class="pattern-match">    (mss = <span class="constructor">__cookie_v4_check(<span class="params">ip_hdr</span>(<span class="params">skb</span>)</span>, th, cookie)) <span class="operator">==</span> 0) &#123;</span></span><br><span class="line"><span class="pattern-match">        <span class="constructor">NET_INC_STATS_BH(<span class="params">sock_net</span>(<span class="params">sk</span>)</span>, <span class="constructor">LINUX_MIB_SYNCOOKIESFAILED</span>);</span></span><br><span class="line"><span class="pattern-match">        goto out;</span></span><br><span class="line"><span class="pattern-match">&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Recovery, TCPRenoRecovery(much smaller than) &lt; SackRecovery<ul>
<li>TCPSackRecoveryFail , many clients and servers<ul>
<li>SACK retransmits failed</li>
<li>After recovery, RTO count, another side not support SACK</li>
</ul>
</li>
<li>TCPRenoRecoveryFail<ul>
<li>classic Reno fast retransmits failed</li>
<li>After recovery, RTO count, another side support SACK</li>
</ul>
</li>
<li>TCPSackRecovery(TCP Selective Acknowledgements (SACK))<ul>
<li>times recovered from packet loss by selective acknowledgements</li>
<li>selective acknowledgements will use the ACK number in the TCP header to indicate which packet was lost. <ul>
<li>At the same time, in these ACK packets<ul>
<li>the receiver can use the SACK option in the TCP header to show which packets have been successfully received after the point of loss.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TCPRenoRecovery<ul>
<li>times recovered from packet loss due to fast retransmit</li>
<li>A packet was lost and we recovered after a fast retransmit</li>
</ul>
</li>
</ul>
</li>
<li>TIMEWAIT<br>-TW  , many clients<ul>
<li>TCP sockets finished time wait in fast timer<ul>
<li>after the TCP_TIMEWAIT_LEN, the TIMEWAIT socket number</li>
<li>TWRecycled ,  many clients</li>
</ul>
</li>
<li>time wait sockets recycled by time stamp<ul>
<li>when a connection is reused (net.ipv4.tcp_tw_reuse = 1), the TWRecycled counter is increased</li>
</ul>
</li>
<li>TIME-WAIT socket reuse count(must net.ipv4.tcp_tw_reuse=1)<ul>
<li>TWKilled</li>
</ul>
</li>
<li>number of TCP sockets finished time wait in slow timer</li>
<li>tcp_tw_recycle enabled</li>
<li>killed TW status socket count</li>
</ul>
</li>
<li>FastOpen<ul>
<li>TCPFastOpenActive<ul>
<li>number of successful outbound TFO connections, activly transmit TFO cookie SYN packages</li>
</ul>
</li>
<li>TCPFastOpenActiveFail<ul>
<li>number of SYN,ACK packets received that did not acknowledge data sent in the SYN packet and caused a retransmissions without SYN data. </li>
<li>Note that the original SYN packet contained a cookie + data, this is not the number of connections to servers that didn’t support TFO</li>
</ul>
</li>
<li>TCPFastOpenPassive<ul>
<li>number of successful inbound TFO connections, passive received TFO sookie SYN packages</li>
</ul>
</li>
<li>TCPFastOpenPassiveFail<ul>
<li>number of inbound SYN packets with TFO cookie that was invalid</li>
</ul>
</li>
<li>TCPFastOpenListenOverflow<ul>
<li>number of inbound SYN packets that will have TFO disabled because the socket has exceeded the max queue length</li>
</ul>
</li>
<li>TCPFastOpenCookieReqd<ul>
<li>number of inbound SYN packets requesting TFO with TFO set but no cookie</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The backlog argument defines the maximum length to which the queue of pending connections for sockfd may grow. If a connection request arrives when the queue is full, the client  may receive an error with an indication of ECONNREFUSED or, if the underlying protocol supports retransmission, the request may be ignored so that a later reattempt at connection succeeds(man 2 listen)    </p>
<p>When the tcp_max_syn_backlog full will trigger SyncookiesSent and SyncookiesRecv increase. The SyncookiesFailed LISTEN status socket received a NON-SYN package will add 1 (cookie_v4_check)   </p>
<p>在 3.10 内核中，TFO 由 net.ipv4.tcp_fastopen 开关控制，默认值为 0(关闭)。而且 net.ipv4.tcp_fastopen 目前也是推荐关闭的，因为网络中有些 middle box 会丢弃那些带有不认识 option 的 SYN 包；所以正常情况下，这些值也应该都是 0 ，当然如果收到过某些不怀好意的、带 TFO cookies 信息的 SYN 包，TCPFastOpenPassive 计数器就可能不为 0 。<br>TCP FastOpen (TFO) 技术是 Google 提出来减少三次握手开销的技术，核心原理就是在第一次建链时，由 server 计算出一个 cookies 发给 client ，之后 client 向 server 再次发起建链请求&gt;时，就可以携带该 cookies 信息以验明正身。如果 cookies 验证通过，则 server 可以不等三次握手的最后一个 ACK 包，就将 client 放在 SYN 包里面的数据传递给应用层。   </p>
<p>在TCP套接口接收数据过程中，如果套接口接收缓存已经大于限定的套接口缓存限值，或者TCP系统占用的缓存已超过限定的总阈值，内核将使用tcp_prune_queue函数尝试回收接收队列占用的缓存。首先使用tcp_collapse_ofo_queue函数尝试合并out_of_order_queue队列中的重复数据，之后使用tcp_collapse函数尝试将sk_receive_queue队列中的数据折叠到少量的skb结构中；最后如果接收缓存还是占用过高，调用函数tcp_prune_ofo_queue删除out_of_order_queue队列中的数据包。<br>When the kernel socket buffer is nearing its max size, a procedure called “collapsing” is performed, which is sort of like garbage collection. The kernel tries to identify segments in the buffer that has identical metadata, and tries to combine them, so as to not have identical metadata filling up the buffer. The size of the buffer should be large enough to avoid collapsing to happen too often, but small enough so that when it does happen it won’t block other operations for too long.     </p>
<p>Pruning<br>When no more collapsing can happen, the “pruning” process starts. Pruning is the act of dropping new packets, since they can’t fit in the buffer.<br>This is a kind of house-keeping where the kernel will try the free space in the receive queue by reducing overhead. However, this operation comes at a CPU cost. If collapsing fails to free sufficient space for additional traffic, then data is “pruned”, meaning the data is dropped from memory and the packet is lost. Therefore, it best to tune around this condition and avoid the buffer collapsing and pruning altogether. The first step is to identify whether buffer collapsing and pruning is occurring.    </p>
<p>TcpAttemptFails/TCPLossFailures/TCPLossProbeRecovery/TCPSackRecoveryFail/TCPPartialUndo/TCPPrequeued</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## retrans/OFO/the others</span></span><br><span class="line">$ nstat -sz | grep -Ei <span class="string">&#x27;LostRetransmit|RetransFail|SynRetrans|SACKUndo|PartialUndo|FullUndo|OFOMerge|EstabResets|SACKOfoRecv|SACKOfoSent|SACKOldSent|SACKDiscard|TCPToZeroWindowAdv|AbortOnData|AbortOnSyn|TCPRcvCollapsed&#x27;</span></span><br><span class="line">You could add SackShiftFallback/PureAcks/TcpRetransSegs/TCPLossProbes/TCPLossUndo <span class="keyword">for</span> another details</span><br><span class="line"></span><br><span class="line">TcpEstabResets                  266                0.0</span><br><span class="line">TcpExtTCPFullUndo               237650             0.0</span><br><span class="line">TcpExtTCPPartialUndo            170004             0.0</span><br><span class="line">TcpExtTCPDSACKUndo              640914             0.0</span><br><span class="line">TcpExtTCPLostRetransmit         1438808            0.0</span><br><span class="line">TcpExtTCPRcvCollapsed           0                  0.0  ---&gt; </span><br><span class="line">TcpExtTCPDSACKOldSent           3677875            0.0</span><br><span class="line">TcpExtTCPDSACKOfoSent           1364               0.0</span><br><span class="line">TcpExtTCPDSACKOfoRecv           18174              0.0</span><br><span class="line">TcpExtTCPAbortOnData            222                0.0</span><br><span class="line">TcpExtTCPSACKDiscard            0                  0.0  ---&gt;</span><br><span class="line">TcpExtTCPRetransFail            807697             0.0</span><br><span class="line">TcpExtTCPOFOMerge               1363               0.0</span><br><span class="line">TcpExtTCPToZeroWindowAdv        0                  0.0  ---&gt;</span><br><span class="line">TcpExtTCPSynRetrans             61                 0.0</span><br><span class="line">bond0: flags=5187&lt;UP,BROADCAST,RUNNING,MASTER,MULTICAST&gt;  mtu 9000</span><br><span class="line">        inet 10.53.129.225  netmask 255.255.255.0  broadcast 10.53.129.255</span><br><span class="line">        inet6 fe80::ec4:7aff:fe88:ca8  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 0c:c4:7a:88:0c:a8  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 65218806861  bytes 433177102002054 (393.9 TiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 62993869401  bytes 376245783666417 (342.1 TiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## backlog/memory</span></span><br><span class="line">$ nstat -sz | grep -Ei <span class="string">&#x27;TCPBacklogDrop|TCPDeferAcceptDrop|FullDoCookies|QFullDrop|ListenDrops|ListenOverflows|OfoPruned|OFODrop|MemoryPressures|RcvPruned|PruneCalled|AbortFailed|AbortOnLinger|AbortOnMemory|TimeWaitOverflow|SyncookiesSent|SyncookiesRecv&#x27;</span></span><br><span class="line"><span class="keyword">for</span> more, add TCPTimeouts/TCPAbortOnTimeout/SyncookiesFaile, sometimes, you could add them   </span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://ylgrgyq.github.io/2017/08/01/linux-receive-packet-3/">prequeue(net.ipv4.tcp_low_latency=1)</a> Will it outdate ?   </p>
<ul>
<li>TCPPrequeueDropped<ul>
<li>packets dropped from prequeue</li>
<li>ucopy.memory &lt; sk-&gt;rcv_buf cause prequeue failed, goto backlog, add 1<ul>
<li>tcp_v4_rcv() -&gt; tcp_prequeue()<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">linux<span class="number">-3.10</span><span class="number">.0</span><span class="number">-1127.</span>el7/net/ipv4/tcp_ipv4.c</span><br><span class="line">                <span class="keyword">while</span> ((skb1 = __skb_dequeue(&amp;tp-&gt;ucopy.prequeue)) != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                        sk_backlog_rcv(sk, skb1);</span><br><span class="line">                       NET_INC_STATS_BH(sock_net(sk),</span><br><span class="line">                                         LINUX_MIB_TCPPREQUEUEDROPPED);</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li>TCPRcvCollapsed<ul>
<li>packets collapsed in receive queue due to low socket buffer<ul>
<li>tcp_prune_queue() -&gt; tcp_collapse() -&gt; tcp_collapse_one()</li>
<li>tcp_prune_ofo_queue() -&gt; tcp_collapse()</li>
</ul>
</li>
</ul>
</li>
<li>TCPPrequeueDropped ucopy.memory &lt; sk-&gt;rcv_buf prequeue failed<ul>
<li>packets dropped from prequeue</li>
<li>tcp_v4_rcv() -&gt; tcp_prequeue()</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/moooofly/MarkSomethingDown/blob/master/Linux/TCP%20%E7%9B%B8%E5%85%B3%E7%BB%9F%E8%AE%A1%E4%BF%A1%E6%81%AF%E8%AF%A6%E8%A7%A3.md">nstat and netstat</a><br><a target="_blank" rel="noopener" href="https://github.com/ecki/net-tools/blob/6cd51595e0b6d1fd679f77b0d8c3d7c5bc6f91a8/statistics.c">netstat.c</a></p>
<h5 id="TCP-fast-retrans"><a href="#TCP-fast-retrans" class="headerlink" title="TCP fast retrans"></a><a target="_blank" rel="noopener" href="http://www.ietf.org/rfc/rfc2581.txt">TCP fast retrans</a></h5><p>—- important —- ???<br>twice duplicated ACK because package out of order<br>Dropped packages must be triple duplicated ACK</p>
<p>If A send 4 TCP segments to B, Number is as follow, N-1 reache B because A received ACK(N) of B, As the order, The received ACK number:<br>                  A ———&gt; B<br>A send order was N-1,N,N+1,N+2<br>B received order<br>N-1，N，N+1，N+2<br>A received single ACK (N)<br>N-1，N，N+2，N+1<br>A received single ACK (N)<br>N-1，N+1，N，N+2<br>A received twice ACK (N)<br>N-1，N+1，N+2，N<br>A received triple ACK (N)<br>N-1，N+2，N，N+1<br>A received twice ACK (N)<br>N-1，N+2，N+1，N<br>A received triple ACK (N)<br>If N loss, or not reach B<br>N-1，N+1，N+2<br>A received triple ACK (N)<br>N-1，N+2，N+1<br>A received triple ACK (N)</p>
<p>TCP segment out of order, there are 2/5 = 40% cause A received triple duplicated ACK(N);<br>If N loss, the ratio is 100%<br>When A received triple duplicated ACK(N) and start a Fast Retransmit is OK , retransmit N right now, It ‘s need to Fast Recovery, for reduce the package loss problem<br>If A receive twice duplicated ACK(N),It ‘s must be out of order that means all packages has reach B, Just re-sort all packages, Don’ t need to retrans.</p>
<h5 id="ABout-TCP-segment-out-of-order"><a href="#ABout-TCP-segment-out-of-order" class="headerlink" title="ABout TCP segment out of order"></a>ABout TCP segment out of order</h5><p>—- important —- ???<br>TCP segment packing in IP packages，If IP package out of order,also tcp</p>
<ul>
<li>ECMP loading balance</li>
</ul>
<p>multiple path loading balance, base per-packet load balance，eg: packet 1,3,5 go path1, packet 2,4,6 go to path2, it’s hard to control packet 1 arrived early than packet 2 reach the destination</p>
<p>Per-session load balance base TCP 5 tuple(source ip,source port,des ip,des port, transfer protocol), the same TCP session will go to a same path</p>
<ul>
<li>route internal traffic scheduling<br>There are multiple traffic process unit in some of route(stream process unit),eg: packet 1,3,5 process by unit1, packet 2,4,6 process by unit2, it’s hard to control packet 1 arrived early than packet 2 reach the destination</li>
</ul>
<p>kernel receive out of order TCP segment, put them to buffer and then all TCP segment has arrived, after re-sort, send all data to application<br>Out of order segment will cause buffer consumption, direct trigger B advertised window size be samller, cause send A window get smaller and smaller,to impact sender’s transmission performance.</p>
<p>If A not do fast retrans，at last it will be retrans by retransmit timer timeout(timeout retransmit),but at this time there is a little winodow size in A, sender A ‘s transmission speed will be too bad.</p>
<p>Before there is no fast retransmit/recovery, retrans by sender ‘s retransmit timeout,In timeout range, if sender not receive receiver’s ack hat means the package loss, sender will resend it.</p>
<ul>
<li>Why package loss<ul>
<li>package checksum error</li>
<li>Traffic jam/Network congestion</li>
<li>Network connection loss for some unknow reason</li>
<li>Some of convergence-algorithm in your route</li>
</ul>
</li>
</ul>
<p>But sender don ‘t know what the situation,<br>The stupid way is sender set half of speed(CWND=1/2),It ‘s good at traffic jam,if connection loss, all packages will loss no matter sender slowing down,For checksum erorr,loss packages is a happenstance.If I loss a package, sender will tuning down the speed, So fast retransmit come out because receiver could recevice the ACK ,because connection has not loss,if in timeout range not receive large than 2 duplicated ACK thaat means maybe is out of order,don ‘t need retrans, just re-sort in receiver.<br>But if sender receive &gt;= 3 x duplicated ACK,loss package has the high possibility.<br>That means sender could receive ACK,The network connection not loss,retrans it first,don ‘t slowing down the speed, if got the correct ACK that means there is no problem and drop that package, If still recive duplicated ACK, maybe it ‘s traffic jam, slowing down the speed.</p>
<h5 id="huoding-debug-process"><a href="#huoding-debug-process" class="headerlink" title="huoding debug process"></a><a target="_blank" rel="noopener" href="https://blog.huoding.com/2020/04/27/814">huoding debug process</a></h5><p><a target="_blank" rel="noopener" href="https://github.com/openbsd/src/blob/master/sys/net/ethertypes.h">thertypes.h</a>  </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">$ dropwatch -l kas</span><br><span class="line">Initalizing kallsyms db</span><br><span class="line">dropwatch&gt; start</span><br><span class="line">Enabling monitoring...</span><br><span class="line">Kernel monitoring activated.</span><br><span class="line">Issue Ctrl-C to stop monitoring</span><br><span class="line"><span class="number">273</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">1</span> drops at skb_queue_purge+<span class="number">18</span> (<span class="number">0xffffffff8155e028</span>)</span><br><span class="line"><span class="number">292</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">908</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">915</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">2</span> drops at __netif_receive_skb_core+<span class="number">671</span> (<span class="number">0xffffffff8156f671</span>)</span><br><span class="line"><span class="number">3</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">2</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">1684</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">2</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">3</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">1712</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line"><span class="number">2</span> drops at skb_release_data+<span class="number">10</span>e (<span class="number">0xffffffff8155debe</span>)</span><br><span class="line">^CGot a stop message</span><br><span class="line">dropwatch&gt; grep -w -A <span class="number">10</span> __netif_receive_skb_core /proc/kallsyms</span><br><span class="line">dropwatch&gt; Terminating dropwatch...</span><br><span class="line">Shutting down ...</span><br><span class="line"></span><br><span class="line">$ grep -w -A <span class="number">10</span> __netif_receive_skb_core /proc/kallsyms</span><br><span class="line">ffffffff8156f000 t __netif_receive_skb_core   &lt;----__netif_receive_skb_core+<span class="number">671</span> (<span class="number">0xffffffff8156f671</span>)</span><br><span class="line">ffffffff8156f800 t __netif_receive_skb        &lt;---|</span><br><span class="line">ffffffff8156f860 t netif_receive_skb_internal</span><br><span class="line">ffffffff8156f920 T netif_receive_skb</span><br><span class="line">ffffffff8156f990 T netif_receive_skb_sk</span><br><span class="line">ffffffff8156fa00 t napi_gro_complete</span><br><span class="line">ffffffff8156fb00 T napi_gro_flush</span><br><span class="line">ffffffff8156fb90 T napi_complete_done</span><br><span class="line">ffffffff8156fc50 T napi_complete</span><br><span class="line">ffffffff8156fc70 T sk_busy_loop</span><br><span class="line">ffffffff8156ff40 t net_rx_action</span><br><span class="line"></span><br><span class="line">./net/core/dev.c:<span class="number">4223</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Limit the use of PFMEMALLOC reserves to those protocols that implement</span></span><br><span class="line"><span class="comment"> * the special handling of PFMEMALLOC skbs.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">bool</span> <span class="title">skb_pfmemalloc_protocol</span><span class="params">(struct sk_buff *skb)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        <span class="keyword">switch</span> (skb-&gt;protocol) &#123;</span><br><span class="line">        <span class="function"><span class="keyword">case</span> <span class="title">htons</span><span class="params">(ETH_P_ARP)</span>:</span></span><br><span class="line"><span class="function">        <span class="keyword">case</span> <span class="title">htons</span><span class="params">(ETH_P_IP)</span>:</span></span><br><span class="line"><span class="function">        <span class="keyword">case</span> <span class="title">htons</span><span class="params">(ETH_P_IPV6)</span>:</span></span><br><span class="line"><span class="function">        <span class="keyword">case</span> <span class="title">htons</span><span class="params">(ETH_P_8021Q)</span>:</span></span><br><span class="line"><span class="function">        <span class="keyword">case</span> <span class="title">htons</span><span class="params">(ETH_P_8021AD)</span>:</span></span><br><span class="line"><span class="function">                <span class="keyword">return</span> <span class="literal">true</span></span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#! /usr/bin/env stap</span><br><span class="line"></span><br><span class="line">probe kernel.function(<span class="string">&quot;__netif_receive_skb_core&quot;</span>).label(<span class="string">&quot;drop&quot;</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;0x%04X\n&quot;</span>, ntohs($skb-&gt;protocol))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// output</span></span><br><span class="line"><span class="number">0x8809</span></span><br><span class="line"><span class="number">0x8809</span></span><br><span class="line"><span class="number">0x8809</span></span><br><span class="line"><span class="number">0x8809</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ETHERTYPE_SLOW          0x8809  <span class="comment">/* 803.3ad slow protocols (LACP/Marker) */</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ETHERTYPE_8023          0x0004  <span class="comment">/* IEEE 802.3 packet */</span></span></span><br><span class="line"></span><br><span class="line">$ tcpdump -i eth0 -e | grep -v -E &#x27;ARP|IP|802.1Q|802.1AD&#x27;</span><br><span class="line">$ tcpdump -ni &lt;interface&gt; -e ether proto <span class="number">0x8809</span></span><br></pre></td></tr></table></figure>

<h5 id="SR-IOV-Demo"><a href="#SR-IOV-Demo" class="headerlink" title="SR-IOV Demo"></a><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/www/public/us/en/documents/technology-briefs/xl710-sr-iov-config-guide-gbe-linux-brief.pdf">SR-IOV Demo</a></h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## intel</span></span><br><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;intel_iommu=on&#x27;</span></span><br><span class="line"><span class="comment">## AMD</span></span><br><span class="line">$ grubby --update-kernel=ALL --args=<span class="string">&#x27;iommu=pt&#x27;</span></span><br></pre></td></tr></table></figure>

<p><code>Please enable sr-iov in Dell BIOS setting with the NIC</code><br>On Linux Kernel version 3.8.x and above, the maximum number of VFs supported by the adapter can be queried by reading the sriov_totalvfs parameter via sysfs interface.   </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">$ dmesg | grep Virtualization</span><br><span class="line">[    0.994611] DMAR: Intel(R) Virtualization Technology <span class="keyword">for</span> Directed I/O</span><br><span class="line"></span><br><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_totalvfs</span><br><span class="line">64</span><br><span class="line">$ cat /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line">4</span><br><span class="line">$ lspci | grep Virtual</span><br><span class="line">03:02.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:02.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.0 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.1 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.2 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line">03:0a.3 Ethernet controller: Intel Corporation XL710/X710 Virtual Function (rev 02)</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f0/device/sriov_numvfs</span><br><span class="line"><span class="built_in">echo</span> 4 &gt; /sys/class/net/ens5f1/device/sriov_numvfs</span><br><span class="line">modprobe -r i40evf</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 0 mac 52:54:00:e8:a5:78</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 1 mac 52:54:00:e8:a5:79</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 2 mac 52:54:00:e8:a5:80</span><br><span class="line">ip link <span class="built_in">set</span> ens5f0 vf 3 mac 52:54:00:e8:a5:81</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 0 mac 52:54:00:e8:a5:82</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 1 mac 52:54:00:e8:a5:83</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 2 mac 52:54:00:e8:a5:84</span><br><span class="line">ip link <span class="built_in">set</span> ens5f1 vf 3 mac 52:54:00:e8:a5:85</span><br><span class="line"></span><br><span class="line">$ ip link show ens5f0</span><br><span class="line">19: ens5f0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 9000 qdisc mq state UP mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:aa brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:78, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:79, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:80, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:81, spoof checking on, link-state auto, trust off</span><br><span class="line">$ ip link show ens5f1</span><br><span class="line">20: ens5f1: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT qlen 1000</span><br><span class="line">    link/ether 0c:c4:7a:88:0c:ab brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    vf 0 MAC 52:54:00:e8:a5:82, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 1 MAC 52:54:00:e8:a5:83, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 2 MAC 52:54:00:e8:a5:84, spoof checking on, link-state auto, trust off</span><br><span class="line">    vf 3 MAC 52:54:00:e8:a5:85, spoof checking on, link-state auto, trust off</span><br></pre></td></tr></table></figure>

<h5 id="PCI-init"><a href="#PCI-init" class="headerlink" title="PCI init"></a>PCI init</h5><p>PCI devices are identified by registers in PCI configuration space</p>
<ul>
<li><p>Device drivers are compiled with a list of PCI device IDs that they can<br>control (MODULE_DEVICE_TABLE)</p>
</li>
<li><p>The kernel uses these tables to determine which device drivers to load</p>
</li>
<li><p>Use ‘lspci -nn’ to find your device</p>
</li>
<li><p>Find PCI vendor and device ID</p>
</li>
<li><p>Look in /lib/modules/<code>uname -r</code>/</p>
</li>
<li><p>modules.pcimap (RHEL6 and earlier)</p>
</li>
<li><p>modules.alias (RHEL7 and later)</p>
<ul>
<li>egrep -i {vid}.*{did} /lib/modules/<code>uname -r</code>/modules.alias</li>
</ul>
</li>
<li><p>PCI probe functions of the device drivers are called to set up devices</p>
</li>
<li><p>Enable the device</p>
</li>
<li><p>Request memory range &amp; I/O ports</p>
</li>
<li><p>Set DMA mask</p>
</li>
<li><p>Register ethtool functions supported by driver</p>
</li>
<li><p>Watchdog task setup</p>
</li>
<li><p>net_device_ops structure setup</p>
</li>
<li><p>Function pointers for opening, sending data, setting MAC, etc.</p>
</li>
<li><p>net_device struct creation</p>
</li>
</ul>
<h5 id="Softirq-Subsystem-Initialization"><a href="#Softirq-Subsystem-Initialization" class="headerlink" title="Softirq Subsystem Initialization"></a>Softirq Subsystem Initialization</h5><ul>
<li>smpboo.c <ul>
<li>Create ksoftirqd kernel threads (1 per CPU)</li>
<li>ksoftirqd processing loops started</li>
<li>Per CPU data structures created</li>
<li>softnet_data Poll list</li>
<li>softirq_pending bits</li>
<li>softirq_vec handlers<ul>
<li>net/core/dev.c (net_dev_init)</li>
</ul>
</li>
</ul>
</li>
<li>Softirq handler (net_rx_action) for NET_RX_SOFTIRQ registered</li>
</ul>
<h5 id="82599-limit"><a href="#82599-limit" class="headerlink" title="82599 limit"></a><a target="_blank" rel="noopener" href="https://decodezp.github.io/2020/12/14/test26-82599-fdir-limit/">82599 limit</a></h5><ul>
<li>no RSS queue-region</li>
<li>ipv6 only support Signature Mode</li>
<li>Input_set global mask</li>
<li>Could not config Input_set</li>
</ul>
<h5 id="Deep-buffers-matter"><a href="#Deep-buffers-matter" class="headerlink" title="Deep buffers matter"></a>Deep buffers matter</h5><ul>
<li><p>lossless networks</p>
</li>
<li><p>how to they deal with incast problems ?</p>
<ul>
<li>Answer: tell everyone to stop</li>
<li>In theory, allows small buffers</li>
<li>In practice, this leads to tree saturation</li>
<li>Causes blocking all the way to all sources<br><img src="/img/deep_buffer_matt-1.png"><table>
<thead>
<tr>
<th>Customer</th>
<th align="center">Real Buffer Utilization</th>
<th align="right">Cool</th>
</tr>
</thead>
<tbody><tr>
<td>HPC</td>
<td align="center">Storage Clustre -medium</td>
<td align="right">33MB</td>
</tr>
<tr>
<td>Animation</td>
<td align="center">Storage filer(NFS)</td>
<td align="right">6.2MB</td>
</tr>
<tr>
<td>Software vendor</td>
<td align="center">Engineering Build servers</td>
<td align="right">14.9MB</td>
</tr>
<tr>
<td>Online shopping</td>
<td align="center">Hadoop 2K servers -big data</td>
<td align="right">52.3MB</td>
</tr>
<tr>
<td>Educational</td>
<td align="center">Virtualization</td>
<td align="right">52.4MB</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>Deep Buffers Matter</p>
<ul>
<li>Cause packets dropped per teragen</li>
<li>Improving uplink contention in mixed speed networks<ul>
<li>High Density in core/spine (many-to-one, in-cast, fan-in)<br><img src="/img/deep_buffer_matt-2.png"></li>
</ul>
</li>
</ul>
</li>
<li><p>Buffer utilisation per port</p>
<ul>
<li><code>Some switch get the lower buffer utilisation it could cause a lot of tcp retransmit</code><br><img src="/img/deep_buffer_matt-3.png"></li>
</ul>
</li>
<li><p>The bufferbloat with the huge buffer</p>
</li>
</ul>
<h5 id="Monitor-script"><a href="#Monitor-script" class="headerlink" title="Monitor script"></a>Monitor script</h5><p><a target="_blank" rel="noopener" href="https://github.com/majek/dump/blob/master/how-to-receive-a-packet/softnet.sh">softnet.sh</a><br><a target="_blank" rel="noopener" href="https://access.redhat.com/articles/1311173">monitor.sh</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># monitor.sh begins here</span></span><br><span class="line"><span class="comment"># Save this script as monitor.sh</span></span><br><span class="line"><span class="comment"># Allocate read write execute permissions: chmod +rwx monitor.sh</span></span><br><span class="line"><span class="comment"># Help available with: ./monitor.sh -h</span></span><br><span class="line"><span class="comment"># License: Creative Commons Zero - https://creativecommons.org/publicdomain/zero/1.0/</span></span><br><span class="line"></span><br><span class="line">VERSION=47</span><br><span class="line"></span><br><span class="line">USAGE=$(cat &lt;&lt;-EOM</span><br><span class="line">Usage: monitor.sh [-d DELAY] [-i ITERATIONS] [-h]</span><br><span class="line"></span><br><span class="line">This script collects data relevant to network debugging.</span><br><span class="line">Valid parameters are all optional.</span><br><span class="line"></span><br><span class="line">-d DELAY</span><br><span class="line">Specifies a delay between collections. Default is 30 seconds.</span><br><span class="line"></span><br><span class="line">    Examples:</span><br><span class="line">    ./monitor.sh -d 10   <span class="comment"># 10 seconds</span></span><br><span class="line">    ./monitor.sh -d 2    <span class="comment"># 2 seconds</span></span><br><span class="line"></span><br><span class="line">-i ITERATIONS</span><br><span class="line">Specifies the number of collections. Default is to run forever.</span><br><span class="line"></span><br><span class="line">  Examples:</span><br><span class="line">  ./monitor.sh -i 10   <span class="comment"># 10 iterations</span></span><br><span class="line">  ./monitor.sh -i 2    <span class="comment"># 2 iterations</span></span><br><span class="line"></span><br><span class="line">-p</span><br><span class="line">Disables process collection <span class="keyword">in</span> <span class="string">&quot;ss&quot;</span>, except when SS_OPTS used.</span><br><span class="line">Default is process collection enabled when SS_OPTS not provided.</span><br><span class="line"></span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -p</span><br><span class="line"></span><br><span class="line">-h</span><br><span class="line">Displays this <span class="built_in">help</span> message.</span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -h</span><br><span class="line"></span><br><span class="line">Options can be combined.</span><br><span class="line"></span><br><span class="line">  Example:</span><br><span class="line">  ./monitor.sh -d 10 -i 360    <span class="comment"># run every 10 secs, for an hour</span></span><br><span class="line"></span><br><span class="line">This script recognizes an environment variable SS_OPTS <span class="built_in">which</span> will</span><br><span class="line">override the script<span class="string">&#x27;s default command line switches when running</span></span><br><span class="line"><span class="string">the &#x27;</span>ss<span class="string">&#x27; utility.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Example:</span></span><br><span class="line"><span class="string">  env SS_OPTS=&quot;-pantoemi sport = :22&quot; bash monitor.sh</span></span><br><span class="line"><span class="string">EOM</span></span><br><span class="line"><span class="string">)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## defaults</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">DELAY=30</span></span><br><span class="line"><span class="string">ITERATIONS=-1</span></span><br><span class="line"><span class="string">DEF_SS_OPTS=&quot;-noemitaup&quot;</span></span><br><span class="line"><span class="string">DEF_SS_OPTS_NOP=&quot;-noemitau&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">## option parsing</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">REAL_SS_OPTS=$&#123;SS_OPTS:-$DEF_SS_OPTS&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">while getopts &quot;:d:i:ph&quot; OPT; do</span></span><br><span class="line"><span class="string">    case &quot;$OPT&quot; in</span></span><br><span class="line"><span class="string">        &quot;d&quot;)</span></span><br><span class="line"><span class="string">            # something was passed, check it&#x27;</span>s a positive <span class="built_in">integer</span></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> ] 2&gt;/dev/null &amp;&amp; [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -gt 0 ] 2&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">                DELAY=<span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">&quot;ERROR: <span class="variable">$OPTARG</span> not a valid option for delay. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">                <span class="built_in">exit</span> 1</span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;i&quot;</span>)</span><br><span class="line">            <span class="comment"># something was passed, check it&#x27;s a positive integer</span></span><br><span class="line">            <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -eq <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> ] 2&gt;/dev/null &amp;&amp; [ <span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span> -gt 0 ] 2&gt;/dev/null; <span class="keyword">then</span></span><br><span class="line">                ITERATIONS=<span class="string">&quot;<span class="variable">$OPTARG</span>&quot;</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">&quot;ERROR: <span class="variable">$OPTARG</span> not a valid option for iterations. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">                <span class="built_in">exit</span> 1</span><br><span class="line">            <span class="keyword">fi</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;p&quot;</span>)</span><br><span class="line">            REAL_SS_OPTS=<span class="variable">$&#123;SS_OPTS:-<span class="variable">$DEF_SS_OPTS_NOP</span>&#125;</span></span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;h&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$USAGE</span>&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 0</span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;:&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;ERROR: -<span class="variable">$OPTARG</span> requires an argument. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">            ;;</span><br><span class="line">        <span class="string">&quot;?&quot;</span>)</span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;ERROR: -<span class="variable">$OPTARG</span> is not a valid option. Run &#x27;monitor.sh -h&#x27; for help.&quot;</span></span><br><span class="line">            <span class="built_in">exit</span> 1</span><br><span class="line">            ;;</span><br><span class="line">    <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ -z <span class="string">&quot;<span class="variable">$SS_OPTS</span>&quot;</span> ] ; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> ! ss -S 2&gt;&amp;1 | grep -q <span class="string">&quot;invalid option&quot;</span>; <span class="keyword">then</span></span><br><span class="line">        REAL_SS_OPTS+=<span class="string">&quot;S&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="comment">## reporting</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Running network monitoring with <span class="variable">$DELAY</span> second delay for <span class="variable">$ITERATIONS</span> iterations.&quot;</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;Running network monitoring with <span class="variable">$DELAY</span> second delay. Press Ctrl+c to stop...&quot;</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## one-time commands</span></span><br><span class="line"></span><br><span class="line">MQDEVS=( $(tc qdisc show | awk <span class="string">&#x27;/^qdisc mq/&#123;print $(NF-1)&#125;&#x27;</span>) )</span><br><span class="line"></span><br><span class="line"><span class="comment">## data collection loop</span></span><br><span class="line"><span class="keyword">while</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> != 0 ]; <span class="keyword">do</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#start timer in background</span></span><br><span class="line">    <span class="built_in">eval</span> sleep <span class="string">&quot;<span class="variable">$DELAY</span>&quot;</span> &amp;</span><br><span class="line"></span><br><span class="line">    now=$(date +%Y_%m_%d_%H)</span><br><span class="line">    <span class="keyword">then</span>=$(date --date=<span class="string">&quot;yesterday&quot;</span> +%Y_%m_%d_%H)</span><br><span class="line">    rm -rf <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$then</span>&quot;</span></span><br><span class="line">    mkdir -p <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;This output created with monitor.sh version <span class="variable">$VERSION</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;See https://access.redhat.com/articles/1311173&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Delay: <span class="variable">$DELAY</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;Iterations: <span class="variable">$ITERATIONS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;SS_OPTS: <span class="variable">$REAL_SS_OPTS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/version.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span></span><br><span class="line">        sysctl -a 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sysctl.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span></span><br><span class="line">        ip address list &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-address.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span></span><br><span class="line">        ip route show table all &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip-route.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> ! [ -e <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span></span><br><span class="line">        uname -a &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/uname.txt&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip_neigh&quot;</span></span><br><span class="line">    ip neigh show &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ip_neigh&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_qdisc&quot;</span></span><br><span class="line">    tc -s qdisc &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_qdisc&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$&#123;#MQDEVS[@]&#125;</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="keyword">for</span> MQDEV <span class="keyword">in</span> <span class="string">&quot;<span class="variable">$&#123;MQDEVS[@]&#125;</span>&quot;</span>; <span class="keyword">do</span></span><br><span class="line">            <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_class_<span class="variable">$MQDEV</span>&quot;</span></span><br><span class="line">            tc -s class show dev <span class="string">&quot;<span class="variable">$MQDEV</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/tc_class_<span class="variable">$MQDEV</span>&quot;</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netstat&quot;</span></span><br><span class="line">    netstat -s &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/nstat&quot;</span></span><br><span class="line">    nstat -az &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/nstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ss&quot;</span></span><br><span class="line">    <span class="built_in">eval</span> <span class="string">&quot;ss <span class="variable">$REAL_SS_OPTS</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ss&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/interrupts&quot;</span></span><br><span class="line">    cat /proc/interrupts &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/interrupts&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softnet_stat&quot;</span></span><br><span class="line">    cat /proc/net/softnet_stat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softnet_stat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/vmstat&quot;</span></span><br><span class="line">    cat /proc/vmstat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/vmstat&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ps&quot;</span></span><br><span class="line">    ps -alfe &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ps&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/mpstat&quot;</span></span><br><span class="line">    <span class="built_in">eval</span> mpstat -A <span class="string">&quot;<span class="variable">$DELAY</span>&quot;</span> 1 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/mpstat&quot;</span> &amp;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/top&quot;</span></span><br><span class="line">    top -c -b -n1 &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/top&quot;</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/numastat&quot;</span></span><br><span class="line">    numastat 2&gt;/dev/null &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/numastat&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/softirqs ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softirqs&quot;</span></span><br><span class="line">        cat /proc/softirqs &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/softirqs&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat&quot;</span></span><br><span class="line">    cat /proc/net/sockstat &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat&quot;</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/net/sockstat6 ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat6&quot;</span></span><br><span class="line">        cat /proc/net/sockstat6 &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sockstat6&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netdev&quot;</span></span><br><span class="line">    cat /proc/net/dev &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/netdev&quot;</span></span><br><span class="line">    <span class="keyword">for</span> DEV <span class="keyword">in</span> $(ip a l | grep mtu | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | awk -F <span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">do</span> <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ethtool_<span class="variable">$DEV</span>&quot;</span>; ethtool -S <span class="string">&quot;<span class="variable">$DEV</span>&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/ethtool_<span class="variable">$DEV</span>&quot;</span> 2&gt;/dev/null; <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">for</span> DEV <span class="keyword">in</span> $(ip a l | grep mtu | awk <span class="string">&#x27;&#123;print $2&#125;&#x27;</span> | awk -F <span class="string">&quot;:&quot;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span>); <span class="keyword">do</span> <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sys_statistics_<span class="variable">$DEV</span>&quot;</span>; find /sys/devices/ -<span class="built_in">type</span> f | grep <span class="string">&quot;/net/<span class="variable">$DEV</span>/statistics&quot;</span> | xargs grep . | awk -F <span class="string">&quot;/&quot;</span> <span class="string">&#x27;&#123;print $NF&#125;&#x27;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sys_statistics_<span class="variable">$DEV</span>&quot;</span>; <span class="keyword">done</span></span><br><span class="line">    <span class="keyword">if</span> [ -e /proc/net/sctp ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-assocs&quot;</span></span><br><span class="line">        cat /proc/net/sctp/assocs &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-assocs&quot;</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;===== <span class="subst">$(date +<span class="string">&quot;%F %T.%N%:z (%Z)&quot;</span>)</span> =====&quot;</span> &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-snmp&quot;</span></span><br><span class="line">        cat /proc/net/sctp/snmp &gt;&gt; <span class="string">&quot;<span class="variable">$HOSTNAME</span>-network_stats_<span class="variable">$now</span>/sctp-snmp&quot;</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">&quot;<span class="variable">$ITERATIONS</span>&quot;</span> -gt 0 ]; <span class="keyword">then</span> <span class="built_in">let</span> ITERATIONS-=1; <span class="keyword">fi</span></span><br><span class="line">    <span class="comment"># Wait till background jobs are finished</span></span><br><span class="line">    <span class="built_in">wait</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># monitor.sh ends here</span></span><br></pre></td></tr></table></figure>

<h5 id="Trace-the-twice-traceroute-hang"><a href="#Trace-the-twice-traceroute-hang" class="headerlink" title="Trace the twice traceroute hang"></a>Trace the twice traceroute hang</h5><p>traceroute twice will hang in linux, in default, each detection will send 3 probes(3 times hops), the default hops = 16 and max=30, but only return 6 x udp port xxx unreachable, the others packet will dropped. why ?<br>Because the kernel parameter limit it.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.icmp_ratelimit = 1000 <span class="comment"># chosen type ICMP packets limited rate per jiffie</span></span><br><span class="line">net.ipv4.icmp_ratemask = 6168</span><br><span class="line"></span><br><span class="line">i h g f e d c b a 9 8 7 6 5 4 3 2 1 0</span><br><span class="line">0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 = 6169</span><br><span class="line"></span><br><span class="line">got it from include/linux/icmp.h</span><br><span class="line">0 Echo Reply</span><br><span class="line">3 Destination Unreachable</span><br><span class="line">4 Source Quench</span><br><span class="line">5 Redirect</span><br><span class="line">8 Echo Request</span><br><span class="line">B Time Exceeded</span><br><span class="line">C Parameter Problem</span><br><span class="line">D Timestamp Request</span><br><span class="line">E Timestamp Reply</span><br><span class="line">F Info Request</span><br><span class="line">G Info Reply</span><br><span class="line">H Address Mask Request</span><br><span class="line">I Address Mask Reply</span><br><span class="line"></span><br><span class="line"><span class="comment">#define ICMP_ECHOREPLY          0       /* Echo Reply                   */</span></span><br><span class="line"><span class="comment">#define ICMP_DEST_UNREACH       3       /* Destination Unreachable      */</span></span><br><span class="line"><span class="comment">#define ICMP_SOURCE_QUENCH      4       /* Source Quench                */</span></span><br><span class="line"><span class="comment">#define ICMP_REDIRECT           5       /* Redirect (change route)      */</span></span><br><span class="line"><span class="comment">#define ICMP_ECHO               8       /* Echo Request                 */</span></span><br><span class="line"><span class="comment">#define ICMP_TIME_EXCEEDED      11      /* Time Exceeded                */</span></span><br><span class="line"><span class="comment">#define ICMP_PARAMETERPROB      12      /* Parameter Problem            */</span></span><br><span class="line"><span class="comment">#define ICMP_TIMESTAMP          13      /* Timestamp Request            */</span></span><br><span class="line"><span class="comment">#define ICMP_TIMESTAMPREPLY     14      /* Timestamp Reply              */</span></span><br><span class="line"><span class="comment">#define ICMP_INFO_REQUEST       15      /* Information Request          */</span></span><br><span class="line"><span class="comment">#define ICMP_INFO_REPLY         16      /* Information Reply            */</span></span><br><span class="line"><span class="comment">#define ICMP_ADDRESS            17      /* Address Mask Request         */</span></span><br><span class="line"><span class="comment">#define ICMP_ADDRESSREPLY       18      /* Address Mask Reply           */</span></span><br></pre></td></tr></table></figure>
<p>Only 6 replys</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">10:09:05.815548 IP 192.168.0.1.42480 &gt; 172.16.0.1.33434: UDP, length 32</span><br><span class="line">10:09:05.815595 IP 192.168.0.1.54215 &gt; 172.16.0.1.33435: UDP, length 32</span><br><span class="line">10:09:05.815635 IP 192.168.0.1.46464 &gt; 172.16.0.1.33436: UDP, length 32</span><br><span class="line">10:09:05.815662 IP 192.168.0.1.33628 &gt; 172.16.0.1.33437: UDP, length 32</span><br><span class="line">10:09:05.815687 IP 192.168.0.1.46279 &gt; 172.16.0.1.33438: UDP, length 32</span><br><span class="line">10:09:05.815717 IP 192.168.0.1.45281 &gt; 172.16.0.1.33439: UDP, length 32</span><br><span class="line">10:09:05.815743 IP 192.168.0.1.37148 &gt; 172.16.0.1.33440: UDP, length 32</span><br><span class="line">10:09:05.815759 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33437 unreachable, length 68</span><br><span class="line">10:09:05.815772 IP 192.168.0.1.33355 &gt; 172.16.0.1.33441: UDP, length 32</span><br><span class="line">10:09:05.815777 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33439 unreachable, length 68</span><br><span class="line">10:09:05.815786 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33438 unreachable, length 68</span><br><span class="line">10:09:05.815797 IP 192.168.0.1.44971 &gt; 172.16.0.1.33442: UDP, length 32</span><br><span class="line">10:09:05.815805 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33440 unreachable, length 68</span><br><span class="line">10:09:05.815823 IP 192.168.0.1.53488 &gt; 172.16.0.1.33443: UDP, length 32</span><br><span class="line">10:09:05.815849 IP 192.168.0.1.54353 &gt; 172.16.0.1.33444: UDP, length 32</span><br><span class="line">10:09:05.815850 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33441 unreachable, length 68</span><br><span class="line">10:09:05.815859 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33442 unreachable, length 68</span><br><span class="line">10:09:05.815874 IP 192.168.0.1.59693 &gt; 172.16.0.1.33445: UDP, length 32</span><br><span class="line">10:09:05.815899 IP 192.168.0.1.52729 &gt; 172.16.0.1.33446: UDP, length 32</span><br><span class="line">10:09:05.815924 IP 192.168.0.1.59767 &gt; 172.16.0.1.33447: UDP, length 32</span><br><span class="line">10:09:05.815953 IP 192.168.0.1.42054 &gt; 172.16.0.1.33448: UDP, length 32</span><br><span class="line">10:09:05.815979 IP 192.168.0.1.47848 &gt; 172.16.0.1.33449: UDP, length 32</span><br></pre></td></tr></table></figure>
<p>When disable the limit, each packet will be replied.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -w net.ipv4.icmp_ratelimit=0</span><br><span class="line"></span><br><span class="line">09:53:30.797886 IP 192.168.0.1.43139 &gt; 172.16.0.1.33443: UDP, length 32</span><br><span class="line">09:53:30.797891 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33443 unreachable, length 68</span><br><span class="line">09:53:30.797895 IP 192.168.0.1.43048 &gt; 172.16.0.1.33444: UDP, length 32</span><br><span class="line">09:53:30.797900 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33444 unreachable, length 68</span><br><span class="line">09:53:30.797904 IP 192.168.0.1.43989 &gt; 172.16.0.1.33445: UDP, length 32</span><br><span class="line">09:53:30.797910 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33445 unreachable, length 68</span><br><span class="line">09:53:30.797915 IP 192.168.0.1.60103 &gt; 172.16.0.1.33446: UDP, length 32</span><br><span class="line">09:53:30.797920 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33446 unreachable, length 68</span><br><span class="line">09:53:30.797924 IP 192.168.0.1.36545 &gt; 172.16.0.1.33447: UDP, length 32</span><br><span class="line">09:53:30.797930 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33447 unreachable, length 68</span><br><span class="line">09:53:30.797934 IP 192.168.0.1.58881 &gt; 172.16.0.1.33448: UDP, length 32</span><br><span class="line">09:53:30.797939 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33448 unreachable, length 68</span><br><span class="line">09:53:30.797943 IP 192.168.0.1.38467 &gt; 172.16.0.1.33449: UDP, length 32</span><br><span class="line">09:53:30.797948 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33449 unreachable, length 68</span><br><span class="line">09:53:31.524749 IP 192.168.0.1.50826 &gt; 172.16.0.1.33434: UDP, length 32</span><br><span class="line">09:53:31.524775 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33434 unreachable, length 68</span><br><span class="line">09:53:31.524783 IP 192.168.0.1.52102 &gt; 172.16.0.1.33435: UDP, length 32</span><br><span class="line">09:53:31.524788 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33435 unreachable, length 68</span><br><span class="line">09:53:31.524793 IP 192.168.0.1.55651 &gt; 172.16.0.1.33436: UDP, length 32</span><br><span class="line">09:53:31.524798 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33436 unreachable, length 68</span><br><span class="line">09:53:31.524802 IP 192.168.0.1.48441 &gt; 172.16.0.1.33437: UDP, length 32</span><br><span class="line">09:53:31.524807 IP 172.16.0.1 &gt; 192.168.0.1: ICMP 172.16.0.1 udp port 33437 unreachable, length 68</span><br></pre></td></tr></table></figure>
<p>trace the code</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">$ dropwatch -l kas</span><br><span class="line">dropwatch&gt; start</span><br><span class="line">32 drops at __udp4_lib_rcv+a14 (0xffffffff858d1cd4)</span><br><span class="line"></span><br><span class="line"><span class="comment">## analysis the source code</span></span><br><span class="line">linux-3.10.0-1127.el7/net/ipv4/icmp.c</span><br><span class="line">        /* peer icmp_ratelimit */</span><br><span class="line">        <span class="keyword">if</span> (!icmpv4_xrlim_allow(net, rt, &amp;fl4, <span class="built_in">type</span>, code))</span><br><span class="line">                goto ende;</span><br><span class="line"></span><br><span class="line">$ bpftrace -e <span class="string">&#x27;kretprobe:inet_peer_xrlim_allow &#123; printf(&quot;returned: %d\n&quot;, retval); &#125;&#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line"></span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1 <span class="comment">## only six packets destination unreachabl</span></span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">returned: 0</span><br><span class="line">$ sysctl -w net.ipv4.icmp_ratelimit=0</span><br><span class="line">bpftrace -e <span class="string">&#x27;kretprobe:inet_peer_xrlim_allow &#123; printf(&quot;returned: %d\n&quot;, retval); &#125;&#x27;</span></span><br><span class="line">Attaching 1 probe...</span><br><span class="line"></span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br><span class="line">returned: 1</span><br></pre></td></tr></table></figure>

<p>Try another way    </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## test command</span></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;=9;i++)); <span class="keyword">do</span> traceroute -w 1 -m 16 -q 1 192.168.0.51; sleep 1; <span class="keyword">done</span></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;=9;i++)); <span class="keyword">do</span> traceroute -q 1 192.168.0.51; sleep 1; <span class="keyword">done</span></span><br><span class="line"><span class="keyword">for</span> ((i=0;i&lt;=9;i++)); <span class="keyword">do</span> traceroute 192.168.0.51; sleep 1; <span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h3 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h3><p><a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E5%B8%A6%E5%AE%BD%E6%97%B6%E5%BB%B6%E4%B9%98%E7%A7%AF">Bandwidth-delay product</a><br><a target="_blank" rel="noopener" href="https://plantegg.github.io/2019/09/28/%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB/">learn tcp buff</a><br>rmem=SO_SNDBUF<br>wmem=SO_REVBUF  </p>
<ul>
<li>1 Gbit/s，1 ms RTT<ul>
<li>Bandwidth x Latency = 10^9 bit/s x 0.001 sec = 10^6 bit/s = 10^6/ 8 = 125 KB/s</li>
</ul>
</li>
<li>MSS Maxitum Transmission Unit<ul>
<li>Ethernet MSS=1460 = 1500(MTU)-20(tcp)-20(ip)</li>
<li>not set SO_RCVBUF,default = mss * cwnd (linux), if set it close to SO_RCVBUF</li>
<li>if SO_RCVBUF=8K, kernel malloc 2x8K=16K, if net.ipv4.tcp_adv_win_scale = 2, malloc 1/(2^2)=1/4 for Out of order message cache, 16-16/4=12K</li>
<li>force increase cwnd(congestion window) and rwnd(receive window), the 2 parameter for limit speed<ul>
<li>ip route change default via 192.168.1.1 dev eth0  proto static initcwnd 10</li>
<li>ip route change default via 192.168.1.1 dev eth0  proto static initrwnd 10<ul>
<li>tcp_connect_init<ul>
<li>tcp_select_inital_window<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  <span class="meta">#<span class="meta-keyword">define</span> TCP_INIT_CWND           10</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#default</span></span><br><span class="line">net/core/sock.c:<span class="number">770</span>:            sk-&gt;sk_sndbuf = <span class="keyword">max_t</span>(<span class="keyword">int</span>, val * <span class="number">2</span>, SOCK_MIN_SNDBUF);</span><br><span class="line"></span><br><span class="line">net/netfilter/ipvs/ip_vs_sync.c:<span class="number">1262</span>:           sk-&gt;sk_sndbuf = val * <span class="number">2</span>;</span><br><span class="line">net/sunrpc/xprtsock.c:<span class="number">1714</span>:             sk-&gt;sk_sndbuf = transport-&gt;sndsize * xprt-&gt;max_reqs * <span class="number">2</span>;</span><br><span class="line">net/sunrpc/svcsock.c:<span class="number">395</span>:       sock-&gt;sk-&gt;sk_sndbuf = snd * <span class="number">2</span>;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>TTL ttl (Time To Live)<ul>
<li>Update TTL = TTL - delta<ul>
<li>delta = Outgoing timestamp - Incoming</li>
<li>ip package pass a repeater, ttl = ttl -1(not use TTL=TTL - delta), util ttl=0 (IP TTL Expired)</li>
</ul>
</li>
<li>2 x MSL (normaly) &gt; 255(the max ttl)</li>
<li>Linux default cat /proc/sys/net/ipv4/ip_default_ttl = 64</li>
</ul>
</li>
<li>MSL Maximum Segment Lifetime<ul>
<li>RFC 793, 1 x MSL = 120s, but the value is diff in diff OS implementation</li>
<li>TIME_WAIT wait 2 x MSL for avoid the old package reach cause the issue<ul>
<li>A –Fin–&gt; B</li>
<li>B –ACK–&gt; A</li>
<li>B –Fin–&gt; A</li>
<li>A –ACK–&gt; B<ul>
<li>In the last ACK from A to B<ul>
<li>B not received,</li>
<li>B received, no any responding<ul>
<li>not received or received, A will wait 2 x MSL (1x ACK MSL + 1x Fin MSL)</li>
<li>Which is the expired or the new message</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>A go to Close status, if B received, it will close too</li>
</ul>
</li>
</ul>
</li>
<li>socketSendBuffer=16K</li>
<li>16K per sec/0.02s(ack time) = 800 KBps</li>
<li>wait the ack about 20ms (RTT(Round-Trip Time))<ul>
<li>the 16K packages has sent out, the buff could not free, before acknowledge receipt of the ack messages(20ms)</li>
<li>that why increase the send buff (here is the socket buf)</li>
<li>bdp = rrt*(100Mbps/8)</li>
<li>eg: (100Mbps = 12.5MBps)*0.02s(20ms RTT(Round-Trip Time))=0.25MBps=250KBps</li>
<li>ping could the rtt</li>
</ul>
</li>
<li>rtt Round-Trip Time</li>
<li>CWND Congestion Window<ul>
<li>1 x rrt time , the sender could send min(CWND, RWND) packages</li>
<li>tcp speed = min(CWND, RWND)/rrt<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">   sender       network         receiver</span><br><span class="line">     |                              |</span><br><span class="line">T0   |--------                      |------</span><br><span class="line">     |        ---------             |     |_______time1</span><br><span class="line">     |                 ------       |     |</span><br><span class="line">     |                       ------&gt;|t0----</span><br><span class="line">     |                              |</span><br><span class="line">     |                              |</span><br><span class="line">     |                              |</span><br><span class="line">     |                        ------|t1-----</span><br><span class="line">     |                  ------      |      |______ time2</span><br><span class="line">     |          --------            |      |</span><br><span class="line">T1   |&lt;---------                    |-------</span><br><span class="line">     |                              |</span><br><span class="line">     |                              |</span><br><span class="line"></span><br><span class="line"># RRT = T1(receive time)-T0(send time)-(t1-t0)= time1 + time2</span><br><span class="line"></span><br><span class="line">example2: </span><br><span class="line">the sender seq <span class="number">400</span>, len=<span class="number">100</span>, the receiver will ack num <span class="number">501</span> to the sender</span><br><span class="line">eg: the receiver got the <span class="number">201</span>，<span class="number">301</span>，<span class="number">401</span> seq packages, the receiver <span class="number">402</span> ack means got the all packages.</span><br><span class="line">                                                                   |</span><br><span class="line">                                                                   ---- seq l401+<span class="number">1</span></span><br><span class="line">           delay ack               clock tick</span><br><span class="line">   |                            |&lt;------------&gt;</span><br><span class="line">T0 |------                      |      ^</span><br><span class="line">   |      -------<span class="number">-1461</span>:<span class="number">2920</span>----&gt;|t0    |</span><br><span class="line">T1 |------                      |      <span class="number">2</span></span><br><span class="line">   |      -------<span class="number">-2921</span>:<span class="number">4380</span>----&gt;|t1    <span class="number">0</span></span><br><span class="line">   |                            |      <span class="number">0</span></span><br><span class="line">   |                            |      ms</span><br><span class="line">   |              ----ack2921---|t2    |</span><br><span class="line">T2 |&lt;----ack2921--              |      v</span><br><span class="line">   |              ----ack4381---|t3&lt;----------&gt;</span><br><span class="line">T3 |&lt;----ack4381--              |</span><br><span class="line">   |                            |</span><br><span class="line">   |                            |</span><br><span class="line"></span><br><span class="line">                      ---T2              ---T0                      ---t2            ---t0</span><br><span class="line">                      |                  |                          |                |</span><br><span class="line">rtt = ((&amp;recvtime)-&gt;tv_sec - sendtime-&gt;tv_sec) - ((&amp;recvtime)-&gt;tv_usec - sendtime-&gt;tv_usec)</span><br><span class="line">In the tcp connections, the <span class="keyword">long</span> distance, the more rrt, the open window slower, the slow start slower, your have more bandwidth, the issue more worse, the relay nodes could reduce the rtt, the congestion window reach the full quickly.</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>RWND Receive Window</li>
<li>SS Slow Start</li>
<li>CA Congestion Avoid<ul>
<li>When package loss, reduce CWND number</li>
</ul>
</li>
<li>ssthresh Slow Start Threshold<ul>
<li>after package loss -&gt; record the CWND, re-calculate ssthresh, eg: package loss -&gt; cwnd go to 1 and ssthresh = cwnd/2</li>
<li>the author recommand net.ipv4.tcp_slow_start_after_idle=0, when the connection is free, the cwnd be initcwnd to default(too slow), good for the long connection<ul>
<li>tcp_slow_start_after_idle, If set, provide RFC2861 behavior and time out the congestion window after an idle period. An idle period is defined at the current RTO<br><img src="/img/Evolution-of-TCPs-congestion-window-Tahoe-and-Reno-10.png"></li>
</ul>
</li>
</ul>
</li>
<li>default parameters    <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -a | grep -Ei <span class="string">&quot;rmem|wmem|tcp_mem|adv_win|moderate|ip_local_port_range&quot;</span></span><br><span class="line">net.core.rmem_default = 212992 <span class="comment"># The default setting in bytes of the socket receive buffer</span></span><br><span class="line">net.core.rmem_max = 212992</span><br><span class="line">net.core.wmem_default = 212992 <span class="comment"># The default setting in bytes of the socket send buffer</span></span><br><span class="line">net.core.wmem_max = 212992</span><br><span class="line">net.ipv4.tcp_adv_win_scale = 1</span><br><span class="line">net.ipv4.tcp_mem = 186936	249250	373872  <span class="comment">## num of pages</span></span><br><span class="line">net.ipv4.tcp_rmem = 4096	87380	6291456 <span class="comment">## num of bytes, if the application set the SO_RCVBUF, it &#x27;s just limit the net.core.rmem_max and limit by tcp_mem</span></span><br><span class="line">net.ipv4.tcp_wmem = 4096	16384	4194304 <span class="comment">## num of bytes, if the application set the SO_SNDBUF, it &#x27;s just limit the net.core.wmem_max and limit by tcp_mem</span></span><br><span class="line">net.ipv4.udp_rmem_min = 4096</span><br><span class="line">net.ipv4.udp_wmem_min = 4096</span><br><span class="line">vm.lowmem_reserve_ratio = 256	256	32</span><br><span class="line">net.ipv4.ip_local_port_range = 32768    60999 <span class="comment">## if not enough port, it will cause error too</span></span><br><span class="line"></span><br><span class="line">net.ipv4.tcp_moderate_rcvbuf = 1</span><br><span class="line"><span class="comment">#If set, TCP performs receive buffer auto-tuning, attempting to automatically size the buffer (no greater than tcp_rmem[2]) to match the size required by the path for full throughput. Enabled by default</span></span><br></pre></td></tr></table></figure></li>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/37b36d8655e3">slow start</a><ul>
<li>net.ipv4.tcp_slow_start_after_idle=1</li>
<li>cwnd 1 x MSS, 2^n increase util cwnd = ssthresh<ul>
<li>inflight (bytes) &lt;= min(rwnd, cwnd)<ul>
<li>inflight is the maximum send bytes</li>
<li>min(rwnd, cwnd) / RTT = send bytes/sec</li>
<li>rwnd and cwnd is the speed controller</li>
<li>Switch/route/NIC buff overflow cause package loss –&gt; replicate ACK<ul>
<li>Speed bottle neck, reduce the rwnd/cwnd<ul>
<li>when the package loss, ssthresh = cwnd / 2, reset the cwnd = 1 , repeat the 2^n increase util cwnd = ssthresh (slow start threshold)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Congestion Avoidance<ul>
<li>Received a ack, cwnd = cwnd + 1 util the next retrans –&gt; go to slow start (ssthresh = cwnd / 2, reset the cwnd = 1)</li>
<li>ssthresh = cwnd / 2; cwnd = cwnd / 2 + 3, 3 dup ACKs(Fast Recovery), timeout not trigger the fast recovery<br><a target="_blank" rel="noopener" href="https://i.stack.imgur.com/Pi81I.png">Figure 3.51 FSM description of TCP congestion control</a><br><img src="/img/Pi81I.png"></li>
</ul>
</li>
<li>tcp windows scale<ul>
<li>tcp send speed = min(CWND, RWND)/rrt<ul>
<li>tcp windows scale negotiate RWND, 16bit, if not support, TCP Windows size = 2^16=65535=64K</li>
<li>rrt = 35ms, windows scale&lt;CWND, 64K*1000/35=1792K(1.8M)</li>
<li>rrt = 30ms, windows scale&gt;CWND, CWND*1500(MTU)*1000(ms)/30</li>
</ul>
</li>
</ul>
</li>
<li>the OS/app hang cause tcp receive window full ( package loss )<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">window update -&gt;</span><br><span class="line">tcp zero window -&gt;</span><br><span class="line">tcp zero window -&gt;</span><br><span class="line">tcp zero window -&gt;</span><br><span class="line">tcp zero window -&gt;</span><br></pre></td></tr></table></figure></li>
<li><a target="_blank" rel="noopener" href="https://perthcharles.github.io/2015/09/07/wiki-tcp-retries/">When the ack retrans out of tcp_retries2</a><ul>
<li>如果RTT比较小，那么RTO初始值就约等于下限200ms,由于timeout总时长是924600ms，表现出来的现象刚好就是重传了15次，超过了timeout值，从而放弃TCP流</li>
<li>如果RTT较大，比如RTO初始值计算得到的是1000ms, 那么根本不需要重传15次，重传总间隔就会超过924600ms。比如我测试的一个RTT=400ms的情况，当tcp_retries2=10时，仅重传了3次就放弃了TCP流</li>
<li>The proxy, slb, switch deliberately loss the package in a tcp stream because the flow control policy</li>
<li>when out of tcp_retries2, the connection will be reset</li>
<li>In some case, the server reset message hang by unknow reason, when the client to re-connect, in this process received the reset message cause the connection interrupt</li>
</ul>
</li>
<li>Consider 9K jumbo frames, how long time will it take to empty 1024 jumbo frames on a 10G link:<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"> (9000*8)/(10000*10^6)*1000*1024 = 7.37ms</span><br><span class="line">But with 9K MTU and 512, we already have:</span><br><span class="line"> (9000*8)/(10000*10^6)*1000*512 = 3.69ms</span><br><span class="line">Guess the more normal use-case would be 1500+38 (Ethernet overhead)</span><br><span class="line"> (1538*8)/(10000*10^6)*1000*1024 = 1.25ms</span><br><span class="line">   |         |               |</span><br><span class="line">   |         |               -------1024 x Frames, the ring buffer</span><br><span class="line">   |         ---------10GbE</span><br><span class="line">   ----1500 + 38 (ethernet overhead)</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a target="_blank" rel="noopener" href="https://blog.cloudflare.com/how-to-receive-a-million-packets/">How to receive a million packets per second</a><br><a target="_blank" rel="noopener" href="https://blog.cloudflare.com/kernel-bypass/">kernel bypass</a><br><a href="(https://www.mellanox.com/related-docs/prod_software/Performance_Tuning_Guide_for_Mellanox_Network_Adapters_Archive.pdf">100GbE setting</a><br><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html-single/performance_tuning_guide/index">redhat performance tuning guide</a><br><a target="_blank" rel="noopener" href="https://fasterdata.es.net/host-tuning/100g-tuning/">100GbE tuning</a><br><a target="_blank" rel="noopener" href="https://www.intel.com/content/dam/www/public/us/en/documents/reference-guides/xl710-x710-performance-tuning-linux-guide.pdf">xl710-x710-performance-tuning-linux-guide</a><br><a target="_blank" rel="noopener" href="https://download.01.org/packet-processing/ONPS2.1/Intel_ONP_Release_2.1_Performance_Test_Report_Rev1.0.pdf">Intel_ONP_Release_2.1_performance_test_report</a><br><a target="_blank" rel="noopener" href="http://lkml.iu.edu/hypermail/linux/kernel/0401.0/0017.html">same case1 TSO or jumbo frame</a><br><a target="_blank" rel="noopener" href="https://community.nxp.com/t5/i-MX-Processors/fec-skb-page-allocation-failure/td-p/652167">same case2 TSO or jumbo frame</a><br><a target="_blank" rel="noopener" href="https://lore.kernel.org/patchwork/patch/381731/">Dever disable the warnning v1</a><br><a target="_blank" rel="noopener" href="https://patchwork.ozlabs.org/project/netdev/patch/1369601101-23057-1-git-send-email-atomlin@redhat.com/">Dever disable the warnning v2</a><br><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/networking/ixgb.txt">ixgbe kernel driver doc</a></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">寸劲</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2018/06/01/ethernet_nic_tuning/">http://yoursite.com/2018/06/01/ethernet_nic_tuning/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/network/">network</a><a class="post-meta__tags" href="/tags/benchmark/">benchmark</a><a class="post-meta__tags" href="/tags/nic/">nic</a><a class="post-meta__tags" href="/tags/irq/">irq</a></div><div class="post_share"><div class="social-share" data-image="https://homerl.github.io/img/32_connection_nodes_communication_network_seo_social_community_relation-512.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/07/02/mem/"><img class="prev-cover" src="https://homerl.github.io/img/operting_system_a32c6f.svg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">memory</div></div></a></div><div class="next-post pull-right"><a href="/2018/05/27/ipmi/"><img class="next-cover" src="https://homerl.github.io/img/network-interface-card-2081371-1751392.png" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">ipmitool</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2020/07/22/network-benchmark-result/" title="Network bencharmk results"><img class="cover" src="https://homerl.github.io/img/kisspng-computer-icons-benchmarking-computer-software-clip-5ad795b068f297.2882681215240780004299.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-07-22</div><div class="title">Network bencharmk results</div></div></a></div><div><a href="/2017/01/08/tcp/" title="TCP"><img class="cover" src="https://homerl.github.io/img/operting_system_a32c6f.svg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2017-01-08</div><div class="title">TCP</div></div></a></div><div><a href="/2018/07/12/storage_benchmark/" title="storage benchmark"><img class="cover" src="https://homerl.github.io/img/kisspng-computer-icons-benchmarking-computer-software-clip-5ad795b068f297.2882681215240780004299.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-07-12</div><div class="title">storage benchmark</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2015 - 2021 By 寸劲</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '0b9d5b98d0a972b33cf7',
      clientSecret: '769efc11b32f6c0d03bcbf3ee800dfc4e2690459',
      repo: 'homerl.github.io',
      owner: 'homerl',
      admin: ['homerl'],
      id: 'aa2a3708a6e70b4bfa7ee619c4323c9f',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    $.getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js', initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>