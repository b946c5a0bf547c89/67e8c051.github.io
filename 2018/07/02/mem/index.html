<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>memory | 己不由心，身又岂能由己</title><meta name="keywords" content="memory"><meta name="author" content="Ginger"><meta name="copyright" content="Ginger"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Make sure the ECC work in Linux1234$ dmidecode -t memory  | grep -Ei &amp;#x27;error correction type&amp;#x27;	Error Correction Type: Single-bit ECC$ dmidecode -t memory  | grep -Ei &amp;#x27;error correction typ">
<meta property="og:type" content="article">
<meta property="og:title" content="memory">
<meta property="og:url" content="http://yoursite.com/2018/07/02/mem/index.html">
<meta property="og:site_name" content="己不由心，身又岂能由己">
<meta property="og:description" content="Make sure the ECC work in Linux1234$ dmidecode -t memory  | grep -Ei &amp;#x27;error correction type&amp;#x27;	Error Correction Type: Single-bit ECC$ dmidecode -t memory  | grep -Ei &amp;#x27;error correction typ">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/img/photo_by_spacex.jpg">
<meta property="article:published_time" content="2018-07-02T02:49:30.000Z">
<meta property="article:modified_time" content="2020-10-09T12:23:43.478Z">
<meta property="article:author" content="Ginger">
<meta property="article:tag" content="memory">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/img/photo_by_spacex.jpg"><link rel="shortcut icon" href="/img/stout-shield.png"><link rel="canonical" href="http://yoursite.com/2018/07/02/mem/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-10-09 20:23:43'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/244247-guts.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">58</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">57</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">9</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Make-sure-the-ECC-work-in-Linux"><span class="toc-number">1.</span> <span class="toc-text">Make sure the ECC work in Linux</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Monitor-ECC-error"><span class="toc-number">2.</span> <span class="toc-text">Monitor ECC error</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#From-OS"><span class="toc-number">2.1.</span> <span class="toc-text">From OS</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#From-IPMI"><span class="toc-number">2.2.</span> <span class="toc-text">From IPMI</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NIC-page-allocation-failure"><span class="toc-number">3.</span> <span class="toc-text">NIC page allocation failure</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#dirty-page"><span class="toc-number">3.1.</span> <span class="toc-text">dirty page</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ZRAM"><span class="toc-number">4.</span> <span class="toc-text">ZRAM</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Some-parameter-about-numa"><span class="toc-number">5.</span> <span class="toc-text">Some parameter about numa</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Soft-lockup-detected-on-a-large-NUMA-system-under-a-heavy-memory-usage"><span class="toc-number">6.</span> <span class="toc-text">Soft lockup detected on a large NUMA system under a heavy memory usage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transparent-Huge-Page"><span class="toc-number">7.</span> <span class="toc-text">Transparent Huge Page</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Single-process-memory"><span class="toc-number">8.</span> <span class="toc-text">Single process memory</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Slab"><span class="toc-number">8.1.</span> <span class="toc-text">Slab</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Page-table"><span class="toc-number">8.2.</span> <span class="toc-text">Page table</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Struct-page"><span class="toc-number">8.3.</span> <span class="toc-text">Struct page</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Use-hugetlbfs"><span class="toc-number">9.</span> <span class="toc-text">Use hugetlbfs</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#set-hugepage"><span class="toc-number">9.1.</span> <span class="toc-text">set hugepage</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Defragment-kernel-memory"><span class="toc-number">9.2.</span> <span class="toc-text">Defragment kernel memory</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#memlock"><span class="toc-number">9.3.</span> <span class="toc-text">memlock</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#free-hugepage"><span class="toc-number">9.4.</span> <span class="toc-text">free hugepage</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#manage-tools"><span class="toc-number">9.5.</span> <span class="toc-text">manage tools</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#reduce-OOM-kill-rate"><span class="toc-number">9.6.</span> <span class="toc-text">reduce OOM kill rate</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#get-pagesize"><span class="toc-number">9.7.</span> <span class="toc-text">get pagesize</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#enable-huge-page-for-performance"><span class="toc-number">10.</span> <span class="toc-text">enable huge page for performance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#slab-exhaust-all-memory-because-a-lot-of-scan"><span class="toc-number">11.</span> <span class="toc-text">slab exhaust all memory because a lot of scan</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#memmap"><span class="toc-number">12.</span> <span class="toc-text">memmap</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Monitor-ecc-error"><span class="toc-number">12.1.</span> <span class="toc-text">Monitor ecc error</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Benchmark-by-perf"><span class="toc-number">13.</span> <span class="toc-text">Benchmark by perf</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AMD-roma-CPU-memroy"><span class="toc-number">14.</span> <span class="toc-text">AMD roma CPU memroy</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(/img/photo_by_spacex.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">己不由心，身又岂能由己</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">memory</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2018-07-02T02:49:30.000Z" title="Created 2018-07-02 10:49:30">2018-07-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2020-10-09T12:23:43.478Z" title="Updated 2020-10-09 20:23:43">2020-10-09</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/OS/">OS</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h3 id="Make-sure-the-ECC-work-in-Linux"><a href="#Make-sure-the-ECC-work-in-Linux" class="headerlink" title="Make sure the ECC work in Linux"></a>Make sure the ECC work in Linux</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ dmidecode -t memory  | grep -Ei <span class="hljs-string">&#x27;error correction type&#x27;</span><br>	Error Correction Type: Single-bit ECC<br>$ dmidecode -t memory  | grep -Ei <span class="hljs-string">&#x27;error correction type&#x27;</span><br>	Error Correction Type: Multi-bit ECC<br></code></pre></td></tr></table></figure>

<a id="more"></a>

<h3 id="Monitor-ECC-error"><a href="#Monitor-ECC-error" class="headerlink" title="Monitor ECC error"></a>Monitor ECC error</h3><h4 id="From-OS"><a href="#From-OS" class="headerlink" title="From OS"></a>From OS</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#Intel x86 scalable</span><br>skx_edac<br><br><span class="hljs-comment">#Intel x86 E3</span><br>ie31200-edac<br>$ edac-util -vs<br>edac-util: EDAC drivers are loaded. 1 MC detected:<br>  mc0:IE31200<br><br>$ edac-util -vs<br>edac-util: EDAC drivers loaded. No memory controllers found<br>$ <span class="hljs-built_in">echo</span> $?<br>1<br><br>$ edac-util -v<br>mc0: 0 Uncorrected Errors with no DIMM info<br>mc0: 0 Corrected Errors with no DIMM info<br>mc0: csrow0: 0 Uncorrected Errors<br>mc0: csrow0: mc<span class="hljs-comment">#0csrow#0channel#0: 0 Corrected Errors</span><br>mc0: csrow0: mc<span class="hljs-comment">#0csrow#0channel#1: 0 Corrected Errors</span><br>mc0: csrow1: 0 Uncorrected Errors<br>mc0: csrow1: mc<span class="hljs-comment">#0csrow#1channel#0: 0 Corrected Errors</span><br>mc0: csrow1: mc<span class="hljs-comment">#0csrow#1channel#1: 0 Corrected Errors</span><br>mc0: csrow2: 0 Uncorrected Errors<br>mc0: csrow2: mc<span class="hljs-comment">#0csrow#2channel#0: 0 Corrected Errors</span><br>mc0: csrow2: mc<span class="hljs-comment">#0csrow#2channel#1: 0 Corrected Errors</span><br>mc0: csrow3: 0 Uncorrected Errors<br>mc0: csrow3: mc<span class="hljs-comment">#0csrow#3channel#0: 0 Corrected Errors</span><br>mc0: csrow3: mc<span class="hljs-comment">#0csrow#3channel#1: 0 Corrected Errors</span><br>edac-util: No errors to report.<br><br><span class="hljs-comment">#CentOS 7.7 not support Xeon E2000, the kernel merge the patch at 2019-06, maybe wait CentOS 7.8</span><br><span class="hljs-comment">#Intel x86 E2000</span><br>ie31200-edac<br>$ edac-util -vs<br>edac-util: EDAC drivers loaded. No memory controllers found<br></code></pre></td></tr></table></figure>
<h4 id="From-IPMI"><a href="#From-IPMI" class="headerlink" title="From IPMI"></a>From IPMI</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ ipmitool sel elist<br></code></pre></td></tr></table></figure>

<h3 id="NIC-page-allocation-failure"><a href="#NIC-page-allocation-failure" class="headerlink" title="NIC page allocation failure"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/641323">NIC page allocation failure</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Mon Jul  2 10:38:25 2018] swapper/16: page allocation failure: order:2, mode:0x104020<br>[Mon Jul  2 10:38:25 2018] CPU: 16 PID: 0 Comm: swapper/16 Tainted: P           OE  ------------   3.10.0-693.5.2.el7_lustre.x86_64 <span class="hljs-comment">#1</span><br>[Mon Jul  2 10:38:25 2018] Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.4.3 01/17/2017<br>[Mon Jul  2 10:38:25 2018]  0000000000104020 7e870b98ec876be5 ffff88103e8039d8 ffffffff816a3e2d<br>[Mon Jul  2 10:38:25 2018]  ffff88103e803a68 ffffffff81188820 0000000000000246 ffff88103e803a28<br>[Mon Jul  2 10:38:25 2018]  fffffffffffffffc 0010402000000000 ffff88107ffdb018 7e870b98ec876be5<br>[Mon Jul  2 10:38:25 2018] Call Trace:<br>[Mon Jul  2 10:38:25 2018]  &lt;IRQ&gt;  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031abba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031ba97&gt;] bnx2x_rx_int+0x227/0x17c0 [bnx2x]<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81573004&gt;] ? consume_skb+0x34/0x80<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81585dad&gt;] ? __dev_kfree_skb_any+0x3d/0x50<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffffc031eecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d<br>[Mon Jul  2 10:38:25 2018]  &lt;EOI&gt;  [&lt;ffffffff816ab546&gt;] ? native_safe_halt+0x6/0x10<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff816ab3de&gt;] default_idle+0x1e/0xc0<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81035006&gt;] arch_cpu_idle+0x26/0x30<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0<br>[Mon Jul  2 10:38:25 2018]  [&lt;ffffffff81051af6&gt;] start_secondary+0x1b6/0x230<br><br><span class="hljs-comment"># in my case </span><br>[Thu Jul 12 04:23:16 2018]  00000000ad5e4ed1<br>[Thu Jul 12 04:23:16 2018] Call Trace:<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  ffff88103e643a20 ffffffff81188820<br>[Thu Jul 12 04:23:16 2018]  &lt;IRQ&gt;<br>[Thu Jul 12 04:23:16 2018]  00000000000000c3<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b<br>[Thu Jul 12 04:23:16 2018]  0000000000000282<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180<br>[Thu Jul 12 04:23:16 2018]  fffffffffffffffc 0010402000000000<br>[Thu Jul 12 04:23:16 2018]  ffff8816385ea000 66b8573252d2c8c3<br>[Thu Jul 12 04:23:16 2018] Call Trace:<br>[Thu Jul 12 04:23:16 2018]  &lt;IRQ&gt;  [&lt;ffffffff816a3e2d&gt;] dump_stack+0x19/0x1b<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81188820&gt;] warn_alloc_failed+0x110/0x180<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8169fe2a&gt;] __alloc_pages_slowpath+0x6b6/0x724<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] ? __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118cdb5&gt;] __alloc_pages_nodemask+0x405/0x420<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1c02&gt;] ? load_balance+0x192/0x9a0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1bd2&gt;] ? load_balance+0x162/0x9a0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81573004&gt;] ? consume_skb+0x34/0x80<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81585dad&gt;] ? __dev_kfree_skb_any+0x3d/0x50<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f95c2&gt;] ? bnx2x_free_tx_pkt+0x1f2/0x2d0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f0062&gt;] ? bnx2x_test_link+0x42/0x270 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811d1078&gt;] alloc_pages_current+0x98/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8118761e&gt;] __get_free_pages+0xe/0x40<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811dca2e&gt;] kmalloc_order_trace+0x2e/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] ? __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811e05c1&gt;] __kmalloc+0x211/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d<br>[Thu Jul 12 04:23:16 2018]  &lt;EOI&gt;<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f8bba&gt;] bnx2x_frag_alloc.isra.61+0x2a/0x40 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527d42&gt;] ? cpuidle_enter_state+0x52/0xc0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527e88&gt;] cpuidle_idle_call+0xd8/0x210<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81034fee&gt;] arch_cpu_idle+0xe/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02f9124&gt;] bnx2x_alloc_rx_data.isra.69+0x54/0x1c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fa0b6&gt;] bnx2x_rx_int+0x846/0x17c0 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810d1c02&gt;] ? load_balance+0x192/0x9a0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110<br>[Thu Jul 12 04:23:16 2018]  &lt;EOI&gt;<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527d42&gt;] ? cpuidle_enter_state+0x52/0xc0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527e88&gt;] cpuidle_idle_call+0xd8/0x210<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d<br>[Thu Jul 12 04:23:16 2018]  &lt;EOI&gt;  [&lt;ffffffff81527d42&gt;] ? cpuidle_enter_state+0x52/0xc0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81527e88&gt;] cpuidle_idle_call+0xd8/0x210<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81034fee&gt;] arch_cpu_idle+0xe/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81051af6&gt;] start_secondary+0x1b6/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81034fee&gt;] arch_cpu_idle+0xe/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81051af6&gt;] start_secondary+0x1b6/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffffc02fcecd&gt;] bnx2x_poll+0x1dd/0x260 [bnx2x]<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8158799d&gt;] net_rx_action+0x16d/0x380<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090b4f&gt;] __do_softirq+0xef/0x280<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810e7bda&gt;] cpu_startup_entry+0x14a/0x1c0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81051af6&gt;] start_secondary+0x1b6/0x230<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b6b1c&gt;] call_softirq+0x1c/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff8102d3c5&gt;] do_softirq+0x65/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81090ed5&gt;] irq_exit+0x105/0x110<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b76b6&gt;] do_IRQ+0x56/0xe0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816ac2ad&gt;] common_interrupt+0x6d/0x6d<br>[Thu Jul 12 04:23:16 2018]  &lt;EOI&gt;  [&lt;ffffffff811a3178&gt;] ? fragmentation_index+0x38/0xa0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811a877b&gt;] compaction_suitable+0x5b/0xb0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81199102&gt;] balance_pgdat+0x502/0x5e0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff81199353&gt;] kswapd+0x173/0x440<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810b1920&gt;] ? wake_up_atomic_t+0x30/0x30<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff811991e0&gt;] ? balance_pgdat+0x5e0/0x5e0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810b099f&gt;] kthread+0xcf/0xe0<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810b08d0&gt;] ? insert_kthread_work+0x40/0x40<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff816b4fd8&gt;] ret_from_fork+0x58/0x90<br>[Thu Jul 12 04:23:16 2018]  [&lt;ffffffff810b08d0&gt;] ? insert_kthread_work+0x40/0x40<br>[Thu Jul 12 04:23:16 2018] swapper/32: page allocation failure: order:2, mode:0x104020<br>[Thu Jul 12 04:23:16 2018] CPU: 32 PID: 0 Comm: swapper/32 Tainted: P           OE  ------------   3.10.0-693.5.2.el7_lustre.x86_64 <span class="hljs-comment">#1</span><br>[Thu Jul 12 04:23:16 2018] Hardware name: Dell Inc. PowerEdge R730/072T6D, BIOS 2.4.3 01/17/2017<br>[Thu Jul 12 04:23:16 2018]  0000000000104020 1fc54c56797ed550 ffff88103ea03990 ffffffff816a3e2d<br>[Thu Jul 12 04:23:16 2018] swapper/12: page allocation failure: order:2, mode:0x104020<br><br><span class="hljs-comment"># you can see a lot of processes could not allocation memory</span><br>[Fri Aug 16 06:08:22 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] kswapd0: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] swapper/10: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 06:43:21 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:53:18 2019] swapper/22: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 07:58:18 2019] java: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] kswapd0: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] systemd-journal: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] swapper/16: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] swapper/16: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] swapper/4: page allocation failure: order:2, mode:0x104020<br>[Fri Aug 16 09:08:22 2019] swapper/4: page allocation failure: order:2, mode:0x104020<br></code></pre></td></tr></table></figure>
<p>zone_reclaim_mode<br>sysctl -w vm.zone_reclaim_mode=1<br>#This can be set to 1 to attempt reclamation of memory within a NUMA node before reclaiming from other NUMA nodes.</p>
<p><code>min_free_kbytes</code> (it ‘s worked, the page allocation failure was missing)<br>sysctl -w vm.min_free_kbytes = 540672<br>#Increase the virtual memory kernel tunable vm.min_free_kbytes, which instructs the virtual memory subsystem to try keep a certain amount of memory always free for allocation.</p>
<p>The network driver is receiving traffic from the network adapter into kernel memory, however when the driver tried to allocate memory, the allocation failed.</p>
<p>Kernel memory is required to be a contiguous block of a certain size. The kernel memory may be all consumed or fragmented, hence why a contiguous block could not be allocated.</p>
<p>Tuning of the system’s use of kernel memory is required to ensure the kernel can always service kernel memory allocations when running in interrupt context.</p>
<p>kswapd high cpu usage in some of not enough memory case<br>reslove the issue temporary</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">sar -rB 2 <span class="hljs-comment"># check system vm status</span><br><br><span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/drop_caches<br><span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/compact_memory<br></code></pre></td></tr></table></figure>

<p>reduce memory compaction ratio<br>echo 1000 &gt;  /proc/sys/vm/extfrag_threshold # 0~1000 ,1000 means the minimum trigger memory compaction operation, it means kernel memory is required to be a contiguous block of a certain size. The kernel memory may be all consumed or fragmented, hence why a contiguous block could not be allocated.</p>
<p>Some times there are a lot of free memory in your system. But I ‘m not sure the sk_buffer to malloc memroy range from the linux kernel when the NIC driver tirgger the issue.</p>
<h4 id="dirty-page"><a href="#dirty-page" class="headerlink" title="dirty page"></a>dirty page</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">sysctl -a | grep dirty<br>vm.dirty_background_bytes = 0<br>vm.dirty_background_ratio = 10<br>vm.dirty_bytes = 0<br>vm.dirty_expire_centisecs = 3000<br>vm.dirty_ratio = 20<br>vm.dirty_writeback_centisecs = 500<br></code></pre></td></tr></table></figure>


<h3 id="ZRAM"><a href="#ZRAM" class="headerlink" title="ZRAM"></a><a target="_blank" rel="noopener" href="http://liujunming.top/2016/07/04/Linux%E5%86%85%E6%A0%B8%E4%B8%ADzram%E6%A8%A1%E5%9D%97%E7%9A%84%E7%90%86%E8%A7%A3/">ZRAM</a></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs bash">description <span class="hljs-string">&quot;Initializes zram swaping&quot;</span><br>start on runlevel [2345]<br>stop on runlevel [!2345]<br>pre-start script<br><span class="hljs-comment"># load dependency modules</span><br>modprobe zram num_devices=2<br><span class="hljs-comment"># initialize the devices</span><br><span class="hljs-built_in">echo</span> 1073741824 &gt; /sys/block/zram0/disksize<br><span class="hljs-built_in">echo</span> 1073741824 &gt; /sys/block/zram1/disksize<br><span class="hljs-comment"># Creating swap filesystems</span><br>mkswap /dev/zram0<br>mkswap /dev/zram1<br><span class="hljs-comment"># Switch the swaps on</span><br>swapon -p 5 /dev/zram0<br>swapon -p 5 /dev/zram1<br>end script<br>post-stop script<br><span class="hljs-comment"># Switching off swap</span><br>swapoff /dev/zram0<br>swapoff /dev/zram1<br>rmmod zram<br>end script<br><br><span class="hljs-comment">##test zram</span><br><span class="hljs-comment">#include &lt;stdio.h&gt;</span><br><span class="hljs-comment">#include &lt;stdlib.h&gt;  </span><br>int main()<br>&#123;<br>	//<span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%d\n&quot;</span>, sizeof(int));<br>	int  *mem;<br>	int i, size;<br>	size = 0x70000000;<br>	mem = (int*)malloc(size*sizeof(int));<br>	<span class="hljs-keyword">for</span>(i = 0; i &lt; size; i++)<br>		mem[i] = (i%1024);<br>	getchar();<br>	free(mem);<br>	<span class="hljs-built_in">return</span> 0;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="Some-parameter-about-numa"><a href="#Some-parameter-about-numa" class="headerlink" title="Some parameter about numa"></a>Some parameter about numa</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">numactl --interleave=all <span class="hljs-comment">#Two/Four socket CPU will share all memory, but you can&#x27; t got the best performance except you need more memory</span><br>vm.zone_reclaim_mode = 0  <span class="hljs-comment">#</span><br><span class="hljs-built_in">echo</span> -15 &gt; /proc/&lt;pid&gt;/oom_adj <span class="hljs-comment">#reduce kill ratio	</span><br>huge page will not be swaped<br></code></pre></td></tr></table></figure>

<h3 id="Soft-lockup-detected-on-a-large-NUMA-system-under-a-heavy-memory-usage"><a href="#Soft-lockup-detected-on-a-large-NUMA-system-under-a-heavy-memory-usage" class="headerlink" title="Soft lockup detected on a large NUMA system under a heavy memory usage"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/1560893">Soft lockup detected on a large NUMA system under a heavy memory usage</a></h3><p>Systems with numa factor lower than or equal to 30 may hang under the high load.<br>Soft lockup detected under a heavy memory pressure on a large NUMA system.</p>
<p>For RHEL 7, users must be aware of the following steps that can avoid the soft lockup from occurring. Disable Transparent Huge Page (THP) to avoid such busy memory-compaction, and add “numa_balancing=disable” to the kernel parameter followed by reboot, OR set /proc/sys/vm/zone_reclaim_mode to 1.<br>For RHEL 6,<br>disable Transparent Huge Page (THP) to avoid such busy memory-compaction OR set /proc/sys/vm/zone_reclaim_mode to 1.</p>
<p>The default value(zero) of /proc/sys/vm/zone_reclaim_mode results in the CPUs running on the memory exhausted nodes to skip over to the next node with available memory to attempt the memory allocation.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs bash">kernel: BUG: soft lockup - CPU<span class="hljs-comment">#102 stuck for 22s! [forkoff:235364]</span><br>kernel: Modules linked <span class="hljs-keyword">in</span>: fuse btrfs zlib_deflate raid6_pq xor msdos ext4<br>mbcache jbd2 binfmt_misc xt_CHECKSUM iptable_mangle ipt_MASQUERADE<br>nf_nat_masquerade_ipv4 iptable_nat nf_nat_ipv4 nf_nat nf_conntrack_ipv4<br>nf_defrag_ipv4 xt_conntrack nf_conntrack ipt_REJECT iptable_filter ip_tables<br>tun bridge stp llc dm_mirror dm_region_hash dm_log dm_mod iTCO_wdt<br>iTCO_vendor_support vfat fat intel_powerclamp coretemp intel_rapl kvm_intel<br>kvm crct10dif_pclmul crc32_pclmul crc32c_intel ghash_clmulni_intel aesni_intel<br>lrw gf128mul glue_helper ablk_helper cryptd pcspkr sb_edac edac_core lpc_ich<br>i2c_i801 mfd_core shpchp ipmi_si ipmi_msghandler tpm_infineon nls_utf8 isofs<br>loop uinput xfs libcrc32c sd_mod crc_t10dif crct10dif_common mgag200<br>syscopyarea sysfillrect sysimgblt drm_kms_helper igb qla2xxx e1000e<br>kernel: ttm dca ptp scsi_transport_fc drm i2c_algo_bit pps_core scsi_tgt<br>megaraid_sas i2c_core<br>kernel: CPU: 102 PID: 235364 Comm: forkoff Not tainted 3.10.0-229.el7.x86_64<br><span class="hljs-comment">#1                                                                                                                                                                                                                                                                             </span><br>kernel:<br>kernel: task: ffff911d25eea220 ti: ffff927835154000 task.ti: ffff927835154000<br>kernel: RIP: 0010:[&lt;ffffffff811798ef&gt;]  [&lt;ffffffff811798ef&gt;]<br>isolate_freepages_block+0xaf/0x380<br>kernel: RSP: 0000:ffff927835157860  EFLAGS: 00000286<br>kernel: RAX: 00000000ffffffff RBX: 00000014e4b60000 RCX: ffff927835157aa8<br>kernel: RDX: 0000000053345c00 RSI: 0000000053345a00 RDI: ffff927835157a50<br>kernel: RBP: ffff9278351578f8 R08: 0000000000000000 R09: ffff8e007ffda000<br>kernel: R10: 00000014cd168000 R11: 0000000060080000 R12: 0000000000000301<br>kernel: R13: ffff927835157850 R14: 0000000000000000 R15: 00007f4501f64000<br>kernel: FS:  00007f4f4d540740(0000) GS:ffff90fa7f9a0000(0000)<br>knlGS:0000000000000000<br>kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033<br>kernel: CR2: 00007f4690400000 CR3: 000009baa7060000 CR4: 00000000001407e0<br>kernel: DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000<br>kernel: DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400<br>kernel: Stack:<br>kernel: ffffea2a02311040 0000000060080000 0000000000000094 ffff927835157948<br>kernel: 0000000053345a00 ffff927835157a50 000000004808ec38 00ff8e0000000000<br>kernel: ffff927835157a90 ffff927835157aa8 ffff927835157a50 ffff8e007ffad000<br>kernel: Call Trace:<br>kernel: [&lt;ffffffff81179d8f&gt;] compaction_alloc+0x1cf/0x240<br>kernel: [&lt;ffffffff811b15ce&gt;] migrate_pages+0xce/0x610<br>kernel: [&lt;ffffffff81179bc0&gt;] ? isolate_freepages_block+0x380/0x380<br>kernel: [&lt;ffffffff8117abb9&gt;] compact_zone+0x299/0x400<br>kernel: [&lt;ffffffff8117adbc&gt;] compact_zone_order+0x9c/0xf0<br>kernel: [&lt;ffffffff8117b171&gt;] try_to_compact_pages+0x121/0x1a0<br>kernel: [&lt;ffffffff815ff336&gt;] __alloc_pages_direct_compact+0xac/0x196<br>kernel: [&lt;ffffffff81160758&gt;] __alloc_pages_nodemask+0x788/0xb90<br>kernel: [&lt;ffffffff810b11c0&gt;] ? task_numa_fault+0x8d0/0xbb0<br>kernel: [&lt;ffffffff811a24aa&gt;] alloc_pages_vma+0x9a/0x140<br>kernel: [&lt;ffffffff811b674b&gt;] do_huge_pmd_anonymous_page+0x10b/0x410<br>kernel: [&lt;ffffffff81182334&gt;] handle_mm_fault+0x184/0xd60<br>kernel: [&lt;ffffffff8160f1e6&gt;] __do_page_fault+0x156/0x520<br>kernel: [&lt;ffffffff8118a945&gt;] ? change_protection+0x65/0xa0<br>kernel: [&lt;ffffffff811a0dbb&gt;] ? change_prot_numa+0x1b/0x40<br>kernel: [&lt;ffffffff810adb86&gt;] ? task_numa_work+0x266/0x300<br>kernel: [&lt;ffffffff8160f5ca&gt;] do_page_fault+0x1a/0x70<br>kernel: [&lt;ffffffff81013b0c&gt;] ? do_notify_resume+0x9c/0xb0<br>kernel: [&lt;ffffffff8160b808&gt;] page_fault+0x28/0x30<br>kernel: Code: 89 ee 48 89 4d b0 41 89 c5 eb 1d 90 49 83 c7 01 48 83 c3 40 4d<br>39 <span class="hljs-built_in">fc</span> 0f 86 07 01 00 00 41 83 c5 01 4d 85 f6 4c 0f 44 f3 8b 43 18 &lt;83&gt; f8 80<br>75 dc 48 8b 45 b8 0f b6 55 c0 48 8d 75 c8 4c 8b 45 b0<br></code></pre></td></tr></table></figure>

<h3 id="Transparent-Huge-Page"><a href="#Transparent-Huge-Page" class="headerlink" title="Transparent Huge Page"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/solutions/46111">Transparent Huge Page</a></h3><p>The transparent Huge Page implementation in the Linux kernel includes functionality that provides compaction. Compaction operations are system level processes that are resource intensive</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#### Enable or disable</span><br>$ cat /sys/kernel/mm/transparent_hugepage/enabled<br>[always] madvise never<br>$ cat /sys/kernel/mm/transparent_hugepage/defrag<br>[always] madvise never<br><br>$ grep AnonHugePages /proc/meminfo<br>AnonHugePages:  19523584 kB<br><br>$ cat /proc/meminfo|grep Huge<br>AnonHugePages:  1681086464 kB<br>HugePages_Total:       0<br>HugePages_Free:        0<br>HugePages_Rsvd:        0<br>HugePages_Surp:        0<br>Hugepagesize:       2048 kB<br><br><span class="hljs-comment">## means 1681086464/2048 = 820843x 2MB huge pages</span><br><br>$ grep -Ei <span class="hljs-string">&#x27;trans|thp&#x27;</span> /proc/vmstat<br>nr_anon_transparent_hugepages 9533<br>thp_fault_alloc 24017<br>thp_fault_fallback 16231<br>thp_collapse_alloc 1687<br>thp_collapse_alloc_failed 39449<br>thp_split 2926<br>thp_zero_page_alloc 1<br>thp_zero_page_alloc_failed 0<br><br><span class="hljs-comment">### check the process</span><br>$ grep -e AnonHugePages  /proc/*/smaps | awk -F <span class="hljs-string">&#x27;[/ ]+&#x27;</span> <span class="hljs-string">&#x27;$(NF-1)&gt;4 &#123;system(&quot;ps -fp  &quot;$3)&#125;&#x27;</span><br>UID        PID  PPID  C STIME TTY          TIME CMD<br>nobody    5023  5016  3 Jun07 ?        22:28:27 /sbin/lustre_exporter --collector.ost=disabled --collector.mdt=core<br>UID        PID  PPID  C STIME TTY          TIME CMD<br>polkitd    743     1  0 Jun07 ?        00:00:19 /usr/lib/polkit-1/polkitd --no-debug<br></code></pre></td></tr></table></figure>


<h3 id="Single-process-memory"><a href="#Single-process-memory" class="headerlink" title="Single process memory"></a>Single process memory</h3><pre><code>   /proc/[pid]/statm
          Provides information about memory usage, measured in pages.
          The columns are:

              size       (1) total program size
                         (same as VmSize in /proc/[pid]/status)
              resident   (2) resident set size
                         (same as VmRSS in /proc/[pid]/status)
              shared     (3) number of resident shared pages (i.e., backed by a file)
                         (same as RssFile+RssShmem in /proc/[pid]/status)
              text       (4) text (code)
              lib        (5) library (unused since Linux 2.6; always 0)
              data       (6) data + stack
              dt         (7) dirty pages (unused since Linux 2.6; always 0)</code></pre>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">cat /proc/3760/statm<br>400865 96456 37653 27355 0 157019 0<br><br></code></pre></td></tr></table></figure>

<p>Second field means res (resident)<br>pmap $(pgrep bash)</p>
<p>There are some of share library in each resident</p>
<p>If you want get share library memory consumption.<br>/proc/[pid]/smaps (since Linux 2.6.14)<br>              This file shows memory consumption for each of the process’s<br>              mappings.  (The pmap(1) command displays similar information,<br>              in a form that may be easier for parsing.)</p>
<h4 id="Slab"><a href="#Slab" class="headerlink" title="Slab"></a>Slab</h4><p>In-kernel data structures cache.</p>
<p>Cache pool for often userd dupulication objects<br>you could found these objects from slabtop</p>
<p>Get all slabsize<br>awk ‘BEGIN{sum=0;}{sum=sum+$3*$4;}END{print sum/1024/1024}’ /proc/slabinfo MB</p>
<h4 id="Page-table"><a href="#Page-table" class="headerlink" title="Page table"></a>Page table</h4><p>awk ‘$0~/PageTables/ {print $2}’ /proc/meminfo KB</p>
<h4 id="Struct-page"><a href="#Struct-page" class="headerlink" title="Struct page"></a>Struct page</h4><p>page frame minimum unit. every page frame has a struct page to point<br><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/34836806/how-to-get-physical-address-from-struct-page-in-linux-kernel">struct page could mapping page frame to physical address</a><br>all page frame in the LUR list.<br>There are 2.3%(96/4096) usage in linux 2.6.32</p>
<h3 id="Use-hugetlbfs"><a href="#Use-hugetlbfs" class="headerlink" title="Use hugetlbfs"></a><a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/5/html/tuning_and_optimizing_red_hat_enterprise_linux_for_oracle_9i_and_10g_databases/sect-oracle_9i_and_10g_tuning_guide-large_memory_optimization_big_pages_and_huge_pages-configuring_huge_pages_in_red_hat_enterprise_linux_4_or_5">Use hugetlbfs</a></h3><h4 id="set-hugepage"><a href="#set-hugepage" class="headerlink" title="set hugepage"></a><a target="_blank" rel="noopener" href="https://paolozaino.wordpress.com/2016/10/02/how-to-force-any-linux-application-to-use-hugepages-without-modifying-the-source-code/">set hugepage</a></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ yum -y install libhugetlbfs-utils libhugetlbfs<br><span class="hljs-comment"># To set the 2MB pool minimum to 512 pages:</span><br>$ hugeadm --pool-pages-min 2MB:512<br>$ hugeadm --pool-pages-max 2MB:2048<br>$ hugeadm --pool-list<br><br>$ mkdir -p /mnt/hugetlbfs-64K<br>$ mount -t hugetlbfs none -opagesize=64k /mnt/hugetlbfs-64K<br>or <br>$ mount -t hugetlbfs none /mnt/hugetlbfs -o uid=postfix -o gid=postfix<br>$ hugeadm --set-recommended-shmmax<br>$ hugeadm --explain<br><br><br>$ LD_PRELOAD=libhugetlbfs.so HUGETLB_MORECORE=yes ./run_your_cmd<br><span class="hljs-comment">## looks like it &#x27;s ok</span><br>  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND<br>31723 root      20   0  642.7g  94996   1348 S  1734  0.0 101:41.53 ./ft.E.x<br></code></pre></td></tr></table></figure>

<h4 id="Defragment-kernel-memory"><a href="#Defragment-kernel-memory" class="headerlink" title="Defragment kernel memory"></a>Defragment kernel memory</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ mount -t debugfs none  /sys/kernel/debug<br>$ cat /proc/buddyinfo<br>                          2^0    2^1    2^2    2^3    2^4    2^5    2^6    2^7    2^8    2^9    2^10 (1024K)<br>Node 0, zone      DMA      1      0      1      0      2      1      1      0      1      1      3<br>Node 0, zone    DMA32      3      3      2      2      3      2      4      2      1      0    458<br>Node 0, zone   Normal 579745  20289    510     94      0      0      0      0      0      0      0<br>Node 1, zone   Normal 2230945 587911  23339      0      0      0      0      0      0      0      0<br>Node 2, zone   Normal 2332274 236445  28213   9936    922     23      9      0      0      0      0<br>Node 3, zone   Normal 654981   7909    163     47     11      1      0      0      0      0      0<br><br>$ <span class="hljs-built_in">echo</span> m &gt; /proc/sysrq-trigger <span class="hljs-comment"># same with buddyinfo</span><br><br>$ cat /sys/kernel/debug/extfrag/extfrag_index<br>Node 0, zone      DMA -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000<br>Node 0, zone    DMA32 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000<br>Node 0, zone   Normal -1.000 0.500 0.750 0.875 0.938 0.969 0.985 0.993 0.996 0.998 0.999<br>Node 1, zone   Normal -1.000 -1.000 0.750 0.875 0.938 0.969 0.985 0.993 0.996 0.998 0.999<br>Node 2, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.990 0.995<br>Node 3, zone   Normal -1.000 -1.000 -1.000 0.860 0.930 0.965 0.983 0.992 0.996 0.998 0.999<br><span class="hljs-comment">#### -1.000 is ok,</span><br><br>$ <span class="hljs-built_in">echo</span> 1 &gt; /proc/sys/vm/compact_memory<br><br>$ cat /proc/buddyinfo<br>Node 0, zone      DMA      1      0      1      0      2      1      1      0      1      1      3<br>Node 0, zone    DMA32      3      3      2      2      3      2      4      2      1      0    458<br>Node 0, zone   Normal  13927    290      0      0      0      0      0      0      0      0      0<br>Node 1, zone   Normal 415126 488237 168310  90724  38203   7840    443      9      0      0      0<br>Node 2, zone   Normal 2068303 341591  58672  25946   4986    920    239     40      1      0      0<br>Node 3, zone   Normal   9030    668      5     23      7      1      0      0      0      0      0<br><br>$ cat /sys/kernel/debug/extfrag/extfrag_index<br>Node 0, zone      DMA -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000<br>Node 0, zone    DMA32 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000<br>Node 0, zone   Normal -1.000 -1.000 -1.000 -1.000 0.935 0.968 0.984 0.992 0.996 0.998 0.999<br>Node 1, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.987 0.994 0.997<br>Node 2, zone   Normal -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 -1.000 0.998 0.999<br>Node 3, zone   Normal -1.000 -1.000 -1.000 -1.000 0.933 0.967 0.984 0.992 0.996 0.998 0.999<br><br><br>$ cat /proc/sys/vm/extfrag_threshold<br>500<br><span class="hljs-comment">## if the value large than extfrag_threshold ,the kswapd will trigger memory compaction, reduce the value to 200 ? </span><br><span class="hljs-comment">## -1.000 means engough memory, if the value near the 1.000 that means more extfrag_threshold </span><br><br></code></pre></td></tr></table></figure>
<p>compact_memory<br>Available only when CONFIG_COMPACTION is set. When 1 is written to the file, all zones are compacted such that free memory is available in contiguous blocks where possible. This can be important for example in the allocation of huge pages although processes will also directly compact memory as required.</p>
<p>in another node, looks like there are 8 ~ 16K page in centos 7.6 ,3.10.0-957.10.1.el7.x86_64</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"> cat /proc/buddyinfo<br>Node 0, zone      DMA      0      1      1      0      2      1      1      0      1      1      3<br>Node 0, zone    DMA32     12   6308  12784   5977   1766    440     93     11     19      0      0<br>Node 0, zone   Normal    190   2376   2586 170387  88814  17747   4114   1895   1211      0      0<br>Node 1, zone   Normal    186    871    437 165556  81041  12616   2113    978    607      0      0<br>Node 2, zone   Normal    427   2125   1593 137923  87498  19412   6125    883    552      0      0<br>Node 3, zone   Normal    280   2686   1041  74979  80569  16675   4315   1792   1145      0      0<br></code></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://paolozaino.wordpress.com/2016/10/02/how-to-force-any-linux-application-to-use-hugepages-without-modifying-the-source-code/">At this point is time to start running your application using libhugetlbfs so that your app will use Hugepages.</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ grep Hugepagesize /proc/meminfo<br>Hugepagesize:       2048 kB<br>$ <span class="hljs-built_in">echo</span> 512 &gt; /proc/sys/vm/nr_hugepages<br>This means <span class="hljs-keyword">if</span> a 1GB Huge Pages pool should be allocated, <span class="hljs-keyword">then</span> 512 Huge Pages need to be allocated<br>it <span class="hljs-string">&#x27;s the static huge page</span><br><span class="hljs-string"></span><br><span class="hljs-string">echo 1000 &gt; /proc/sys/vm/hugetlb_shm_group</span><br><span class="hljs-string">##means only members of group testuser(1000) can allocate &quot;huge&quot; Shared memory segment</span><br><span class="hljs-string">mount -t hugetlbfs -o uid=1000,gid=1000,mode=775,size=10g none /data/hugeshm</span><br><span class="hljs-string"></span><br><span class="hljs-string">#kernel parameter, 4x1G, 1024x2M</span><br><span class="hljs-string">default_hugepagesz=1G hugepagesz=1G hugepages=4 hugepagesz=2M hugepages=1024</span><br><span class="hljs-string">mount -t hugetlbfs -o pagesize=1G none /dev/hugepages1G</span><br><span class="hljs-string">mount -t hugetlbfs -o pagesize=2M none /dev/hugepages2M</span><br><span class="hljs-string"></span><br><span class="hljs-string">echo 4 &gt; /sys/devices/system/node/node1/hugepages/hugepages-1048576kB/nr_hugepages</span><br><span class="hljs-string">echo 1024 &gt; /sys/devices/system/node/node3/hugepages/hugepages-2048kB/nr_hugepages</span><br><span class="hljs-string"></span><br><span class="hljs-string">/proc/sys/vm/nr_overcommit_hugepages</span><br><span class="hljs-string">Defines the maximum number of additional huge pages that can be created and used by the system through overcommitting memory. Writing any non-zero value into this file indicates that the system obtains that number of huge pages from the kernel&#x27;</span>s normal page pool <span class="hljs-keyword">if</span> the persistent huge page pool is exhausted. As these surplus huge pages become unused, they are <span class="hljs-keyword">then</span> freed and returned to the kernel<span class="hljs-string">&#x27;s normal page pool.</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure>

<h4 id="memlock"><a href="#memlock" class="headerlink" title="memlock"></a>memlock</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">oracle           soft    memlock         1048576<br>oracle           hard    memlock         1048576<br></code></pre></td></tr></table></figure>
<p>The memlock parameter specifies how much memory the oracle user can lock into its address space. Note that Huge Pages are locked in physical memory. The memlock setting is specified in KB and must match the memory size of the number of Huge Pages that Oracle should be able to allocate. So if the Oracle database should be able to use 512 Huge Pages, then memlock must be set to at least 512 * Hugepagesize, which on this system would be 1048576 KB (512<em>1024</em>2). If memlock is too small, then no single Huge Page will be allocated when the Oracle database starts</p>
<h4 id="free-hugepage"><a href="#free-hugepage" class="headerlink" title="free hugepage"></a>free hugepage</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> 0 &gt; /proc/sys/vm/nr_hugepages<br></code></pre></td></tr></table></figure>

<h4 id="manage-tools"><a href="#manage-tools" class="headerlink" title="manage tools"></a>manage tools</h4><p>hugeadm</p>
<h4 id="reduce-OOM-kill-rate"><a href="#reduce-OOM-kill-rate" class="headerlink" title="reduce OOM kill rate"></a>reduce OOM kill rate</h4><p>echo -15 &gt; /proc/${pid}/oom_adj</p>
<h4 id="get-pagesize"><a href="#get-pagesize" class="headerlink" title="get pagesize"></a>get pagesize</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">getconf PAGESIZE<br>4096<br></code></pre></td></tr></table></figure>

<h3 id="enable-huge-page-for-performance"><a href="#enable-huge-page-for-performance" class="headerlink" title="enable huge page for performance"></a>enable huge page for performance</h3><ul>
<li>Hugepages is a feature that allows the Linux kernel to utilize the multiple page size capabilities of<br>modern hardware architectures.<ul>
<li>A page is the basic unit of virtual memory, with the default page size being 4 KB in the x86 architecture.</li>
</ul>
</li>
<li>Leave sufficient memory for OS use<ul>
<li>no longer subject to normal memory allocations</li>
</ul>
</li>
<li>Huge Pages are ‘pinned’ to physical RAM and cannot be swapped/paged out.<ul>
<li>Preference is for 1G hugepages.</li>
<li>Each hugepage requires a TLB entry. Smaller hugepages =&gt; more TLBs and TLB lookups due to page faults =&gt; higher probability of packet drop blips</li>
</ul>
</li>
</ul>
<p>hugepagesz<br>[HW,IA-64,PPC,X86-64] The size of the HugeTLB pages.<br>On x86-64 and powerpc, this option can be specified multiple times interleaved with hugepages= to reserve huge pages of different sizes. Valid pages sizes on x86-64 are 2M (when the CPU supports “pse”) and 1G (when the CPU supports the “pdpe1gb” cpuinfo flag).</p>
<p>hugepages<br>[HW,X86-32,IA-64] HugeTLB pages to allocate at boot.</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">hugepagesz</span>=1G <span class="hljs-attribute">hugepages</span>=224<br></code></pre></td></tr></table></figure>

<h3 id="slab-exhaust-all-memory-because-a-lot-of-scan"><a href="#slab-exhaust-all-memory-because-a-lot-of-scan" class="headerlink" title="slab exhaust all memory because a lot of scan"></a>slab exhaust all memory because a lot of scan</h3><p>top<br><img src="/img/top-mem1.png"></p>
<p>Why Slab=24021820 kB (24GB)</p>
<p>slabtop<br><img src="/img/slabtop1.png"> </p>
<p>meminfo</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs bash">MemTotal:       32832340 kB<br>MemFree:          829744 kB<br>Buffers:           85096 kB<br>Cached:          1895216 kB<br>SwapCached:       164592 kB<br>Active:          4572372 kB<br>Inactive:        2520612 kB<br>Active(anon):    4131784 kB<br>Inactive(anon):   983612 kB<br>Active(file):     440588 kB<br>Inactive(file):  1537000 kB<br>Unevictable:       25864 kB<br>Mlocked:            9512 kB<br>SwapTotal:       8191996 kB<br>SwapFree:        5818864 kB<br>Dirty:               120 kB<br>Writeback:             0 kB<br>AnonPages:       4974644 kB<br>Mapped:            12584 kB<br>Shmem:                36 kB<br>Slab:           24021820 kB<br>SReclaimable:   11202668 kB<br>SUnreclaim:     12819152 kB<br>KernelStack:       10624 kB<br>PageTables:        38088 kB<br>NFS_Unstable:          0 kB<br>Bounce:                0 kB<br>WritebackTmp:          0 kB<br>CommitLimit:    24608164 kB<br>Committed_AS:    7777952 kB<br>VmallocTotal:   34359738367 kB<br>VmallocUsed:      413916 kB<br>VmallocChunk:   34359269244 kB<br>HardwareCorrupted:     0 kB<br>AnonHugePages:     30720 kB<br>HugePages_Total:       0<br>HugePages_Free:        0<br>HugePages_Rsvd:        0<br>HugePages_Surp:        0<br>Hugepagesize:       2048 kB<br>DirectMap4k:        4096 kB<br>DirectMap2M:     1957888 k<br></code></pre></td></tr></table></figure>

<h3 id="memmap"><a href="#memmap" class="headerlink" title="memmap"></a><a target="_blank" rel="noopener" href="https://docs.pmem.io/getting-started-guide/creating-development-environments/linux-environments/linux-memmap">memmap</a></h3><p><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs bash">memmap=exactmap	[KNL,X86] Enable setting of an exact<br>			E820 memory map, as specified by the user.<br>			Such memmap=exactmap lines can be constructed based on<br>			BIOS output or other requirements. See the memmap=nn@ss<br>			option description.<br><br>	memmap=nn[KMG]@ss[KMG]<br>			[KNL] Force usage of a specific region of memory.<br>			Region of memory to be used is from ss to ss+nn.<br>			If @ss[KMG] is omitted, it is equivalent to mem=nn[KMG],<br>			<span class="hljs-built_in">which</span> limits max address to nn[KMG].<br>			Multiple different regions can be specified,<br>			comma delimited.<br>			Example:<br>				memmap=100M@2G,100M<span class="hljs-comment">#3G,1G!1024G</span><br><br>	memmap=nn[KMG]<span class="hljs-comment">#ss[KMG]</span><br>			[KNL,ACPI] Mark specific memory as ACPI data.<br>			Region of memory to be marked is from ss to ss+nn.<br><br>	memmap=nn[KMG]<span class="hljs-variable">$ss</span>[KMG]<br>			[KNL,ACPI] Mark specific memory as reserved.<br>			Region of memory to be reserved is from ss to ss+nn.<br>			Example: Exclude memory from 0x18690000-0x1869ffff<br>			         memmap=64K<span class="hljs-variable">$0x18690000</span><br>			         or<br>			         memmap=0x10000<span class="hljs-variable">$0x18690000</span><br>			Some bootloaders may need an escape character before <span class="hljs-string">&#x27;$&#x27;</span>,<br>			like Grub2, otherwise <span class="hljs-string">&#x27;$&#x27;</span> and the following number<br>			will be eaten.<br><br>	memmap=nn[KMG]!ss[KMG]<br>			[KNL,X86] Mark specific memory as protected.<br>			Region of memory to be used, from ss to ss+nn.<br>			The memory region may be marked as e820 <span class="hljs-built_in">type</span> 12 (0xc)<br>			and is NVDIMM or ADR memory.<br></code></pre></td></tr></table></figure>

<figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> dmesg | grep e820<br><span class="hljs-symbol">$</span> grubby --args=<span class="hljs-string">&quot;memmap=96G:32G&quot;</span> --update-kernel=<span class="hljs-keyword">ALL</span><br></code></pre></td></tr></table></figure>
<p>mapping /dev/pmemX can be used to create a DAX filesystem</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><br>$ sudo parted <span class="hljs-regexp">/dev/</span>pmem0<br>(parted) mkpart<br>Partition type?  primary/extended? p<br><span class="hljs-keyword">File</span> system type?  [ext2]? ext4<br>Start? <span class="hljs-number">2</span>MiB<br>End? <span class="hljs-number">100</span>GiB<br>(parted)<br><br>(parted) mkpart<br>Partition type?  primary/extended? p<br><span class="hljs-keyword">File</span> system type?  [ext2]? ext4<br>Start? <span class="hljs-number">100</span>GiB<br>End? <span class="hljs-number">200</span>GiB<br><br>$  getconf PAGE_SIZE<br><span class="hljs-number">4096</span><br><br>$ sudo mkfs.ext4 -b <span class="hljs-number">4096</span> -E stride=<span class="hljs-number">512</span> -F <span class="hljs-regexp">/dev/</span>pmem0<br>$ sudo mkdir /pmem<br>$ sudo mount -o dax <span class="hljs-regexp">/dev/</span>pmem0p1 /pmem<br>$ sudo mount -v | <span class="hljs-keyword">grep</span> /pmem<br>$ fallocate --length <span class="hljs-number">1</span>G <span class="hljs-regexp">/pmem/</span>data<br>$ echo <span class="hljs-number">1</span> &gt; <span class="hljs-regexp">/sys/</span>kernel<span class="hljs-regexp">/debug/</span>tracing<span class="hljs-regexp">/events/</span>fs_dax<span class="hljs-regexp">/dax_pmd_fault_done/</span>enable<br>$ echo <span class="hljs-number">0</span> &gt; <span class="hljs-regexp">/sys/</span>kernel<span class="hljs-regexp">/debug/</span>tracing<span class="hljs-regexp">/events/</span>fs_dax<span class="hljs-regexp">/dax_pmd_fault_done/</span>enable<br><br># Verify the namespace is in fsdax mode<br>$ ndctl list -u<br>$ cat <span class="hljs-regexp">/proc/i</span>omem<br></code></pre></td></tr></table></figure>


<h4 id="Monitor-ecc-error"><a href="#Monitor-ecc-error" class="headerlink" title="Monitor ecc error"></a>Monitor ecc error</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ dmesg -T |  grep -Ei <span class="hljs-string">&quot;Err.*bit ECC&quot;</span><br><br><span class="hljs-comment"># Monitor multiple bit</span><br>$ cat /sys/devices/system/edac/mc/mc*/[u,c]e_count | <span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> line; <span class="hljs-keyword">do</span> [[ ! <span class="hljs-variable">$line</span> -eq 0 ]] &amp;&amp; <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Got DRAM ecc error&quot;</span> &amp;&amp; <span class="hljs-built_in">exit</span> 2; <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure>

<h3 id="Benchmark-by-perf"><a href="#Benchmark-by-perf" class="headerlink" title="Benchmark by perf"></a>Benchmark by perf</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ lscpu<br>......<br>NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18<br>NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19<br><br>$ perf bench numa mem  -p 1 -t 10  -T 12000  -Irq -H 1 -C 1,3,5,7,9,11,13,15,17,19 -M 0,0,0,0,0,0,0,0,0,0<br><span class="hljs-comment"># Running &#x27;numa/mem&#x27; benchmark:</span><br><br> <span class="hljs-comment"># Running main, &quot;perf bench numa numa-mem -p 1 -t 10 -T 12000 -Irq -H 1 -C 1,3,5,7,9,11,13,15,17,19 -M 0,0,0,0,0,0,0,0,0,0&quot;</span><br>          8.837 secs slowest (max) thread-runtime<br>          8.000 secs fastest (min) thread-runtime<br>          8.182 secs average thread-runtime<br>          4.738 % difference between max/avg runtime<br>         12.584 GB data processed, per thread<br>        125.840 GB data processed, total<br>          0.702 nsecs/byte/thread runtime<br>          1.424 GB/sec/thread speed<br>         14.239 GB/sec total speed<br><br>$ perf bench numa mem  -p 1 -t 10  -T 12000  -Irq -H 1 -C 0,2,4,6,8,10,12,14,16,18 -M 0,0,0,0,0,0,0,0,0,0<br><span class="hljs-comment"># Running &#x27;numa/mem&#x27; benchmark:</span><br><br> <span class="hljs-comment"># Running main, &quot;perf bench numa numa-mem -p 1 -t 10 -T 12000 -Irq -H 1 -C 0,2,4,6,8,10,12,14,16,18 -M 0,0,0,0,0,0,0,0,0,0&quot;</span><br>          5.528 secs slowest (max) thread-runtime<br>          5.000 secs fastest (min) thread-runtime<br>          5.084 secs average thread-runtime<br>          4.776 % difference between max/avg runtime<br>         12.584 GB data processed, per thread<br>        125.840 GB data processed, total<br>          0.439 nsecs/byte/thread runtime<br>          2.276 GB/sec/thread speed<br>         22.764 GB/sec total speed<br></code></pre></td></tr></table></figure>

<h3 id="AMD-roma-CPU-memroy"><a href="#AMD-roma-CPU-memroy" class="headerlink" title="AMD roma CPU memroy"></a>AMD roma CPU memroy</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">$</span> <span class="hljs-string">dmidecode</span> <span class="hljs-string">-t</span> <span class="hljs-string">memory</span> <span class="hljs-string">|</span> <span class="hljs-string">grep</span> <span class="hljs-string">-Ei</span> <span class="hljs-string">&#x27;1638|32&#x27;</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Size:</span> <span class="hljs-number">16384</span> <span class="hljs-string">MB</span><br>	<span class="hljs-attr">Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br>	<span class="hljs-attr">Configured Memory Speed:</span> <span class="hljs-number">3200 </span><span class="hljs-string">MT/s</span><br><br><span class="hljs-string">$</span> <span class="hljs-string">for</span> <span class="hljs-string">i</span> <span class="hljs-string">in</span> &#123;<span class="hljs-number">5</span><span class="hljs-string">..8</span>&#125;<span class="hljs-string">;</span> <span class="hljs-string">do</span> <span class="hljs-string">echo</span> <span class="hljs-string">$i;</span> <span class="hljs-string">perf</span> <span class="hljs-string">bench</span> <span class="hljs-string">numa</span> <span class="hljs-string">mem</span>  <span class="hljs-string">-p</span> <span class="hljs-number">1</span> <span class="hljs-string">-t</span> <span class="hljs-number">2</span>  <span class="hljs-string">-T</span> <span class="hljs-number">15000</span>  <span class="hljs-string">-Irq</span> <span class="hljs-string">-H</span> <span class="hljs-number">1</span> <span class="hljs-string">-C</span> <span class="hljs-number">4</span><span class="hljs-string">,$i</span> <span class="hljs-string">|</span> <span class="hljs-string">grep</span> <span class="hljs-string">&quot;sec total speed&quot;</span><span class="hljs-string">;</span> <span class="hljs-string">done</span><br><span class="hljs-number">5</span><br>         <span class="hljs-number">12.818</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">6</span><br>         <span class="hljs-number">12.757</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">7</span><br>         <span class="hljs-number">12.810</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">8</span><br>         <span class="hljs-number">13.142</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><br><span class="hljs-string">$</span> <span class="hljs-string">for</span> <span class="hljs-string">i</span> <span class="hljs-string">in</span> &#123;<span class="hljs-number">21</span><span class="hljs-string">..24</span>&#125;<span class="hljs-string">;</span> <span class="hljs-string">do</span> <span class="hljs-string">echo</span> <span class="hljs-string">$i;</span> <span class="hljs-string">perf</span> <span class="hljs-string">bench</span> <span class="hljs-string">numa</span> <span class="hljs-string">mem</span>  <span class="hljs-string">-p</span> <span class="hljs-number">1</span> <span class="hljs-string">-t</span> <span class="hljs-number">2</span>  <span class="hljs-string">-T</span> <span class="hljs-number">15000</span>  <span class="hljs-string">-Irq</span> <span class="hljs-string">-H</span> <span class="hljs-number">1</span> <span class="hljs-string">-C</span> <span class="hljs-number">20</span><span class="hljs-string">,$i</span> <span class="hljs-string">|</span> <span class="hljs-string">grep</span> <span class="hljs-string">&quot;sec total speed&quot;</span><span class="hljs-string">;</span> <span class="hljs-string">done</span><br><span class="hljs-number">21</span><br>         <span class="hljs-number">12.836</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">22</span><br>         <span class="hljs-number">12.824</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">23</span><br>         <span class="hljs-number">12.847</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-number">24</span><br>         <span class="hljs-number">13.183</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><br><span class="hljs-string">$</span> <span class="hljs-string">perf</span> <span class="hljs-string">bench</span> <span class="hljs-string">numa</span> <span class="hljs-string">mem</span>  <span class="hljs-string">-p</span> <span class="hljs-number">1</span> <span class="hljs-string">-t</span> <span class="hljs-number">2</span>  <span class="hljs-string">-T</span> <span class="hljs-number">15000</span>  <span class="hljs-string">-Irq</span> <span class="hljs-string">-H</span> <span class="hljs-number">1</span> <span class="hljs-string">-C</span> <span class="hljs-number">20</span><span class="hljs-string">,46</span> <span class="hljs-string">|</span> <span class="hljs-string">grep</span> <span class="hljs-string">&quot;sec total speed&quot;</span><br>         <span class="hljs-number">13.125</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br><span class="hljs-string">$</span> <span class="hljs-string">perf</span> <span class="hljs-string">bench</span> <span class="hljs-string">numa</span> <span class="hljs-string">mem</span>  <span class="hljs-string">-p</span> <span class="hljs-number">1</span> <span class="hljs-string">-t</span> <span class="hljs-number">2</span>  <span class="hljs-string">-T</span> <span class="hljs-number">15000</span>  <span class="hljs-string">-Irq</span> <span class="hljs-string">-H</span> <span class="hljs-number">1</span> <span class="hljs-string">-C</span> <span class="hljs-number">20</span><span class="hljs-string">,47</span> <span class="hljs-string">|</span> <span class="hljs-string">grep</span> <span class="hljs-string">&quot;sec total speed&quot;</span><br>         <span class="hljs-number">13.137</span> <span class="hljs-string">GB/sec</span> <span class="hljs-string">total</span> <span class="hljs-string">speed</span><br></code></pre></td></tr></table></figure>
<p>AMD roma looks like 4 cores share a mem channel, 2 threads x 15000MB = 30G , 12GB/s means in a mem channel, 13GB/s means pass two mem channel, just guess.</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Ginger</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yoursite.com/2018/07/02/mem/">http://yoursite.com/2018/07/02/mem/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/memory/">memory</a></div><div class="post_share"><div class="social-share" data-image="/img/photo_by_spacex.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/07/08/scsi_dev/"><img class="prev-cover" src="/img/photo_by_spacex.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">scsi device maintain</div></div></a></div><div class="next-post pull-right"><a href="/2018/06/01/nic_ethernet_tuning/"><img class="next-cover" src="/img/photo_by_spacex.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">ethernet nic tuning</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2018/08/06/numa/" title="numa"><img class="cover" src="/img/photo_by_spacex.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-08-06</div><div class="title">numa</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2015 - 2020 By Ginger</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk({
      clientID: '0b9d5b98d0a972b33cf7',
      clientSecret: '769efc11b32f6c0d03bcbf3ee800dfc4e2690459',
      repo: 'homerl.github.io',
      owner: 'homerl',
      admin: ['homerl'],
      id: 'bf66e170ded620c91eb0086029154e63',
      language: 'en',
      perPage: 10,
      distractionFreeMode: false,
      pagerDirection: 'last',
      createIssueManually: false,
      updateCountCallback: commentCount
    })
    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    $.getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js', initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Gitalk' === 'Gitalk' || !false) {
  if (false) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></div></body></html>